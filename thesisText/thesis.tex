%% History:
% Pavel Tvrdik (26.12.2004)
%  + initial version for PhD Report
%
% Daniel Sykora (27.01.2005)
%
% Michal Valenta (3.12.2008)
% rada zmen ve formatovani (diky M. Duškovi, J. Holubovi a J. Žďárkovi)
% sjednoceni zdrojoveho kodu pro anglickou, ceskou, bakalarskou a diplomovou praci

% One-page layout: (proof-)reading on display
%%%% \documentclass[11pt,oneside,a4paper]{book}
% Two-page layout: final printing
\documentclass[11pt,twoside,a4paper]{book}   
%=-=-=-=-=-=-=-=-=-=-=-=--=%
% The user of this template may find useful to have an alternative to these 
% officially suggested packages:
\usepackage[english]{babel}
\usepackage[T1]{fontenc} % pouzije EC fonty 
% pripadne pisete-li cesky, pak lze zkusit take:
% \usepackage[OT1]{fontenc} 
\usepackage[utf8]{inputenc}
%=-=-=-=-=-=-=-=-=-=-=-=--=%
% In case of problems with PDF fonts, one may try to uncomment this line:
%\usepackage{lmodern}
%=-=-=-=-=-=-=-=-=-=-=-=--=%
%=-=-=-=-=-=-=-=-=-=-=-=--=%!b!p!
% Depending on your particular TeX distribution and version of conversion tools 
% (dvips/dvipdf/ps2pdf), some (advanced | desperate) users may prefer to use 
% different settings.
% Please uncomment the following style and use your CSLaTeX (cslatex/pdfcslatex) 
% to process your work. Note however, this file is in UTF-8 and a conversion to 
% your native encoding may be required. Some settings below depend on babel 
% macros and should also be modified. See \selectlanguage \iflanguage.
%\usepackage{czech}  %%%%%\usepackage[T1]{czech} %%%%[IL2] [T1] [OT1]
%=-=-=-=-=-=-=-=-=-=-=-=--=%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Styles required in your work follow %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\usepackage{graphicx}
\usepackage{tabularx,colortbl}
%\usepackage{tabularx}
%\usepackage{indentfirst} %1. odstavec jako v cestine.
\usepackage{qtree}
\usepackage{tikz}
\usepackage{tikz-qtree}
\usepackage{caption}
\usepackage{listings}
\usepackage{color}
\usepackage{textcomp}
\usepackage{amssymb}
\usepackage{amsmath}
\usepackage{fixltx2e}
\usepackage{multirow}


%\usepackage{epstopdf}
%\usepackage{hyperref}
\definecolor{listinggray}{gray}{0.9}
\definecolor{lbcolor}{rgb}{0.9,0.9,0.9}
\providecommand{\abs}[1]{\lvert#1\rvert}
\lstset{ %
language=Java,                % the language of the code
basicstyle=\footnotesize,       % the size of the fonts that are used for the code
numbers=left,                   % where to put the line-numbers
numberstyle=\footnotesize,      % the size of the fonts that are used for the line-numbers
%stepnumber=2,                   % the step between two line-numbers. If it's 1,
%each line
                                % will be numbered
numbersep=5pt,                  % how far the line-numbers are from the code
backgroundcolor=\color{white},  % choose the background color. You must add \usepackage{color}
showspaces=false,               % show spaces adding particular underscores
showstringspaces=false,         % underline spaces within strings
showtabs=false,                 % show tabs within strings adding particular underscores
frame=single,                   % adds a frame around the code
tabsize=2,                      % sets default tabsize to 2 spaces
captionpos=b,                   % sets the caption-position to bottom
breaklines=true,                % sets automatic line breaking
breakatwhitespace=false,        % sets if automatic breaks should only happen at whitespace
title=\lstname,                 % show the filename of files included with \lstinputlisting;
                                % also try caption instead of title
escapeinside={\%*}{*)},         % if you want to add a comment within your code
morekeywords={*,...},            % if you want to add more keywords to the set
keywordstyle=\color[rgb]{0,0,1}\bfseries,
    commentstyle=\color[rgb]{0.133,0.545,0.133},
    stringstyle=\color[rgb]{0.627,0.126,0.941}
}


\usepackage{k336_thesis_macros} % specialni makra pro formatovani DP a BP
 % muzete si vytvorit i sva vlastni v souboru k336_thesis_macros.sty
 % najdete  radu jednoduchych definic, ktere zde ani nejsou pouzity
 % napriklad: 
 % \newcommand{\bfig}{\begin{figure}\begin{center}}
 % \newcommand{\efig}{\end{center}\end{figure}}
 % umoznuje pouzit prikaz \bfig namisto \begin{figure}\begin{center} atd.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Zvolte jednu z moznosti 
% Choose one of the following options
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%\newcommand\TypeOfWork{Diplomová práce} \typeout{Diplomova prace}
 \newcommand\TypeOfWork{Master's Thesis}   \typeout{Master's Thesis} 
% \newcommand\TypeOfWork{Bakalářská práce}  \typeout{Bakalarska prace}
% \newcommand\TypeOfWork{Bachelor's Project}  \typeout{Bachelor's Project}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Zvolte jednu z moznosti 
% Choose one of the following options
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% nabidky jsou z: http://www.fel.cvut.cz/cz/education/bk/prehled.html

%\newcommand\StudProgram{Elektrotechnika a informatika, dobíhající, Bakalářský}
%\newcommand\StudProgram{Elektrotechnika a informatika, dobíhající, Magisterský}
% \newcommand\StudProgram{Elektrotechnika a informatika, strukturovaný, Bakalářský}
% \newcommand\StudProgram{Elektrotechnika a informatika, strukturovaný,
% Navazující magisterský}
% \newcommand\StudProgram{Softwarové technologie a management, Bakalářský}
% English study:
% \newcommand\StudProgram{Electrical Engineering and Information Technology}  % bachelor programe
 \newcommand\StudProgram{Electrical Engineering and Information Technology}  %master program


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Zvolte jednu z moznosti 
% Choose one of the following options
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% nabidky jsou z: http://www.fel.cvut.cz/cz/education/bk/prehled.html

%\newcommand\StudBranch{Výpočetní technika}   % pro program EaI bak. (dobihajici i strukt.)
%\newcommand\StudBranch{Výpočetní technika}   % pro prgoram EaI mag. (dobihajici
%i strukt.)
%\newcommand\StudBranch{Softwarové inženýrství}            %pro STM
%\newcommand\StudBranch{Web a multimedia}                  % pro STM
%\newcommand\StudBranch{Computer Engineering}              % bachelor programe
\newcommand\StudBranch{Computer Science and Engineering}  % master programe


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Vyplnte nazev prace, autora a vedouciho
% Set up Work Title, Author and Supervisor
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\newcommand\WorkTitle{Framework Squander Usage}
\newcommand\FirstandFamilyName{Bc. Martin Kožený}
\newcommand\Supervisor{Ing. Jiří Daněček}


% Pouzijete-li pdflatex, tak je prijemne, kdyz bude mit vase prace
% funkcni odkazy i v pdf formatu
\usepackage[
pdftitle={\WorkTitle},
pdfauthor={\FirstandFamilyName},
bookmarks=true,
colorlinks=true,
breaklinks=true,
urlcolor=black,
citecolor=black,
linkcolor=black,
unicode=true,
]
{hyperref}



% Extension posted by Petr Dlouhy in order for better sources reference (\cite{} command) especially in Czech.
% April 2010
% See comment over \thebibliography command for details.

\usepackage[square, numbers]{natbib}             % sazba pouzite literatury
%\usepackage{url}
%\DeclareUrlCommand\url{\def\UrlLeft{<}\def\UrlRight{>}\urlstyle{tt}}  %rm/sf/tt
%\renewcommand{\emph}[1]{\textsl{#1}}    % melo by byt kurziva nebo sklonene,
\let\oldUrl\url
\renewcommand\url[1]{<\texttt{\oldUrl{#1}}>}




\begin{document}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Zvolte jednu z moznosti 
% Choose one of the following options
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%\selectlanguage{czech}
\selectlanguage{english} 

% prikaz \typeout vypise vyse uvedena nastaveni v prikazovem okne
% pro pohodlne ladeni prace


\iflanguage{czech}{
	 \typeout{************************************************}
	 \typeout{Zvoleny jazyk: cestina}
	 \typeout{Typ prace: \TypeOfWork}
	 \typeout{Studijni program: \StudProgram}
	 \typeout{Obor: \StudBranch}
	 \typeout{Jmeno: \FirstandFamilyName}
	 \typeout{Nazev prace: \WorkTitle}
	 \typeout{Vedouci prace: \Supervisor}
	 \typeout{***************************************************}
	 \newcommand\Department{Katedra počítačů}
	 \newcommand\Faculty{Fakulta elektrotechnická}
	 \newcommand\University{České vysoké učení technické v Praze}
	 \newcommand\labelSupervisor{Vedoucí práce}
	 \newcommand\labelStudProgram{Studijní program}
	 \newcommand\labelStudBranch{Obor}
}{
	 \typeout{************************************************}
	 \typeout{Language: english}
	 \typeout{Type of Work: \TypeOfWork}
	 \typeout{Study Program: \StudProgram}
	 \typeout{Study Branch: \StudBranch}
	 \typeout{Author: \FirstandFamilyName}
	 \typeout{Title: \WorkTitle}
	 \typeout{Supervisor: \Supervisor}
	 \typeout{***************************************************}
	 \newcommand\Department{Department of Computer Science and Engineering}
	 \newcommand\Faculty{Faculty of Electrical Engineering}
	 \newcommand\University{Czech Technical University in Prague}
	 \newcommand\labelSupervisor{Supervisor}
	 \newcommand\labelStudProgram{Study Programme} 
	 \newcommand\labelStudBranch{Field of Study}
}




%%%%%%%%%%%%%%%%%%%%%%%%%%    Poznamky ke kompletaci prace
% Nasledujici pasaz uzavrenou v {} ve sve praci samozrejme 
% zakomentujte nebo odstrante. 
% Ve vysledne svazane praci bude nahrazena skutecnym 
% oficialnim zadanim vasi prace.
{
\pagenumbering{roman} \cleardoublepage \thispagestyle{empty}
%\chapter*{Na tomto místě bude oficiální zadání vaší práce}
%\begin{itemize}
%\item Toto zadání je podepsané děkanem a vedoucím katedry,
%\item musíte si ho vyzvednout na studiijním oddělení Katedry počítačů na
%Karlově náměstí,
%\item v jedné odevzdané práci bude originál tohoto zadání (originál zůstává po
%obhajobě na katedře),
%\item ve druhé bude na stejném místě neověřená kopie tohoto dokumentu (tato se
%vám vrátí po obhajobě).
%\end{itemize}
\newpage
}

%%%%%%%%%%%%%%%%%%%%%%%%%%    Titulni stranka / Title page 

\coverpagestarts

%%%%%%%%%%%%%%%%%%%%%%%%%%%    Podekovani / Acknowledgements 

\acknowledgements
\noindent
At this point I would like to thank supervisor of my thesis Mr. Ing. Jiří
Daněček and author of Squander framework Mr. Aleksandar Milicevic for valuable comments
and advices to this work.


%%%%%%%%%%%%%%%%%%%%%%%%%%%   Prohlaseni / Declaration 

\declaration{In~Prague, 30.\,9.\,2011}
%\declaration{In Kořenovice nad Bečvárkou on May 15, 2008}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%    Abstract 
 
\abstractpage

The aim of this work is to describe and study framework Squander developed on
Massachusetts Institute of Technology by Mr. Aleksandar Milicevic. This
framework brings into language Java another way of programming, which can
improve effectiveness of implementing and computation performance of the program.

Work shows how was this framework used for implementing set of algorithms,
especially NP graph algorithms, and compares that implementation with
common imperative way of programming.
% Prace v cestine musi krome abstraktu v anglictine obsahovat i
% abstrakt v cestine.
\vglue60mm

%\noindent{\Huge \textbf{Abstrakt}}
%\vskip 2.75\baselineskip

%\noindent
%Abstrakt práce by měl velmi stručně vystihovat její podstatu. Tedy čím se práce
%zabývá a co je jejím výsledkem/přínosem.

%\noindent
%Očekávají se cca 1 -- 2 odstavce, maximálně půl stránky.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  Obsah / Table of Contents 

\tableofcontents


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  Seznam obrazku / List of Figures 

\listoffigures


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  Seznam tabulek / List of Tables

\listoftables


%**************************************************************

\mainbodystarts
% horizontalní mezera mezi dvema odstavci
%\parskip=5pt
%11.12.2008 parskip + tolerance
\normalfont
\parskip=0.2\baselineskip plus 0.2\baselineskip minus 0.1\baselineskip

% Odsazeni prvniho radku odstavce resi class book (neaplikuje se na prvni 
% odstavce kapitol, sekci, podsekci atd.) Viz usepackage{indentfirst}.
% Chcete-li selektivne zamezit odsazeni 1. radku nektereho odstavce,
% pouzijte prikaz \noindent.

%**************************************************************

% Pro snadnejsi praci s vetsimi texty je rozumne tyto rozdelit
% do samostatnych souboru nejlepe dle kapitol a tyto potom vkladat
% pomoci prikazu \include{jmeno_souboru.tex} nebo \include{jmeno_souboru}.
% Napr.:
% \include{1_uvod}
% \include{2_teorie}
% atd...

%*****************************************************************************
\chapter{Introduction}
As was said in abstract, the main purpose of this thesis is to describe and use
framework Squander developed at Massachusetts Institute of Technology (MIT) by Mr
Aleksandar Milicevic. This framework brings into Java declarative
constructs, which are useful for implementing programs involving computations
that are relatively easy to specify but hard to solve algorithmically. In such
cases is better to use declarative constraints to naturally express the core of
the computation, whereas imperative code is natural choice to read input
parameters and setting up data structures for the computation. This is
big advantage of this framework, that programmer can smoothly switch between
declarative logic and imperative programming.

By ability of mixing imperative and declarative code can programmer easily
express constraints of problem in terms of existing data structures and objects
on the heap. Despite having overhead of encoding and decoding, it is surprising
how is competitive Squander's SAT-based solution with specialized heuristic
developed for concrete problem.

In first chapter I am going to describe basic principles of logic programming
using language Prolog and in following one meaning of annotations, which are
used to express logic constructions in framework Squander. Last chapters are
devoted to framework itself and its comparison to common imperative way of
programming.
%*****************************************************************************
\chapter{Logic programming principles}
\label{chap:logProgPrinc}
The most known logic programming in the world is definitely Prolog and
thereby we can describe properties of logic programming using this language.
His name is derived from term PROgramming in LOGic and was developed for
programming of symbolic computation. His success led to formation new discipline
in mathematical information technology - \textbf{logic programming}.

Logic programming focus on description of relation's properties without need
to know how to do that.

\section{Logic programming paradigm}

According to \cite{nino:pls}, logic programming differ from imperative
languages in following points:
\begin{enumerate}
  \item no assignment statement
  \item no cycles, no branching 
  \item no flow control
  \item object is marked as \textit{variable}, which satisfies some set of
  conditions, that are being during computation more specified
\end{enumerate}
Logic programming is based on following concepts:
\begin{enumerate}
  \item declaring facts about objects and relations between objects
  \item declaring valid rules about objects and relations between themselves
  and computing queries
\end{enumerate}
In logic programming are \textit{facts} unconditional commands and
\textit{rules} are conditional commands. Facts and rules are stored in one
shared database. Language does not differ between program and data.

\newpage
\subsection{Facts}
\label{sec:facts}
As is presented in \cite{jirku:progProlog}, for expressing \textit{facts} and
\textit{rules} are used \textit{clauses}. Facts are used for expressing unconditionally true assertions and are clauses
with defined headers, but with no body. Usual way to illustrate how to
composed facts are family relationships.

\begin{quote}
\begin{verbatim}
                            parent(david, john).
                            parent(john, jane).
                            parent(ann, jane).
                            parent(john, richard).
                            parent(ann, richard).
                            man(john).
                            man(richard).
                            womam(ann).
                            woman(jane).
\end{verbatim}
\end{quote}
Every clause declares concrete fact about relation. We can see that relation
\verb|parent|, e.g. \verb|parent(john, jane).| is concrete \textit{instance} of
this relation for \textit{objects} \verb|john| and \verb|jane|. After declaring
those facts is possible to form queries concerning relation \verb|parent|.

\begin{verbatim}
                                 ?-parent(john, jane).
\end{verbatim}
Example above shows, how it is possible to ask, if John is parent to Jane.
Because language has this fact recorded in its environment and answer is:

\begin{verbatim}                            
                                 yes
\end{verbatim}
Similarly can be query constructed on non-existing fact:

\begin{verbatim}
                                 ?-parent(john, emily).
                            
                                 no
\end{verbatim}
Answer to this query is \verb|no| of course. Query can be also composed in a
way, that we want to get some object, which is with other object in
required relation.

\begin{verbatim}
                                 ?-parent(X, jane).
                            
                                 X = john
\end{verbatim}
Here it is also possible to get other possible solution, so we get one more
positive answer:

\begin{verbatim}
                                 X = ann
\end{verbatim}
\newpage
After that are all possible answers exhausted, so for the next command we get:

\begin{verbatim}
                                 no
\end{verbatim}
Now we try to express little bit complicated query: who is mother of Jane. This
query is necessary construct from two subqueries. First we limit set of solution
to Jane's parents. For that purpose we use query already shown above:

\begin{verbatim}
                                 ?-parent(X, jane).
\end{verbatim}




In variable \verb|X| is now stored every object, who has relation \verb|parent|
to object \verb|jane|. In our case \verb|john| and \verb|ann|. Now we have to
limit this set of results to object, which is declared in clause \verb|women|,
so we add:

\begin{verbatim}
                          ?-parent(X, jane), women(X).
\end{verbatim}
As a result of these clauses we get:

\begin{verbatim}
                          X = ann
\end{verbatim}
and nothing more. In framework Squander are as facts used objects, that are
declared in framework's rules (see Subsection \ref{sec:rules}). There are no
facts declared explicitly so we do not devote to them any more.

\subsection{Rules}
\label{sec:rules}
Expressing knowledge by facts cannot be always effective. Complexity of
relationships in family expressed by unconditional commands would lead to
big expansion of database. Despite having unlimited memory available, searching
for relevant information would has been time consuming. For this reason Prolog
provides conditional expressions - \textit{rules}.

By investigating facts is possible to derived new rule based on logic or
factual context. That knowledge allow us to express facts, which are not
explicitly stored in database. Let us show it in following example:

\begin{verbatim}
                          mother(X, Y) :- parent(X, Y),woman(X).
\end{verbatim}
Left side of rule expressed so called \textbf{head of rule} and right side
\textbf{body of rule}. This rule express, that \verb|X| is mother of \verb|Y|.
Rule is only labeled generalization of last example in previous Subsection \ref{sec:facts}.
In next example will be shown more complicated construct:

\begin{verbatim}
               brother(X, Y) :- parent(O, Y),parent(O, X),man(X).
\end{verbatim}
Expression above means, that \verb|X| is brother of \verb|Y| if exists at least
one object \verb|O|, which is common in relation \verb|parent| for both \verb|X|
and \verb|Y| assuming \verb|X| is a man. Mathematical interpretation of the
rule is:
\begin{center}
\uv{For all arbitrary persons X and Y,\\
 if some of the parents of X is O \\
 and some of the parents of Y is O \\
 and person X is a man, \\
 then X is brother of Y.}
\end{center}


When calling this rule with following parameters:
\begin{verbatim}
                          brother(richard, Y).
                          
                          Y = jane
\end{verbatim}
Rules are main construct of framework Squander, because they defined state of
object before and after computation, declares which object or object's
properties can be modified etc. On the other hand these rules are not called as
it is in Prolog, but they are declared as metadata for handling with objects.
More about Squander's rules in chapter \ref{chap:framework}.

\section{Terminology}
As presents Kolář \cite{kolar:jui}, when simplifying in Prolog, we can say,
that in every task appear \textit{objects} and \textit{relations}. Name of objects are called
\textit{terms} and name of relations are called \textit{predicates}. Terms are
analogous to arithmetic expressions, which point to the computed value, and
predicates are analogous to name of procedures, which defines relationship
between input parameters and output values, in imperative programming language.

There are two types of terms: \textit{simple terms} consisting of constants
(e.g. \verb|ann|, \verb|richard|,\ldots) and \textit{compound terms}. Compound
terms are also called \textit{structures} is every term containing simple
or compound term.

In previous Subsection \ref{sec:rules}, there are predicates \verb|parent|,
\verb|man| and \verb|woman| as names of three relations defined by program.
Predicate with name \verb|parent| is defined as a set:
\verb|{(john,jane),(ann,jane),(john,richard),(ann,richard)}|. Next predicate
with name \verb|man| is defined as a set:
\verb|{john,richard}| and finally predicate
with name \verb|woman| is defined as a set:
\verb|{ann,jane}|. 

Finally there are three types of \textit{formulas} in Prolog:
\begin{itemize}
  \item \textit{atomic} - basic formulas (e.g. \verb|parent(john, jane).,|
  \verb|parent(ann, jane).|)
  \item \textit{conditional command} - implication constructs $A :- P_1,
  P_2,\ldots, P_n$ where $P_1, P_2,\ldots, P_n$ are atomic formulas
  (e.g. \verb|brother(X, Y) :- parent(O, Y),parent(O, X),man(X).|)
  \item \textit{target clauses} - query type ($?-C_1, C_2,\ldots, C_n$ where
  $C_1, C_2,\ldots, C_n$ are targets)\\ (e.g. \verb|?-parent(X, jane),|
  \verb|women(X).|)
\end{itemize} 

\section{Evaluation in Prolog}
Main difference between \textbf{procedural semantics} and \textbf{declarative
semantics} is shown on clause below:
\begin{verbatim}
                          P :- Q, R.
\end{verbatim}
where \verb|P| and \verb|Q| are arbitrary forms of terms. We can read this
clause from declarative point of view:
\begin{itemize}
  \item \verb|P| is true, if \verb|Q| and \verb|R| are true
  \item from validity of \verb|Q| and \verb|R| follow \verb|P|
\end{itemize}
From procedural point of view has clause different meaning:
\begin{itemize}
  \item to solve problem \verb|P|, it is necessary to solve \textbf{first}
  problem \verb|Q| and \textbf{then} problem \verb|R|
  \item to fulfill target \verb|P|, it is necessary \textbf{first} to fulfil
  target \verb|Q| and then fulfil target \verb|R|
\end{itemize}

\verb|Evaluation| of sequence of targets $G_1, G_2,..., G_m$ in Prolog consists
of following steps \cite{kolar:jui}:
\begin{itemize}
  \item If is sequence of targets empty, evaluation \textbf{succeded}.
  \item For non-empty sequence of targets, operation \textit{SEARCHING} is
  invoked.
  \item \textit{SEARCHING}: Clauses of the program from top to bottom are
  searched till first clause $C$ occurence, whose head is successfully
  unified with target $G_1$. If such clause is not found, evaluation ended
  unsuccessfully.
  
  If is found clause $C$ in form
 \begin{center}
                          $H :- B_1, B_2,\ldots, B_n$
\end{center}
then all its variables are renamed such, that new form $C'$ of clause $C$, which
has no variables in common with targets $G_1, G_2,..., G_m$. $C'$ has form:
\begin{center}
                          $H' :- B_1', B_2',\ldots, B_n'$
\end{center}
$G$ and $H$ are unified by substitution $S$.
In sequence of targets is target $G_1$ replaced by body of clause $C'$ such,
that new sequence has form:
\begin{center}
                          $B_1', B_2',\ldots, B_n', G_2,\ldots, G_m$
\end{center}
If is $C$ fact, then $n = 0$ and sequence of targets is shortened to $m - 1$
targets.

Then substitution $S$ is done in order to make new list of targets, so new form
is:
\begin{center}
                          $B_1'', B_2'',\ldots, B_n'', G_2',\ldots, G_m'$
\end{center}


By recursive invocation procedure \verb|Evaluate| is evaluated this sequence of
targets. If this evaluation ends successfully, previous evaluation is treated as
also successful. If this evaluation does not end successfully, last sequence of
targets is left and it is made return to operation \textit{SEARCHING}, where is
continued immediately behind clause $C$ in order to find some next usable
clause.
\end{itemize}
Let us show evaluation in following rules, which used facts declared in
Subsection \ref{sec:facts}:\\
\\
\begin{verbatim}
                   (a)  ancestor(X, Y) :- parent(X, Y).
                   (b)  ancestor(X, Y) :- parent(X, Z), ancestor(Z, Y).
\end{verbatim}

\setlength{\parskip}{1cm plus4mm minus3mm}


\begin{figure}[ht]
\centering
%\begin{center}
%\qtreecentertrue
\begin{tikzpicture}


%\tikzset{level distance=42pt}

\Tree [ .\node(xh){$ancestor(david, jane)$}; \edge
node[auto=right]{\textbf{a1}};[ \node(t){unsuccess}; ] .{$parent(david, jane)$}
\edge node[auto=left]{\textbf{b1}}; [ [ [ \edge
node[auto=left]{\textbf{a2}};[ \node(u){success}; ].{$parent(john, jane)$}
].{$ancestor(john, jane)$} ]  .\fbox{$Z = john$} ].\node(wh){$parent(david,
Z), ancestor(Z, jane)$};]

\draw[dashed,->] (t)..controls +(east:3.5) .. (wh);
\draw[dashed,->] (u)..controls +(west:2.5) .. (xh);
\end{tikzpicture}
%\end{center}
\caption{Expression evaluation in Prolog}

\end{figure}



First of the queries is answered unsuccessfully when applied rule \textbf{a},
rule \textbf{b} is then successful.


%*****************************************************************************
\chapter{Meaning of annotations}

\section{Introduction}
Annotations are tags that programmer insert into source code so that they
can be processed by tools. The Java compiler understands a couple of
annotations, but to go any further, you need to build your own processing tool
or obtain a tool from a third party. Most common use of annotations are
\cite{horstmannCornell:coreJava}:

\begin{itemize}
  \item Automatic generation of auxiliary files, such as deployment descriptors or bean information classes.
  \item Automatic generation of code for testing, logging, transaction semantics, and so on.
\end{itemize}

In EJB 3.0 are annotations used in such sense, that a lot of repetitive code is
automated by annotations.

\section{Annotations as metadata}
Metadata are data about data. In context of computer program, metadata are data
about the code. Since Java 5.0 release, programmer can insert arbitrary data
into his source code \cite{java:annotations}. Annotations in Java is used like
an \textit{modifier}, placed before annotated item (it is a keyword similar to \verb|public| or
\verb|static|). Annotations are used to annotate classes, fields or local
variables and can be processed by tools that read them.

Each annotation is declared by annotation interface correspond to the element of
the annotation.

Annotations do not directly affect program semantics, but they do affect the way
programs are treated by tools and libraries, which can in turn affect the
semantics of the running program. Annotations can be read from source files,
class files, or reflectively at runtime.

\section{Examples of use}

\subsection{Field validation}

Annotation type declarations are similar to normal interface declarations. Each method
declaration defines an \textit{element} of the annotation type. Method
declarations must not have any parameters or a \verb|throws| clause. Return
types are restricted to primitives, \verb|String|, \verb|Class|, \verb|enums|,
annotations, and arrays of the preceding types. Methods can have default values.
Here is an example annotation type declaration:

\lstinputlisting[label=samplecode,caption=Length annotation]{src/Length.java}

Annotations can be annotated itself. Such annotations are called
\textit{meta-annotations}. E.g. using
(\verb|@Target(ElementType.FIELD)|) indicates, that annotation type should
be used to annotate only field declarations.
This simple annotation is typically used for entity field e.g. of type
\verb|String| for permitted length of this field.

Once an annotation type is defined, you can use it to annotate declarations. An
annotation is a special kind of modifier, and can be used anywhere that other
modifiers (such as \verb|public|, \verb|static|, or \verb|final|) can be used.
By convention, annotations precede other modifiers. Annotations consist of an at-sign
(\verb|@|) followed by an annotation type and a parenthesized list of
element-value pairs. The values must be compile-time constants. Here is a filed
declaration with an annotation corresponding to the annotation type declared above:

\lstinputlisting[label=samplecode,caption=Class Role]{src/Role.java}

Annotation type without any elements is called \textit{marker}
annotation type, e.g.:

\lstinputlisting[label=samplecode,caption=Entity annotation]{src/Entity.java}

We can join these two types of annotation together in following example:

\lstinputlisting[label=samplecode,caption=Entity Role]{src/entity/Role.java}

Another type of meta-annotation
(\verb|@Target(ElementType.METHOD)|) is presented below and indicates using
annotation only for method declarations:

\lstinputlisting[label=samplecode,caption=Test annotation]{src/Test.java}

In following example, there is updated entity shown above with tool for testing
the annotations:
\lstinputlisting[label=samplecode,caption=Extended class
Role]{src/extended/Role.java}
\lstinputlisting[label=samplecode,caption=Test of method
annotation]{src/RunTests.java}
\newpage
\lstinputlisting[label=samplecode,caption=Test of entity
Role annotation]{src/TestRole.java}


%\subsection{Annotating Event Handlers}
%In this subsection is shown example presented in
%\cite{horstmannCornell:coreJava}. When programmer have to use in his code
%action listeners, it leads to write a lot of repetitive code. Listeners are
%usually declared:

%\lstinputlisting[label=listener,caption=Action
%listener]{src/listeners/Button.java}

%Writing this boring code can be omitted by using annotations. Annotation will
%have form:

%\lstinputlisting[label=listenerAnnotation,caption=Annotation for
%performing action]{src/listeners/AnnotationAction.java}

%Instead of calling action listener is every method tagged with annotation.

%\lstinputlisting[label=usingListenerAnnotation,caption=Use annotation for
%performing action]{src/listeners/ButtonTest.java}

%\lstinputlisting[label=ActionListener,caption=Declaration of annotation for
%performing action]{src/listeners/ActionListenerFor.java}

%We now need a mechanism to analyze them and install action listeners. That is
%the job of the \verb|ActionListenerInstaller| class. The \verb|ButtonFrame|
%constructor calls

%\lstinputlisting[label=ActionListener,
%caption=Action Installer invocation]{src/listeners/InstallerCall.java}

%The static \verb|processAnnotations| method enumerates all methods of the
%object that it received. For each method, it gets the \verb|ActionListenerFor|
%annotation object and processes it.

%Here, we use the getAnnotation method that is defined in the
%\verb|AnnotatedElement| interface. The classes \verb|Method|,
%\verb|Constructor|, \verb|Field|, \verb|Class|, and \verb|Package| implement
%this interface. The name of the source field is stored in the annotation
%object. We retrieve it by calling the \verb|source| method, and then look up
%the matching field.

%\lstinputlisting[label=findingField,
%caption=Looking up for field]{src/listeners/FindingField.java}

%For each annotated method, we construct a proxy object that implements the\\
%\verb|ActionListener| interface and whose \verb|actionPerformed| method calls
%the annotated method. The details are not important. The key observation is
%that the functionality of the annotations was established by the
%\verb|processAnnotations| method. In Example \ref{actionListenerInstaller}, the
%annotations were processed at run time. It would also have been possible to
%process them at the source level. A source code generator might have produced
%the code for adding the listeners. Alternatively, the annotations might have
%been processed at the bytecode level. A bytecode editor might have injected the
%calls to \verb|addActionListener| into the frame constructor.
%\newpage
%\lstinputlisting[label=actionListenerInstaller,
%caption=Action Listener Installer
%class]{src/listeners/ActionListenerInstaller.java}



%*****************************************************************************
\chapter{Framework description}
\label{chap:framework}
\section{Introduction}
\subsection{Overview}
According to \cite{web:squander}, Squander is a framework providing unified
environment for both declarative constraints and imperative statements in single program. This is very practical when
implementing problems, which are easy to define but difficult to solve them
algorithmically. In such cases, declarative constraints can be natural way to
express problem, whereas imperative code is used for setting up the problem and
data manipulation.

Thanks to ability of mixing imperative code with executable declarations, it is
possible to express problem in terms of existing data structures and then run
framework solver, which according to given constraints update the heap to
reflect the solution.


Without having technology like this one, programmer has to translate his program
to external solver, then run the solver and then again manually translate the
solution back to the native programming language.

\subsection{Architecture}
We can divide running of Squander in following steps\cite{web:squander}:
\begin{enumerate}
  \item serialize heap into relations
  \item translate specs and heap relations into Kodkod
  \item translate relational into boolean logic
  \item (if a solution is found) restore relations from boolean assignments
  (if a solution is found) restore field values from relations
  \item (if a solution is found) restore the heap to reflect the solution
   
\end{enumerate}
\begin{figure}[ht]
\begin{center}
\includegraphics[width=7cm]{figures/architecture-diagram}
\caption{Architecture diagram}
\label{fig:architecture}
\end{center}
\end{figure}

Further will be explained in detail all of these steps and terms like Kodkod
etc.

\subsection{Applications}
\label{sub:apps}
In this section will be briefly described applications of framework presented
at \cite{web:squander}. Most typical applications are these:
\begin{itemize}
  \item \textbf{solving hard constraint problems} - puzzles (solitaire, sudoku,
  n-queens,\ldots), graph problems (traveling salesman problem, Hamiltonian
  path, general bisection breadth,\ldots), schedulers, dependency managers,\ldots
  \item \textbf{test input generation} - e.g. generate data structure instances
  that satisfy complex constraints
  \item \textbf{specification validation} - specifications can also contain
  errors, and the most intuitive way to test a specification would be to execute
  it on some concrete input and see if the result makes sense or not
  \item \textbf{runtime assertion checking} - check whether a given rich
  property holds at an arbitrary point during the execution of a program
\end{itemize}

On the other hand, framework has some limitations:
\begin{itemize}
  \item \textbf{boundedness} - everything has to be bounded $\rightarrow$ framework
  cannot generate an arbitrary set of new objects (which may be needed to satisfy a
  specification); instead, the exact number of new objects of each class must be
  specified by the user
  \item \textbf{small integers} - integers must also be bounded to a small
  bitwidth (to make the solving tractable), which can occasionally cause subtle
  integer overflow bugs, which are typically hard to find
  \item \textbf{equality issues} - referential equality is used by default for
  all classes except for \verb|String|, so it is impossible to write a spec that
  asserts that two objects are equal in the sense of Java \verb|equals|
  \item \textbf{lack of support for higher-order expressions} - it is not
  possible to write a specification that says \uv{find a path in the graph such
  that there is no other path in the graph longer than it} and solve it with
  Squander; it is possible, however, to express and solve \uv{find a path in the
  graph with at least k nodes}, which is computationally as hard as the previous
  problem, because a binary search can be used to efficiently find the maximum k
  for which a solution exists
 
 
\end{itemize}

\section{Execution of Squander}

Information about framework presented in this section are taken from
\cite{milicevic:executableSpecificationsForJavaPrograms}, where is
the background of Squander described in detail.

\subsection{Kodkod}
Kodkod is a solver for relational logic. Kodkod requires bounded universe, a
set of untyped relations, bounds for every relation and relation formula. Then
translates given problem into boolean satisfiability problem (SAT) and applies
of-the-shelf SAT solver to search for satisfying solution, which is reflected
back if found.

When are the relations in Kodkod created, they are untyped, meaning that every
relation can potentially contain any tuple drawn from the finite universe.
Actual set of tuples, which relation actually may contains is defined through
Kodkod \textit{bounds}:
\begin{itemize}
  \item \textit{lower bound} to define tuples, that relation \textbf{must}
  contain.
  \item \textit{upper bounds} to define tuples, which relation \textbf{may}
  contain.
\end{itemize}

The size of these bounds has a big influence on search time - the fewer tuples
are in the difference of lower and upper bound, the smaller search space is, the
faster solving is.


\subsection{JFSL}
JSFL is formal lightweight specification for Java supporting relational and set
algebra, as well as common Java operators. Using expressive power of relation
algebra, JFSL makes it easy to succinctly and formally specify complex
properties about Java programs such as method pre and postcondition, class
invariants and so called \textit{frame conditions}, which means portion of the
heap, that is methods allow to modify. It also supports \textit{specification
fields} which can be useful for specifying abstract data types. 


\subsubsection{JFSL expressions}

JFSL expressions are evaluated into relations. JFSL provides common algebra
operators, together with integer and boolean operators. Some of them are shown
in Table \ref{tab:unaryExpressions} and quantified operators, which are also
provided by the framework, are shown in Table \ref{tab:quantifiedExpressions}.


\begin{table}[ht]
  \centering
  
  \begin{tabular}{|l|l|}
  \hline
  \rowcolor[gray]{.8}    Operator  & Description  \\
  \hline
  \hline
  \verb|#| & set cardinality\\
  \hline
  \hline
  \verb|no| & \uv{no} multiplicity (empty)\\ 
  \hline
  \verb|lone|  & \uv{lone} multiplicity (zero or one)\\ 
  \hline
  \verb|one| & \uv{one} multiplicity (exactly one) \\ 
  \hline
  \verb|some| & \uv{some} multiplicity (one or more) \\ 
  \hline
  \verb|!| & boolean negation \\ 
  \hline
  \verb|-| & integer negation \\ 
  \hline
  \verb|sum| & integer summation \\ 
  \hline
  \hline
  \verb|=>| & boolean implication \\ 
  \hline
  
  \verb|<=>| & boolean equivalence (\uv{if and only if}) \\ 
  \hline
  \hline
  \verb|?| & if-then-else ternary operator (as in Java) \\ 
  \hline
  \hline
  \verb|@+| & relational union \\ 
  \hline
  \verb|@-| & relational difference \\ 
  \hline
  \verb|@&| & relational intersection \\ 
  \hline
  \end{tabular}
  \caption{Unary expressions supported by JFSL}
  \label{tab:unaryExpressions}
\end{table}

\begin{table}[ht]
  \centering
  
  \begin{tabular}{|l|l|l|}
  \hline
  \rowcolor[gray]{.8}    Operator  & Description  & Usage\\
  \hline
  \hline
  \verb|all| & universal quantifier & \verb#all x: T | P(x)#\\
  \hline
  \verb|some| & existential quantifier & \verb#some x: T | P(x)#\\ 
  \hline
  \verb|sum|  & integer summation & \verb#sum i: int | a[i]#\\ 
  \hline
  \verb|union| & set comprehension & \verb#{x: T | P(x)}#\\ 
  \hline
  
  \end{tabular}
  \caption{Quantified expressions supported by JFSL}
  \label{tab:quantifiedExpressions}
\end{table}
\newpage
\subsubsection{JFSL annotations}
JFSL annotations are written as Java annotations and are for interaction
between framework and programmer. Main components (JFSL annotations) are:

\begin{itemize}
  \item \verb|@Invariant| - this annotation is attached to the classes and used
  to define, that condition must be fulfilled for the given class. That means,
  that this condition has to be fulfilled before and after execution.
  
  \item \verb|@Requires| -  this annotation specifies constraints before method
  invocation. The method is expected to execute correctly if only the
  precondition is satisfied immediately before method invocation. Class
  invariants are added immediately to the method preconditions.
  \newpage
  \item \verb|@Ensures| - attached to the methods and used to specify
  constraints on the state, which have to be satisfied after method invocation.
  It means, that it captures all effect that method is expected to produce.
  Class invariants are implicitly added to method postconditions.
  
  \item  \verb|@Modifies| - this annotation is attached to the methods to
  specify frame conditions. Frame condition can hold up 4 different pieces of
  specification (syntax: \verb|@Modifies| \verb|("f [s][l][u]")|). First, and
  the only one mandatory piece, is the name of modifiable field, \verb|f|. It is
  optionally followed by \textit{instance selector} \verb|s|, followed by
  \textit{lower bound} and the \textit{upper bound}. Instance selector specifies
  instances, for which the field may be modified - if not specified, it is
  assumed \uv{all}. The lower bound contains concrete field values for some
  objects in the post-state. The upper bound holds the possible field values in
  the post-state.
  
  \item \verb|@SpecField| - attached to the classes and used to define
  specification fields. Definition of type specification consists of type
  declaration, and optionally an abstract function. the abstraction function
  defines, how the field value is computed in terms of other fields. For example
  \verb#@SpecField("x: one int| x = this.y - this.z")#  defines a singleton
  integer field \verb|x|, the value of which must be equal to the difference of
  \verb|y| and \verb|z|. Specifications fields are inherited from super-types
  and sub-types can override the abstraction function (by simply redefining
  it), a feature that is particularly useful for specifying abstract datatypes,
  such as Java collections.
  
  

  
\end{itemize}

In context of these specification, the goal is to execute a method, that makes
modification of the portion of the heap (specified in frame condition), so that
final state satisfies postcondition.

\subsection{From object heap to relational logic}

Execution of Squander begins in client's code when invoking
method \verb|Squander.exe()| involving following steps:

\begin{enumerate}
  \item Assembling all relevant constraints from annotations, as well as class
  annotations corresponding to all invariant classes.
  \item Construction relations representing objects and their fields in
  pre-state and adding additional relations for holding their values in the
  post-state, along with their Kodkod bounds
  \item Parsing constraints and converting them to a single relational formula
  \item If solution is found, translation of the Kodkod result objects into
  updates of Java heap state, by modification of the object fields
\end{enumerate}

\subsubsection{Traversing the heap}

For discovering reachable portion of the heap, bread-first search algorithm is
used, which started from the set of root objects and repeatedly visiting all
children until all reachable objects have been visited. The most important part
is how to enumerate children, i.e. how to serialize a given object into a set of
field values.

\subsection{Relations and bounds}
After traversing the heap, founding all reachable objects and
discovered all classes/-fields reffered in the specification, we have enough
information to construct the relation, that represent state of the heap.

The translation does not used all fields, but only those, whose are considered
as \textit{relevant fields} - those, who are explicitly mentioned in the
specification (Squander's annotation). Similarly, not all reachable objects are
needed; only objects reachable by following the relevant fields are included in
the translation. These objects will be referred to as \textit{literals}.

First we define a finite universe consisting of all literals, plus integers within the
bound. For every literal, a unary relation is created.

For each Java type, one could either create a new relation (with appropriate
bounds so that it contains the known literals), or one could construct a relational
expression denoting the union of relations corresponding to all instance literals of that
type.


For every field, a relation of type
\verb|fld|$.declType \rightarrow$ \verb|fld|$.type$ is created to hold
assignments of field values to objects. If the field is modifiable (inferred
from its mention in a \verb|@Modifies| clause), an additional relation is
created, with the suffix \uv{pre} appended to denote the pre-state value.
Relations for unmodifiable fields are given an exact bound that reflects the
current state of the heap. For the modifiable relations, the \uv{pre} relation
is given the same exact bound, and the “post” relation is bounded so that it may
contain any tuple permitted by the field's type. Local variables, such as
\verb|this|, \verb|return|, and method arguments are treated similarly to
literals.

\newpage

Table \ref{tab:translationsToRelations} below summarizes how relations and
bounds are created. Function \verb|rel| takes a Java element and, depending
whether the element is modifiable, returns either one or two relations. Function
\verb|bound| takes a Java element and its corresponding relation, and returns a
bound for the relation. The \verb|Bound| data type contains both lower and upper
bounds. If only one expression is passed to its constructor (\textbf{B}), both
bounds are set to that value. Helper functions \verb|is_mod|, \verb|is_post|
and \verb|fldval| are used to check whether a field is modifiable, to check
whether a relation refers to the post-state, and to return a literal that
corresponds to the value of a given field of a given literal, respectively.


\begin{table}[ht]
  \centering
  
  \begin{tabular}{|l|l|l|}
  \hline
  \rowcolor[gray]{.8}   \textbf{rel} :: Element $\rightarrow [$Relation$]$\\
  \hline
  \hline
  
  \textbf{rel} (Literal lit) \hspace{31mm} $=$ \hspace{2mm} $
  [$\textbf{R}(lit.$name$, lit.$type$)$]$ \\
  \textbf{rel} (Type t)\hspace{37mm} $=$ \hspace{2mm} $ 	\bigcup_{lit<:t}$
  \textbf{rel} lit\\ \textbf{rel} (Field fld) \hspace{33.1mm} $=$ \\
\hspace{2mm}	\textbf{if} is\_ mod(fld)\\
\hspace{10mm} $[$\textbf{R}(fld.$name$, fld.$declType \rightarrow
$fld.$type$)$]$ ++\\ 
\hspace{10mm} $[$\textbf{R}(fld.$name$ + \_pre, fld.$declType \rightarrow
$fld.$type$)$]$\\ 
\hspace{5mm} \textbf{else}\\
\hspace{10mm} $[$\textbf{R}(f.$name$, f.$declType \rightarrow $f.$type$)$]$\\
\textbf{rel} (Local var)\hspace{34mm} $=$ \hspace{2mm} $
[$\textbf{R}(var.$name$, var.$type$)$]$\\
 
  \hline
  \hline
  \rowcolor[gray]{.8}   \textbf{rel} :: Element, Relation $\rightarrow
  [$Bound$]$\\
  \hline
  \hline
  
  \textbf{bound} (Literal lit) (Relation r) \hspace{5.2mm} $=$ \hspace{2mm} 
  \textbf{B}(lit) \\
  \textbf{bound} (Field f) (Relation r) \hspace{10mm} $=$ \\ 
  \hspace{5mm}	\textbf{if} is\_ mod(fld) $\wedge$ is\_post(r)\\

\hspace{10mm} $[$\textbf{B}(\{\}, ext(fld.$declType \times
$fld.$type$))$]$\\ 

\hspace{5mm} \textbf{else}\\
\hspace{10mm} $[$\textbf{B}($ 	\bigcup_{lit<:Object}$
  \textbf{rel} lit $\times$ fldval(lit,fld))$]$\\\textbf{bound}
  (Return ret) (Relation r)\hspace{5mm} $=$ \hspace{2mm} $[$\textbf{B}(\{\},
  ext(ret.$type$))$]$\\
 \textbf{bound}
  (Local var) (Relation r)\hspace{7mm} $=$ \hspace{2mm} $[$\textbf{B}(var)$]$\\
  \hline
  \hline
  \rowcolor[gray]{.8}   $[$Type$]$ $\rightarrow$
  Expression \hspace{40mm} (hepler)\\
  \hline
  \hline
  
  \textbf{ext} $[]$ \hspace{49.5mm} $=$ \hspace{2mm} \{\}\\ 
  \textbf{ext} (t:$[]$)  \hspace{44mm} $=$ \hspace{2mm} $ \bigcup_{lit<:t}$
  lit\\ \textbf{ext} (t:xs) \hspace{42.5mm} $=$ \hspace{2mm} \textbf{ext} t
  $\times$ \textbf{ext} xs\\
  \hline
  
  \end{tabular}
  \caption{Translation of different Java constructs into relations (function
  \texttt{rel}) and bounds (function \texttt{bound})}
  \label{tab:translationsToRelations}
\end{table}

\newpage
\subsection{Example: translation of \texttt{BST.insert}}
\label{sub:translation}
We will use for illustration of translation Binary Search Tree example. This BST
has single root node. Every node contains integer key value and pointer to the
left and right node. To verify validity of BST, some Squander's specifications
are used (see Listing \ref{bst}). \verb|@SpecField| constraint declares, that
set of BST nodes consist of root node and all nodes in left and right subtree of this root node except
for \verb|null| values. Another constraints represented by \verb|@Invariant|
annotation declares: (1) there are no loops in BST - using transitive closure to
define, that actual node is not accessible transitively via field \verb|parent|
- and (2) and for every node $n$ in the BST, the $key$ of $n$ is strictly greater,
than all keys of all nodes in the left subtree and strictly lower than all keys
of all nodes in its right subtree - there is used reflexive transitive closure
operator (\verb|.*|) to conveniently specify all reachable nodes starting from
the root node.


\lstinputlisting[label=bst,caption=Binary Search Tree
declaration]{src/bst/BST.java}

Methods for modifying tree, \verb|insert()| and \verb|remove()| shown in
Listing \ref{operation} are obvious. In order to insert node into tree, node
with same key may not exist in the tree, and after the insertion, tree must
contain the given node. All left and right pointers of nodes and pointer to root
node are allowed to modify. Deletion is defined in similar way, BST must contain node
with the same key as node to remove and after deletion this node may not exist
in BST.
\newpage
\lstinputlisting[label=operation,caption=Operations on
BST]{src/bst/Operations.java}

The resulting set of relations, shown in Table \ref{fig:translationTable}, are
divided into three sections. Relations in the upper section are unary, unmodifiable relations,
and represent objects on the heap. The middle section contains relations that
are also unmodifiable, because they are used to either represent unmodifiable
fields or values in the pre-state of modifiable fields. Finally, the relations
in the bottom section represent the post-state of modifiable fields; these are
the relations for which the solver will attempt to find appropriate values. By
default, the lower bound is simply set to an empty set and the upper bound is
the upper bound is set the extent of the field's type.


\begin{figure}[ht]
\begin{center}
\includegraphics[width=4cm]{figures/bst}
\caption{A snapshot of \texttt{t1.insert(t4)}}
\label{fig:bstInsert}
\end{center}
\end{figure}

\newpage


\begin{table}[ht]
\begin{center}
\begin{tabular}{ l l }
	\textbf{BST}: & $\{t_1\}$\\
	\textbf{N1}: & $\{n_1\}$\\
	\textbf{N2}: & $\{n_2\}$\\
	\textbf{N3}: & $\{n_3\}$\\
	\textbf{N4}: & $\{n_4\}$\\
	\textbf{null}: & $\{null\}$\\
	\textbf{BST\textsubscript{--}this}: & $\{t_1\}$\\
	\textbf{z}: & $\{n_4\}$\\
	\textbf{ints}: & $\{0, 1, 5, 6\}$\\
  \hline
  	\textbf{key}: & $\{(n_1\rightarrow 5),(n_2\rightarrow
	0),(n_3\rightarrow 6),(n_4\rightarrow 1)\}$\\
	\textbf{root\textsubscript{--}pre}: & $\{(t_1\rightarrow n_1)\}$\\
	\textbf{nodes\textsubscript{--}pre}: & $\{(t_1\rightarrow n_1),(t_1\rightarrow
	n_2),(t_1\rightarrow n_3),(t_1\rightarrow n_4)\}$\\
	\textbf{right\textsubscript{--}pre}: & $\{(n_1\rightarrow n_2),(n_2\rightarrow
	null),(n_3\rightarrow null),(n_4\rightarrow null)\}$\\
	\textbf{left\textsubscript{--}pre}: & $\{(n_1\rightarrow n_3),(n_2\rightarrow
	null),(n_3\rightarrow null),(n_4\rightarrow null)\}$\\
	\hline
	\textbf{root}: & $\{\},\hspace{4mm}\{t_1\}\times\{n_1,n_2,n_3,n_4\}$\\
	\textbf{nodes}: & $\{\},\hspace{4mm}\{t_1\}\times\{n_1,n_2,n_3,n_4\}$\\
	\textbf{left}: &
	$\{\},\hspace{4mm}\{n_1,n_2,n_3,n_4\}\times\{n_1,n_2,n_3,n_4\}$\\
	\textbf{right}: &
	$\{\},\hspace{4mm}\{n_1,n_2,n_3,n_4\}\times\{n_1,n_2,n_3,n_4\}$\\
	
\end{tabular}
\end{center}
\caption{Translation of the heap from Figure \ref{fig:bstInsert}}
\label{fig:translationTable}
\end{table}

\subsection{Tightening the bounds}
By declaring as modifiable fields \verb|left| and \verb|right|, as in the
specification in \ref{bst}, we allow arbitrary modifications to the tree, as
long as all constraints are satisfied. In effect, after the execution of the
specification for the \verb|insert()| method, the tree will contain all old
nodes plus the new node, but the shape of the tree may randomly change.

If we want to change method specification so, that tree topology is preserved
and new nodes can be append only to leaf nodes, we can do that by adding new
clauses to the postcondition specification in sense, that left and right
pointers of certain nodes must remain the same in the post state. This idea is
completely right, but more efficient would to change the frame condition also
for improving performance. Reducing search space by allowing modification only
\verb|left| and \verb|right| pointers pointing to \verb|null| value improve
performance significantly.

Consider modified frame condition shown in Listing \ref{modifiedOperation}
specifying additional constraints on the modification of \verb|left| and \verb|right| fields. This
frame condition shows idea specified in paragraph before and ensures, that all
new nodes will be inserted at the leaf positions.

\lstinputlisting[label=modifiedOperation,caption=Modified
frame condition on \texttt{insert()} method]{src/bst/ModifiedOperations.java}

With the list of modifiable objects, Squander modifies the bounds for the
corresponding field relation so that the current field values of the objects not
to be modified are included in the lower bound, thus forcing the value to stay
the same in the post state. For the heap shown in Figure \ref{fig:bstInsert},
the modifiable objects for the \verb|left| field are \verb|n2| and \verb|n3|,
because their left pointers are currently set to null. Similarly, for the
\verb|right| field, the modifiable objects are also \verb|n2| and \verb|n3|. The
updated bounds for these two fields are shown in Table \ref{fig:updatedBounds}.


\begin{table}[ht]
\begin{center}
\begin{tabular}{ l l }
	\textbf{left}: &
	$\{(n_1\rightarrow
	n_2),(n_4 \rightarrow
	null)\},\hspace{4mm}(n_1 \rightarrow n_2)\cup(n_4 \rightarrow
	null)\cup \{n_2,n_3\}\times\{n_1,n_2,n_3,n_4\}$\\ 
	\textbf{right}: &
	$\{(n_1\rightarrow
	n_3),(n_4 \rightarrow
	null)\},\hspace{4mm}(n_1 \rightarrow n_3)\cup(n_4 \rightarrow
	null)\cup \{n_2,n_3\}\times\{n_1,n_2,n_3,n_4\}$\\
	
\end{tabular}
\end{center}
\caption{The updated bounds for the \texttt{left} and \texttt{right} relations}
\label{fig:updatedBounds}
\end{table}

\subsection{Minimizing the universe size}
\label{sub:minUniverse}
For representing relations in Squander are used single sequential arrays indexed
by Java integer. Maximal count of members in this array is \verb|Integer.MAX_VALUE| which is
$2147483647$. In practice this can be a problem, because framework for relation
of arity $k$, which has $n$ atoms in the universe (later it will be described,
what is exactly meant under this term), allocates matrix of size $n^k$ (when
ternary relation contains more than 1290 atoms). Heap with more than 1290
objects are not uncommon, so a simple translation described in
\ref{sub:translation} would not work. In the next subsection will be described a
different translation technique called \textit{KodkodPart}, which was developed
to minimize number of atoms representing object heap.

\subsubsection{\textit{KodkodPart} translation}
\label{sub:kodkodpart}
KodkodPart translation achieves a universe with fewer atoms by mapping
Java objects to Kodkod atoms (not injective mapping). That means that multiple
literals are mapped to a single atom, so that there will be fewer atoms than
literals. The key requirements is, that there exists some inverse function,
which maps back from the atoms literals.

Considering previous example with BST (see Subsection \ref{sub:translation}), we
can define domains $\mathcal{D}$, literals $\mathcal{L}$ and assignment literals to domains
$\gamma : \mathcal{D} \rightarrow \mathcal{P}\left(\mathcal{L}\right)$ for this
example, which is summarized in Table \ref{tab:summaryDomainsLiterals}.

\begin{table}[ht]
\begin{center}
\begin{align*}
	\mathcal{D}& =\{\texttt{BST},\hspace{1mm} \texttt{Node},\hspace{1mm}
	\texttt{Null}, \hspace{1mm} \texttt{Integer}\}\\ 
	\mathcal{L}& =\{bst_1,\hspace{1mm} n_1,\hspace{1mm} n_2,\hspace{1mm}
	n_3,\hspace{1mm} n_4, \hspace{1mm} null,\hspace{1mm} 0,\hspace{1mm} 1,\hspace{1mm} 5,\hspace{1mm} 6\}\\
	\gamma\left(\texttt{BST}\right)& = \{bst_1\}\\
	\gamma\left(\texttt{Node}\right)& =
	\{n_1,\hspace{1mm}n_2,\hspace{1mm}n_3,\hspace{1mm}n_4\}\\
	\gamma\left(\texttt{Null}\right)& =
	\{null\}\\
	\gamma\left(\texttt{Integer}\right)& =
	\{0,\hspace{1mm}1,\hspace{1mm}5,\hspace{1mm}6\}\\
\end{align*}
\end{center}
\caption{Summary of domains and instances for the \texttt{BST.insert} example}
\label{tab:summaryDomainsLiterals}
\end{table}

Recall that field types are represented as unions of base types (in this section also
called \textit{partitions}). For instance, the type of the field \verb|BST.root|
is \verb|BST| $\rightarrow$ \verb|Node| $\cup$ \verb|Null|, because values of
this field can be either instances of \verb|Node| or the \verb|null| constant.
That means that all objects of class \verb|Node| plus the constant \verb|null|
must be mapped to different atoms, so that it is possible to unambiguously
restore the value of the field \verb|root|. This is the basic idea behind the
KodkodPart translation: \textit{all literals within any given partition must be
mapped to different atoms, whereas literals not belonging to a common partition may
share atoms}. The inversion function can then work as follows: for a given atom,
first select the correct partition based on the type of the field being
restored, then unambiguously select the corresponding literal from that
partition. To complete the example, the set of all unary types used in the
specification for this example is:

\begin{center}
\begin{align*}
	\mathcal{T}& =\{\texttt{BST},\hspace{1mm}
	\texttt{BST}\cup\texttt{Null},\hspace{1mm} \texttt{Node},\hspace{1mm}
	\texttt{Node} \cup \texttt{Null}, \hspace{1mm} \texttt{Null},\hspace{1mm} \texttt{Integer}\}\\
\end{align*}
\end{center}

Set presented above is set of our partitions. A valid assignment of
atoms to literals that uses only 5 atoms, as opposed to 10 which is how many the
original translation would use, could be:

\begin{center}
\begin{tabular}{|l|l|l|l|l|}
  \hline
  $bst_1 \rightarrow a_0$ & $n_1 \rightarrow a_0$ & $n_2 \rightarrow a_1$ & $n_3
  \rightarrow a_2$ & $n_4 \rightarrow a_3$\\
  \hline
  $null \rightarrow a_4$ & $0 \rightarrow a_0$ & $1 \rightarrow a_1$ & $5
  \rightarrow a_2$ & $6 \rightarrow a_3$\\
  \hline
  \end{tabular}
\end{center}

Limitation of this technique is when the class \verb|Object| is used as a field
type or anywhere in the specification. This lead to one big partition containing
all literals (because every class is a subclass of \verb|Object|), making the
algorithm equivalent to the original translation.

\subsubsection{Partitioning algorithm}
For a given set of base domains $\mathcal{D}$, literals $\mathcal{L}$, and
partitions $\mathcal{T} \left( \mathcal{T} = \mathcal{P}\left( \mathcal{D} \right) \right)$, and a given function $\gamma : \mathcal{D} \rightarrow \mathcal{P}\left( \mathcal{L} \right)$ that maps domains to their instance
literals, this algorithm produces a set of atoms $\mathcal{A}$ and a function $\alpha : \mathcal{L} \rightarrow \mathcal{A}$, such that for every partition
$p$, function $\alpha$ returns different values for all instance literals of
$p$. Formally:

$$\left(\forall p \in \mathcal{T}\right)\left(\forall l_1,l_2 \in
\psi\left(p\right)\right) l_1 \neq l_2 \Longrightarrow \alpha
\left(l_1\right)\neq \alpha \left(l_2\right)$$


where $\psi$ is a function that for a given partition returns a comprehension of
all instance literals of all of its domains:


$$\psi : \mathcal{T}\rightarrow \mathcal{P} \left(\mathcal{L}\right);
\hspace{2mm} \psi\left(p\right) = \{\gamma\left(d\right)\mid d \in p\}$$

Obviously, a simple bijection would satisfy this specification, but such a solution
wouldn't achieve its main goal, which is to minimize the number of atoms, because
the number of atoms in this case would be exactly the same as the number of literals.
In order to specify solutions that are actually useful, we are going to require the
algorithm to produce a result, such that the cardinality of $\mathcal{A}$ (i.e.
the total number of atoms) is minimal.

It is not immediately clear what the minimal number of atoms ought to be. One
might think that no more atoms are required than the number of instances in the
largest partition. However, this is not always true. Consider the case shown in
Figure \ref{fig:kodkodpart}. The largest partitions are \verb|P1| and \verb|P4|,
both having 5 literals. On the other hand, any pair of the domains \verb|B|, \verb|C|, and
\verb|D| have a partition in common, even though there is no single partition
containing them all. They thus form a strongly connected component, and their literals must differ. There are 6 literals in total in
these three domains, so 5 atoms cannot be enough. As a conclusion, the minimal
number of atoms is indeed the number of literals in the largest partitions, but only
after all strongly connected domains have been merged into a single partition.


\begin{figure}[ht]
\begin{center}
\includegraphics[width=8cm]{figures/kodkodpart}
\caption{KodkodPart: an example where more than the number of literals of the
largest partition is needed.}
\label{fig:kodkodpart}
\end{center}
\end{figure}

Luckily, cases like the one in Figure \ref{fig:kodkodpart} never happen in
Squander, so our implementation of the algorithm doesn't have to search for
cliques and merge partitions. The reason this never happens is that domains are
always Java classes, and partitions are types used to represent fields. A type
of a field is a union type which includes the entire subclass hierarchy of the
field’s base type. For instance, if \verb|C| and \verb|D| are Java classes,
\verb|C| extends \verb|D (C <: D)|, and some field has declared type \verb|D|,
then the type of the field (in the relational world) will be \verb|D| $\cup$
\verb|C| $\cup$ \verb|Null|, meaning that \verb|D| $\cup$ \verb|Null| is
never going to be used as a partition for anything.

In summary, the actual implementation inside Squander works as follows:


\begin{enumerate}
  \item Dependencies between domains are computed. A domain depends on all
  domains with which it shares a partition. Let the function $\delta :
  \mathcal{D} \rightarrow \mathcal{P}\left(\mathcal{D}\right)$ express this:
  
  $$\delta\left(d\right) = \{d_1 \mid d_1 \neq d\ \wedge
  \left(\left(\exists p \in \mathcal{T}\right)d_1 \in p\wedge d \in p\right)\}
  $$
  \item The largest partition $p_{max}$ is found, such that
  $$\left(\nexists p\in \mathcal{T}\right) \abs{\psi\left(p\right)} >
  \abs{\psi\left(p_{max}\right)}$$
  \item For every literal $l$ in $\psi\left(p_{max}\right)$ an atom a is
  created, it is added to the universe $\mathcal{A}$ and assigned to $l$, such
  that $\alpha\left(l\right) = a$. From this point onwards, $\mathcal{A}$ is fixed.
  \item For every other partition $p$ iteratively, for all literals $l_p \in p$
  that do not already have an atom assigned, a set of possible atoms
  $\mathcal{A}_{lp}$ is computed and the first value from this set is assigned
  to $l_p$. $\mathcal{A}_{lp}$ is computed when atoms corresponding to all literals of all
  dependent domains is subtracted from $\mathcal{A}$, i.e.:
  \newpage
  
  $$\mathcal{A}_{lp} = \mathcal{A} \setminus \{\alpha\left(l\right)\mid
  l\in\mathcal{L}_d\} \text{, where}$$
  
  $$\mathcal{L}_d = \{\gamma\left(d\right)\mid
  d\in\mathcal{D}_d\} \text{, where}$$
  
  $$\mathcal{D}_d = \delta\left(d_l\right) \text{, where } d_l\in\mathcal{D}
  \wedge l_p \in \gamma\left(d_l\right)$$
\end{enumerate}

\section{From bounded relational logic to SAT}
How does translating from relational logic to boolean logic works is described
in detail in Torlak's Phd. thesis \cite{torlak:constraintSolver}. I will
occupy with this issue no longer, because it is out of scope of this thesis.


\section{Differences between Prolog and framework}

Thing, which have both classical logic programming in Prolog and
programming using framework Squander in common, is defining what to compute
instead of how. Both programming paradigms use set of rules for its computation,
but here the analogy ends.

If we study Prolog and Squander more in depth, we can see, that there is
significant difference in declaring input data. Whereas Squander is strongly
connected to its Java data structures, Prolog use set of facts, as was
mentioned in Chapter \ref{chap:logProgPrinc}.


Both Prolog and Squander use set of rules for its computation. If we want to
compute some variable in Prolog, language go recursively through all rules,
matching the input using rewriting clauses, until all of them are replaced by
valid facts and we do not care about order of evaluation (no flow control).
Prolog uses three types of formula. \textit{Atomic} formulas declares basic
facts, \textit{conditional commands} are used for implication constructs and
finally, \textit{target clauses} form query types.


To incorporate Squander into Java annotations are used. For solving some
algorithm, annotation \verb|@Requires|,\verb|@Ensures| and \verb|@Modifies| are
mostly used. First one, \verb|@Requires|, is used for declaring requirements for
input data before method \verb|Squander.exe()| is invoked. Annotation
\verb|@Ensures| defines how the data structures should look like after method
execution. Last one, \verb|@Modifies|, tells framework class objects or object's
fields can be modified during execution. This is very important declaration
for the performance of the computation in particular. If we define this
annotation optimally, we minimize search space and speed up solving. Calculation
itself is done by translating object heap into relations. Then are these
relations transformed into SAT problem, which is then solved and the solution,
if exists, is reflected back to the heap.
%*****************************************************************************
\chapter{Implementation of algorithms}

\section{Introduction}
As was mentioned before, framework Squander is suitable for implementation of
algorithms, which are easy to specify, but difficult to implement imperatively.
For this reason I implemented algorithms belonging to NP problems. Problem is
said that belongs to the set of NP problems if it is solvable in polynomial
time on nondeterministic Turing machine \cite{schmidt:paa}. There is one more
expression to explain for description of NP problems - \textit{nondeterministic Turing
machine}. First of all we have to define deterministic Turing machine, which for
given set of rules prescribes at most one action to be performed for any given
situation. Whereas nondetermistic Turing machine is machine, that for given set
of rules prescribes more than one action. We can imagine, that in every step of
computation is Turing machine cloned in nondeterministic Turing machine.

Most of the algorithm I tried to implement are NPO (especially graph
algorithms), but there is a little problem with Squander. It does not support
higher-order expressions (Subsection \ref{sub:apps}). Unfortunately it is not
possible to write a specification that says \uv{find a path in the graph such
that there is no other path in the graph longer than it} and solve it with
Squander; it is possible, however, to express and solve \uv{find a path in the
graph with at least k nodes}, which is computationally as hard as the previous
problem, because a binary search can be used to efficiently find the maximum k
for which a solution exists. Due that restriction are all of the optimizations
algorithms implemented in such way, that there is some treshold level, which
solution has to satisfy.


All in all, Squander should be able to solve all NP problems, because it
transforms everything into SAT problem \cite{schmidt:paa}, which is NP-complete
(Cook's theorem) problem and every NP problem is transferable into NP-complete problem.
\section{Knapsack Problem}

\subsection{First version}
At the beginning when I started \uv{playing} with Squander, I tried to
implement optimization variant of well known algorithm Knapsack. This algorithm
is usually introduced, that there is burglar with knapsack inside some estate and he has to steal
as many things as capacity of his knapsack allowed to him with highest price. 

This problem is also sometimes called the easiest one from NP-hard problems. If
we try to solve it by brute force, we get an exponential time complexity. But
there are more than one way how to solve this problem with different complexity.
E.g. by using dynamic programming we get pseudo-polynomial time complexity,
which means that time complexity is depends not only on input data but also on
another variable.

By using Squander's method specification it was pretty easy to declare
annotations for computation. Firstly it was necessary to prepare data
structures. In this case I implement class \verb|KnapSack.java|, which has
following properties:

\begin{itemize}
  \item \textit{integer array c} - costs of particular things in knapsack
  \item \textit{integer array v} - weights of particular things in
  knapsack
  \item \textit{integer n} - number of things in knapsack
  \item \textit{integer capacity} - capacity of knapsack (measured in weight
  units)
\end{itemize}

That is all information we need to know about object \verb|Knapsack|. Important
thing is to define some treshold - in our case it will be total cost of things
in knapsack, which we pass as parameter. Now we have to define some Squander's
specification. Firstly we make a decision, if configuration of things will be returned as a new array or
if we pass some array as a method parameter. Let us try to choose first option.
This option is connected with annotation \verb|@FreshObjects|, which is used to
define, which type of object will be returned from \verb|Squander.exe()|
method, so one instance of the object \verb|Integer| array should be created on
the heap specifying which things are in the knapsack (value $1$) and which not
(value $0$). After these steps, our method specification looks like this:

\lstinputlisting[label=knapSack1,caption=Declaration of return type of
\texttt{Squander.exe()} method]{src/knapsack/KnapSack1.java}

After that we define some constraints, that help reduce search space. Question
that we must ask is what objects or fields of which classes are allowed to
be modified. Costs and weights are same during computation, similarly capacity
and count of things in knapsack. The only structure that has to be modifiable is
return array of \verb|Integers|. According to Squander's documentation we have
to declare via annotation \verb|@Modifies|, that both length and elements of
returned array are modifiable:

\lstinputlisting[label=knapSack2,caption=Definition of modifiable objects on
\texttt{Squander.exe()} method]{src/knapsack/KnapSack2.java}

The next step is to decide if we have some requirements on input data. We can
see that this data are quite enough restricted by its own data type so we do not
use annotation \verb|@Requires|, which is used to define some prerequisites for
the execution. Let us continue with specification what we expected as a result
of computation. 

So the last thing we have to specify is method output. At first come definition,
that total weight of the all things in knapsack has to be smaller or equal to
the knapsack capacity:

\lstinputlisting[label=knapSack3,caption=Declaration of knapsack capacity
constraint on \texttt{Squander.exe()} method]{src/knapsack/KnapSack3.java}

Then it is necessary to specify, that total cost of things in knapsack has to be
greater than variable \verb|minCost|, which is passed as method parameter:

\lstinputlisting[label=knapSack4,caption=Declaration of knapsack total cost
constraint on \texttt{Squander.exe()} method]{src/knapsack/KnapSack4.java}

It is obvious, that Squander use keyword \verb|this| in similar way as Java.
Finally we make a specification, that length of return \verb|Integer| array has
to be \verb|n| and that values of that arrays have to be from set $\{0, 1\}$:

\lstinputlisting[label=knapSack5,caption=Declaration of parameters of returned
array on \texttt{Squander.exe()} method]{src/knapsack/KnapSack5.java}

Knapsack problem is now completely implemented but let us think about possible
improvements. When thinking about improvement, we should concentrate on
modifiable object, which is returned \verb|Integer| array. In this case we get
by with array of Boolean values, which shrinks variable domain as much as possible
and limit the search space. We have declared constraint in \verb|@Ensures|
annotation, that values of returned array are in set $\{0, 1\}$, but this
constraint does not limit search space. Due that change, we should also modify
declaration of constraints describing minimal cost and capacity of knapsack. It
is necessary also modify \verb|@FreshObject| annotation to Boolean data type.
\newpage
\lstinputlisting[label=knapSack6,caption=Improving
implementation of Knapsack using Boolean data type]{src/knapsack/KnapSack6.java}

Now we have implement Knapsack problem in advanced way and it is time for
testing, if it works correctly. During testing I used instances for which I
know the \verb|bestPrice| solution and for a treshold \verb|minCost| I used
value equals to \verb|bestPrice - 1|.

At first was the implementation tested on smaller instances consisting of 4
things. From 45 examples was one failed, when Squander returns configuration,
which was overweight. Moreover when was minimal cost greater or equal to
$512$, program fails on error\\ 
\verb|Arity too large (3) for a universe of size 2048|. We know from Chapter
\ref{chap:framework}, Subsection \ref{sub:kodkodpart} that Squander used for
representing relation array indexed by Java integer. Due to size of the universe
$2048^3 = 8589934592$ which is greater than \verb|Integer.MAX_VALUE| (=
$2147483647$) is Squander unable to represent relation. Why does this happen? If
is in the specification \verb|minCost| greater or equal to $512$ and lower than
$1023$, Squander automatically uses $11$ bits to represent \verb|Integers|,
which gives a scope $\langle-2^{10},2^{10}) = \{-1024,\ldots,1023\} = 2048$ \verb|Integers| and as was
mentioned in Subsection \ref{sub:minUniverse}, these ternary relations cannot be
mapped into \verb|Integer| indexed array $(2048^3 > 2147483647)$. Another
problem comes in, when the variable \verb|minCost| is set to $511$. Then
Squander uses bitwidth $10$, which means $\langle-2^9,2^9) =
\{-512,\ldots,511\}$ and that is why it is unable to find solution, which is $512$ so not in the scope,
and throws \verb|noSolutionException|. Similar problem appears, when is integer
\verb|minCost| set to another value $2$ powered by $n\in\mathbb{N}$ and then
subtracted by $1$.

We can see from the measurement, that this implementation of knapsack
using Squander is for this type of problem quite unsuitable.

\subsection{Second version}

In order to reduce search space, I tried to implement another version of
knapsack problem. Let us think about things in knapsack as an entity, not as a
configuration variable in array. By using this way of thinking, we get reduced
count of atoms in Squander, because now we have only one set of objects \verb|Thing| but in the
first version of implementation there were two arrays of the same data type
(\verb|Integer| array \textit{c} and \verb|Integer| array \textit{v} same size
as set of things we have now), which drastically increase number of atoms.
Fields of entity \verb|Thing| look like this:

\begin{itemize}
  \item \textit{integer c} - cost of actual thing
  \item \textit{integer v} - weight of actual thing
  \item \textit{boolean choosed} - symptom if is choosed
  \item \textit{integer position} - this variable is used for sorting the
  output, because instances of \verb|Thing| are in \verb|java.util.Set|
  (for performance reasons)
\end{itemize}

For a specification of Squander, we create \verb|Set| of objects \verb|Thing|,
allowing to modify only \verb|boolean choosed| symptom. Summation logic is the
same as in first version and variable \verb|position| is used for sorting
resulted set of object in order to have better interpretation of the solution.

In this example we use experience from the previous one and declare variable
\verb|minCost| as the real maximum cost of possible solution and write it to the
specification (sum of cost should be equal to \verb|minCost|), so best
solution value will not disappear in higher \verb|Integer| bitwidth. On the
other hand, this implementation is not very usable, because we almost always do
not know exact highest total price.

\lstinputlisting[label=knapSack7,caption=Improving
implementation of Knapsack using previous
experince and reducing count of relations]{src/knapsack/KnapSack7.java}

This way of implementation is suitable for instances with more things in
knapsack, which means higher value of variable \verb|capacity| and higher value
of variable \verb|minCost|, because there are not so many relations created.
Implementation was successfully tested for $40$ things in one instance at most.

\section{General bisection breadth}

\subsection{First version}

\label{sec:gbb}
This problem is taken from course \textit{Parallel Algorithms and Computing}
\cite{tvrdik:par} lectured at Faculty of Electrical Engineering of Czech
Technical University in Prague (CTU FEE). It is a graph algorithm and task for that algorithm is to find
two groups of nodes - number of nodes in one group is exactly define - such, that
number of edges connecting these two groups is minimal. Exact definition is:

\begin{center}
\uv{Find distribution set of $n$ nodes into to two disjoint groups $X$, $Y$
such, that set $X$ contains $a$ nodes, set $Y$ contains $n-a$ nodes and count of edges
$\{u,v\}$, whose $u$ is from $X$ and $v$ is from $Y$, is minimal.}
\end{center}

Because of using first order logic in Squander (\ref{sub:apps}), again it is
necessary to define some maximum treshold of counts of edges connecting groups of nodes. For generating
graph was implemented project called \verb|Common graph utils|, which generates
graph according to this rules:

\begin{enumerate}
  \item generate and add $n$ nodes to the graph
  \item generate a random permutation of nodes and add edges between the neighboring
nodes in the permutation, including the edge between the last and the first
node. At this point, the graph contains a Hamiltonian cycle.
  \item randomly choose a number between $30$ and $90$ percent of the maximum
  number of nodes $(n(n + 1))$ and keep adding random edges until the number of
  edges in the graph is equal to the chosen number.
  \item randomly choose a node and remove all its incoming edges. At this point, the
graph still contains at least one Hamiltonian path, the one that starts from the
node selected in this step.
\item if the goal is to generate graphs with no Hamiltonian paths, remove all outgoing
edges of the node selected in the previous step.
\end{enumerate}

This algorithm for generating graph is taken from Hamiltonian path problem,
which will be introduced later, but we will use it for generating graphs for all
graph algorithms presented in this thesis.

Regarding \textit{General bisection breadth} algorithm, we will use these data
structures and objects:

\begin{itemize}
  \item \textit{class Node} with property \verb|value|, which symbolizes label
  of actual node
  \item \textit{class Edge} with properties \verb|src|, \verb|dest| of type
  \verb|Node| and \verb|Integer| property cost, that will not be used in this
  algorithm at all
  \item \textit{Set nodes} which will contain all nodes in the graph
  \item \textit{Set edges} which will contain all edges in the graph
  \item \textit{Set resultA} which will represent set of nodes of exactly
  defined size
  \item \textit{integer a} representing exact size of set of nodes
  \verb|resultA|
  \item \textit{Set resultN} defining size of set containing rest nodes
  \item \textit{integer n} defining total count of nodes in graph 
  \item \textit{integer treshold} representing maximum
  count of edges having source node in \verb|resultA| and destination node in \verb|resultN| and
  reversely
  \item \textit{Set commonEdges} is help data structure containing edges
  starting from one set of nodes and ending in the other one
\end{itemize}

Again we started defining what we allow to modify and what are the
prerequisites. The answer is easy, because all data structures we need to
change are both main set of nodes \verb|resultA| and \verb|resultN| and set of
\verb|commonEdges| also with its length, because we want also to find set of
fewer common edges than treshold is. After that we add constraint that
variable \verb|a|, which symbolizes count of nodes in set \verb|resultA|, has
to be lower or equal to total count of nodes \verb|n|:


\lstinputlisting[label=gbb1,caption=Declaration
of modifiable objects in General
bisection breadth]{src/generalBisectionBreadth/Gbb1.java}

Then we can add constraints about what we expect after execution by annotation
\verb|@Ensures|. This specification will contain information that both sets
\verb|resultA| and \verb|resultN| are subsets of set of nodes in the graph,
information that size of set \verb|resultA| is \verb|a| and size of set
\verb|resultN| is \verb|n - a|:

\lstinputlisting[label=gbb2,caption=Declaration
of both sets of nodes]{src/generalBisectionBreadth/Gbb2.java}

Finally we have to add specification that none of the nodes is at the same time
in set \verb|resultA| and in set \verb|resultN| and specifications concerning
set of \verb|commonEdges|. First one is that count of \verb|commonEdges| is
lower or equal to \verb|treshold| and that \verb|commonEdges| are subset of set
\verb|edges|. Next step is to define that all edges, whose source and
destination node are in different set (\verb|resultA| and \verb|resultN|), are
in set \verb|commonEdges|:

\lstinputlisting[label=gbb3,caption=Final
version of implementation General
bisection breadth algorithm]{src/generalBisectionBreadth/Gbb3.java}

During testing testing this Squander implementation was able to deal with
instances up to $30$ nodes but there was sometimes problem when using
constraints on \verb|commonEdges|, which does not always work properly -
sometimes returns \verb|RuntimeException: No solution|, when solution was found
in previous test.

\subsection{Second version}
In implementation of second version of General bisection breadth algorithm was
removed declaration of \uv{help} set \verb|commonEdges| and instead of that
is used direct summation of edges connecting both set of nodes. This summation
was implemented via transformation of set of \verb|edges| (all edges in the
graph) into array, which is necessary to use when using summation in Squander.
In summation is via ternary operator decided if actual edge connects both set of
nodes and according to that counted number of connecting edges - see Listing
\ref{gbb4}.

\lstinputlisting[label=gbb4,caption=Alternative
version of implementation General
bisection breadth algorithm]{src/generalBisectionBreadth/Gbb4.java}

\newpage
\section{L-dominant set of graph}
\label{sec:ldsg}

\subsection{First version}
\label{sub:ldsFrstVer}
Idea of this algorithm was also taken as \ref{sec:gbb} from the same course at
CTU FEE. Also this algorithm is graph a algorithm and main idea is to find set
of nodes in the graph, which will cover with its neighborhood of defined
breadth, whole graph. Again to be more precise, definition of algorithm is:

\begin{center}
\uv{For a given natural number $l\geq 0$ and node $u$ of graph $G$ is
$l-neighborhood$ of node $u$ set of all nodes of $G$ in distance not more than
$l$ from node $u$, including node $u$ itself. Then $l-dominant\hspace{1mm}set\hspace{1mm}of\hspace{1mm}graph\hspace{1mm}G$
is every set of nodes such, that union of their $l-neighborhood$ contains
all nodes in $G$.}
\end{center}

For this algorithm is necessary to have more specific data about the graph. At
first we have to generate neighborhood of specified length of all nodes in the
graph. Due to generating this neighborhood I implemented \textit{Breadth
first search algorithm (BFS)} and extends data structure \textit{Node} from
previous algorithm \ref{sec:gbb} of information about its state during BFS
traversing and its neighborhood. As was said before, Squander use first
order logic so some treshold of size of result set has to be define. Data
structures and objects used in this implementation:

\begin{itemize}
  \item \textit{class ExtendedNode} which extends \textit{class Node} from
  \ref{sec:gbb} of enum field \textit{state} (\textit{FRESH, OPENED, CLOSED})
  and of \textit{Set neighborhood}
  \item \textit{Set extendedNodes} containing all nodes in the graph
\item \textit{Set edges} containing all edges in the graph
  \item \textit{integer l} defining $l-neighborhood$ of node
  \item \textit{integer treshold} expressing maximum of nodes in result set
\end{itemize}

In our implementation we will return result set of nodes as an array of
class \verb|ExtendedNode|, which we allow to modify:

\lstinputlisting[label=ldomset1,caption=Declaration
of modifiable objects in L-Dominant set of graph
implementation]{src/lDominantSet/LDomSet1.java}

Now comes definition what we are expected to return. Definitely is return array
subset of set \verb|extendedNodes| and its length has to be shorter or equal to
variable \verb|treshold|:

\lstinputlisting[label=ldomset2,caption=Defining result array in L-Dominant set
of graph implementation]{src/lDominantSet/LDomSet2.java}

Next we define that all neighborhoods of all nodes in result array cover
whole graph. Then we tell Squander that in result array must not be one node
twice or more and all of the nodes in return result array are not in
neighborhood themselves:

\lstinputlisting[label=ldomset2,caption=Final
version of implementation L-Dominant set
of graph algorithm]{src/lDominantSet/LDomSet3.java}

This implementation works with instances with up to 60 nodes. During
testing appears little failure, that in some cases result array contains some
nodes more than once despite constraint \ref{ldomset4}. I have fix this failure
in second version of implementation \ref{sub:ldsScndVer}.

\lstinputlisting[label=ldomset4,caption=Constraint causing failure in
implementation L-Dominant set of graph
algorithm]{src/lDominantSet/LDomSet4.java}

\subsection{Second version}
\label{sub:ldsScndVer}

This version of implementation algorithm L-dominant set of graph is modified
from \ref{sub:ldsFrstVer} in return type of result. Here is used instead of
array a set of class \verb|ExtendedNode|, so it is not necessary to check,
whether result set contains concrete node or not, because from definition
\cite{oracle:javadocSet} is \verb|java.util.Set| a collection, that contains no
duplicate elements \ref{ldomset5}.

\lstinputlisting[label=ldomset5,caption=Implementation L-Dominant set of graph
algorithm using set as a return type of result]{src/lDominantSet/LDomSet5.java}
 
\section{Hamiltonian Path}
\label{sec:hp}
Algorithm \textit{Hamiltonian path} is quite well known. Core of this algorithm
is to find path which covers all nodes in the graph and visit no node twice or
more. It is last graph algorithm presented in this thesis using similar data
structures as previous ones. Implementation of algorithm is taken from
\cite{milicevic:executableSpecificationsForJavaPrograms}. Also data structures
and objects are similar as in previous ones:

\begin{itemize}
  \item \textit{class Node} with property \verb|value|, which symbolizes label
  of actual node
  \item \textit{class Edge} with properties \verb|src|, \verb|dest| of type
  \verb|Node| and \verb|Integer| property cost, that will not be used in this
  algorithm at all
  \item \textit{Set nodes} containing all nodes in the graph
	\item \textit{Set edges} containing all edges in the graph
\end{itemize}

Our implementation will return in new array of class \verb|Edge| sequence of
visited edges during traversing - to do that, \verb|@FreshObjects| annotation is
used. Then we allow to modify (via \verb|@Modifies| annotation) elements of
result array and its length (see Listing \ref{hp1}).

\lstinputlisting[label=hp1,caption=Declaration
of modifiable objects and returned result in Hamiltonian path
implementation]{src/hp/Hp1.java}

After that we add constraints defining, how resulted array of edges will looks
like - \verb|@Requires| annotation. Of course, firstly we tell Squander, that
returned array is subset of set \verb|edges|. Then we add similar constraint about nodes that all nodes
(both source and destination) are equal to set of \verb|nodes| and constraint
that length of resulted array is count of \verb|nodes -1|. Last constraint in
\verb|@Requires| annotation define, that for every edge in result set is
destination node source node of following one:

\lstinputlisting[label=hp2,caption=Final implementation of Hamiltonian path
algorithm]{src/hp/Hp2.java}

This implementation works fine for graphs with 15 nodes containing Hamiltonian
path and for graphs with 10 nodes which do not contain Hamiltonian path.

\section{Triangular solitaire}
As last algorithm I tried to implement simple game called  \textit{Triangular
solitaire}. Idea of that algorithm as idea of previous two graph
algorithms (\ref{sec:gbb} and \ref{sec:ldsg}) was taken from course
\textit{Parallel algorithms and computing} lectured at CTU FEE. Specification of
the algorithm was finally changed according to \cite{web:mathIsFun}. Target of
this algorithm is to leave only one occupied position on the game field by doing
allowed transitions. Allowed transition between two states of game field is to
move move with choosed peg via another peg to position which is not occupied by
the peg. Movements in actual state are available horizontally in both directions
and vertically under angle 45 or 135 degrees, see following Figure
\ref{fig:initGF}.

\begin{figure}[ht]
\begin{center}
\begin{tikzpicture}[>=stealth]
\draw[fill=gray!50] (0,0) -- (3,5.196152423) -- (6,0)-- (0,0);




\draw[fill=red] (1,0.65) circle (0.3);
\draw[fill=red] (2,0.65) circle (0.3);
\draw[fill=white] (3,0.65) circle (0.3);
\draw[fill=red] (4,0.65) circle (0.3);
\draw[fill=red] (5,0.65) circle (0.3);

\draw[fill=red] (1.5,1.5) circle (0.3);
\draw[fill=red] (2.5,1.5) circle (0.3);
\draw[fill=red] (3.5,1.5) circle (0.3);
\draw[fill=red] (4.5,1.5) circle (0.3);

\draw[fill=red] (2,2.35) circle (0.3);
\draw[fill=red] (3,2.35) circle (0.3);
\draw[fill=red] (4,2.35) circle (0.3);

\draw[fill=red] (2.5,3.2) circle (0.3);
\draw[fill=red] (3.5,3.2) circle (0.3);

\draw[fill=red] (3,4.05) circle (0.3);

%\draw[dashed,thick,->] (1,0.65) -- (3,0.65);
%\draw[dashed,thick,->] (5,0.65) -- (3,0.65);
%\draw[dashed,thick,->] (2,2.35) -- (3,0.65);
%\draw[dashed,thick,->] (4,2.35) -- (3,0.65);


\draw [dashed,->] (1,0.65) arc (140:45:1.3cm);
\draw [dashed,->] (5,0.65) arc (40:135:1.3cm);
\draw [dashed,very thick,->] (2,2.35) arc (80:-15:1.3cm);
\draw [dashed,->] (4,2.35) arc (100:195:1.3cm);



\draw [thick,->] (6,2.5) -- (8,2.5);


\draw[fill=gray!50] (8,0) -- (11,5.196152423) -- (14,0)-- (8,0);




\draw[fill=red] (9,0.65) circle (0.3);
\draw[fill=red] (10,0.65) circle (0.3);
\draw[fill=red] (11,0.65) circle (0.3);
\draw[fill=red] (12,0.65) circle (0.3);
\draw[fill=red] (13,0.65) circle (0.3);

\draw[fill=red] (9.5,1.5) circle (0.3);
\draw[fill=white] (10.5,1.5) circle (0.3);
\draw[fill=red] (11.5,1.5) circle (0.3);
\draw[fill=red] (12.5,1.5) circle (0.3);

\draw[fill=white] (10,2.35) circle (0.3);
\draw[fill=red] (11,2.35) circle (0.3);
\draw[fill=red] (12,2.35) circle (0.3);

\draw[fill=red] (10.5,3.2) circle (0.3);
\draw[fill=red] (11.5,3.2) circle (0.3);

\draw[fill=red] (11,4.05) circle (0.3);

%\draw[dashed,thick,->] (1,0.65) -- (3,0.65);
%\draw[dashed,thick,->] (5,0.65) -- (3,0.65);
%\draw[dashed,thick,->] (2,2.35) -- (3,0.65);
%\draw[dashed,thick,->] (4,2.35) -- (3,0.65);


%\draw [dashed,->] (9,0.65) arc (140:45:1.3cm);
%\draw [dashed,->] (13,0.65) arc (40:135:1.3cm);
%\draw [dashed,very thick,->] (10,2.35) arc (80:-15:1.3cm);
%\draw [dashed,->] (12,2.35) arc (100:195:1.3cm);

\end{tikzpicture}

\end{center}
\caption{Initialized game field and possible transitions}
\label{fig:initGF}
\end{figure}

In this Figure we can see except initialization state also example of one
possible transition between two states. If it is target of the game to leave
only one position occupied with peg, it is obvious that we need $N - 1$ steps to
do that, where $N$ is count of positions in game field, because in every step we
lose one peg ($N = \frac{n(n+1)}{2}$, where $n$ is length of side of the game
field, it is simple summation of arithmetic progression). Now we should
declare, what we want to return from our program. Of course it will be sequence
of states of game field, which lead to solution, specifying occupation of
concrete cell. Let us declare data structures, which are necessary for computation.

First one will be definitely \textit{class Cell} containing boolean field
\verb|occupied| and maybe some information about its position in the game field
which is not very necessary for purpose of Squander computation. Next data
structure we need is \textit{class State} grouping individual cell together
defining actual state of game field. \textit{Class SolitaireSolver}, computing
configuration of states, has following fields:
\newpage
\begin{itemize}
  \item \textit{startState} defining initial state of the game field, where only
  one cell is not occupied
  \item \textit{integer n} for defining size of side of game field - it has to
  be greater or equal to 5
  \item \textit{integer array adj} containing type of adjacency (if exists)
  between cells, where index to that matrix is position of the cell in
  \verb|cells| array ($left=1, right=2, top_{45}=3, top_{135}=4, bottom_{135}=5,
  bottom_{45}=6$)
\end{itemize}

Now let us do the specification of the main method computing desirable sequence
of states. At first we will define some requirements on data structures we have.
We only allow to modify field \verb|occupied| of class \verb|Cell|, but only on
those instances, who are not representing \verb|startState|, because this state
has to be constant all the time (declared via \verb|@Modifies| annotation and
optional instance selector in this annotation). Then we add constraint to object
\verb|startState|, that only one of the object in array \verb|Cells| can be
unoccupied. We declare this constraint using annotation \verb|@Invariant|
guarantees this constraint all the time (in this implementation will be enough
to use annotation \verb|@Required| when declaring this constraint, because we
allow to modify only \verb|Cell| objects in all states except for
\verb|startState|). Last requirement is that size of side of the triangle has
to be greater or equal to 5.

\lstinputlisting[label=ts1,caption=Defining requirements for Triangular
solitaire algorithm]{src/solitaire/TriSol1.java}

That were requirements for the algorithm. Now we have to add specifications
about the output of the algorithm. Specifications about returned array of states
are that all members of the result set are equal to all input states, because we
have to pass \uv{empty} states as method parameter. Last specification told us,
that only one cell of the last state is occupied. Specification is described in
Listing \ref{ts2}.
\newpage
\lstinputlisting[label=ts2,caption=Defining result set parameters for
Triangular solitaire algorithm]{src/solitaire/TriSol2.java}

Finally the most important thing is to add to method specification transition
constraints between two following states. In that constraint we specify that in
all states except last one exists three different cells such, that first one
(\verb|src|) and second one (\verb|via|) is occupied and the last one
(\verb|dest|) is empty and that value for first and second one and for the
second one and last one in the \verb|adj| matrix is the same and nonzero (that
means using positions of object cell in the \verb|cells| array of actual state
in \verb|adj| matrix to get type of adjacency if exists). If everything what was
mentioned is fulfilled, then is possible to make a transition such, that all
cell's occupied values are copied from actual state to following one except for
those three states mentioned above, which are copied inversely (\verb|src|,
\verb|via| and \verb|dest|) - see Listing \ref{ts3}.

This implementation works fine only for instances with up to 21 cells in game
field (side length 6). For larger instances was timeout treshold exceeded.
\newpage
\lstinputlisting[label=ts3,caption=Final implementation of
Triangular solitaire algorithm]{src/solitaire/TriSol3.java}


%*****************************************************************************
\chapter{Comparison}
\label{ch:comparison}
For measurement of some metrics (execution time and memory analysis) I have
tried to use Java profiler \textit{Test} \& \textit{Performance Tools Platform
(TPTP)}, which is Eclipse plugin profiling tool. This tool is highly integrated with Eclipse, so
it allows profiling of applications running from within Eclipse - see Figure
\ref{fig:pfMonitor}. But this profiler had a big overhead when measuring
Squander implementation and this led to situation, that every instance in Squander
reached time out. I have also tried another Eclipse profiler called
\textit{Colorer}, but developing of this profiler was cancelled in 2008 and also
there were quite a lot of problems to use it in oldest available Eclipse Europa.


\begin{figure}[ht]
\begin{center}
\includegraphics[width=14cm]{figures/pf}
\caption{TPTP profiling monitor}
\label{fig:pfMonitor}
\end{center}
\end{figure}

After that I decided to use tools provided by JVM, concretely \textit{JConsole}
(see Figure \ref{fig:pfJC}). This console can connect to any of running Java
process and monitore its Heap memory usage, CPU usage, number of load classes or
number of active threads. This data can be exported to csv file. It also
provides some statistics like CPU time, compile time, which kind of garbage
collector is used and how many collections were done etc.

For all measurement presented here, we had 1 warmup run and 5 test runs. The
purpose of the initial warmup run was to eliminate possible \uv{cold start}
effects, such as JVM initialization and class loading. In the subsequent 5 test runs, I executed
the operation under test on 3 same instances of a given
size, measured the total execution time, and reported the
average. The timeout threshold was set to 45 minutes for all experiments, and
the maximum Java heap size was left to the default value of 256MB. All
measurements were run a Linux box, with Intel\textsuperscript{\textregistered}
Core\texttrademark 2 Duo CPU @ 2.1GHz, 4GB of RAM, running Ubuntu 10.04.

\begin{figure}[ht]
\begin{center}
\includegraphics[width=14cm]{figures/jconsole/overview}
\caption{Profiling using JConsole}
\label{fig:pfJC}
\end{center}
\end{figure}


\section{Hamiltonian Path}

I used for measurement of implementation of algorithm Hamiltonian Path Squander
implementation presented in \ref{sec:hp}. Imperative algorithm was implemented
as simple backtracking. In main method for finding solution is algorithm
iteratively going through matrix of followers row by row and when is resulted
array of edges (length of this array is number of nodes - 1) empty, the actual
edge is put at the beginning of the array. Another possibility is to put actual
edge into resulted array to concrete position when this condition is satisfied:
there is an edge between actual nodes in the iteration and in resulted array of
edge does not appear source node of this edge. Rule that source and destination
node af actual edge are different has to be fulfilled. After that if we are at
the end of resulted array, then we are return back from the recursion, otherwise
program is searching for the following edge in next recursive step. If program
is returned from recursive step in depth $n$ and none of the edges occupies
actual position in resulted array, then is edge from recursive step $n - 1$
removed, because following edge for edge in depth $n-1$ does not exist.
Implementation of algorithm with comments is in Listing \ref{hpImp}.


\lstinputlisting[label=hpImp,caption=Imperative
implementation of Hamiltonian Path algorithm]{src/hp/imp/GraphExecutor.java}

For testing both implementations I have implemented simple graph generator
according to the rules mentioned in \ref{sec:gbb} and add restriction of maximal
grade of node in the graph. I have also made class \verb|Graph| serializable in
order to store it in some file and then load it into execution algorithm in order to run
both implementations on the same data.

In my test I have measured execution time of imperative backtrack method and
Squander implementation via method \verb|getCurrentThreadCpuTime()| of
\verb|ThreadMXBean| interface. According to \cite{oracle:javadoc}, a Java
virtual machine has a single instance of the implementation class of this interface. This instance implementing this
interface is an \verb|MXBean| that can be obtained by calling the
\verb|ManagementFactory.getThreadMXBean()| method or from the platform
\verb|MBeanServer| method. This method returns the total CPU time for the
current thread in nanoseconds. Results of the measurement are in Table
\ref{tab:hpTimes}.

From that table is obvious, that common imperative way of programming reached
better results than Squander implementation. In that point it is important to
note, that in execution time for Squander is included time for traversing heap,
checking preconditions and creating bounds for the universe, ensuring post
condition, translating to CNF and solving this CNF. We can also see, that bigger
influence on the execution time has maximal grade of node in the graph than
total number of nodes, mainly in imperative implementation, because it causes
branching during backtracking.




\begin{table}[ht]
\caption{Execution times of Hamiltonian Path algorithm implementation in ms}
%\label{tab:hpTimes}
\begin{center}
\begin{tabular}{l|r|r|r|r|r|r|r|r|r|} \cline{2-10}

\multirow{4}{*}{} & 
\multicolumn{9}{>{\cellcolor[gray]{.8}}c|}{Number of nodes
in the graph} \\ \cline{2-10} 
&  \multicolumn{4}{c|}{40} &
\multicolumn{2}{c|}{50} &
\multicolumn{3}{c|}{60}\\ \cline{2-10}
 & \multicolumn{4}{>{\cellcolor[gray]{.8}}c|}{max grade} &
\multicolumn{2}{>{\cellcolor[gray]{.8}}c|}{max grade} &
\multicolumn{3}{>{\cellcolor[gray]{.8}}c|}{max grade}\\ \cline{2-10}
 &  3 & 4 & 5 & 6 & 3 & 4 & 2 & 3 & 4  \\ \hline
\multicolumn{1}{|>{\cellcolor[gray]{.8}}l|}{Imperatively} & 180 &
4 220 & 39 910 & 772 860 & 120 & 60 390
& 10 & 440 & 780 \\ \hline
\multicolumn{1}{|>{\cellcolor[gray]{.8}}l|}{Squander} & 3 200 & 33 510 &
130 800 & \textbf{t/o} & 3 270 & 704 230 & 3 540 & 6 380 & \textbf{t/o}
\\
\hline
\end{tabular}
\end{center}
\label{tab:hpTimes}
\end{table}



\begin{table}
%\begin{center}
\begin{tabular}{l|r|r|r|r|r|r|r|r|r|} \cline{2-10}

\multirow{4}{*}{} & 
\multicolumn{9}{>{\cellcolor[gray]{.8}}c|}{Number of nodes
in the graph} \\ \cline{2-10} 

&  \multicolumn{3}{c|}{70} & \multicolumn{2}{c|}{80} &
 \multicolumn{2}{c|}{90} & \multicolumn{2}{c|}{100}\\ \cline{2-10}
 & \multicolumn{3}{>{\cellcolor[gray]{.8}}c|}{max grade} &
\multicolumn{2}{>{\cellcolor[gray]{.8}}c|}{max grade} &
\multicolumn{2}{>{\cellcolor[gray]{.8}}c|}{max grade} &
\multicolumn{2}{>{\cellcolor[gray]{.8}}c|}{max grade}\\ \cline{2-10}
&  2 & 3 & 4 & 2 & 3 & 2 & 3 & 2 & 3  \\ \hline
\multicolumn{1}{|>{\cellcolor[gray]{.8}}l|}{Imperatively}  & 30 & 3 940
& \textbf{t/o} & 20 & 14 920 & 70 & 173 090 & 40 &
 \textbf{t/o}\\ \hline 
\multicolumn{1}{|>{\cellcolor[gray]{.8}}l|}{Squander} & 3 940 & 5 100 &
\textbf{t/o} & 4 060 & 70 860 & 5 080 & \textbf{t/o} & 4 700 &
\textbf{t/o}\\ \hline
\end{tabular}

%\end{center}
\end{table}
\newpage
As was said before, I used for tracking execution of algorithm JConsole, which
started measuring on key press. When using JConsole for measuring \textit{heap
memory usage} and \textit{cpu usage}, I have extracted data into csv file and
use them for generating graphs in GNUPlot\textsuperscript{\textregistered},
which is command-line driven graphing utility allowing to generate graphs into \LaTeX source code.


When looking at the graphs of heap memory usage of imperative implementation, we
can see that there are some peaks in the graphs and those peak with biggest
number of used memory symbolizes probably finding some solution in actual
branch, which was not cut off, or some set of branches, that was not cut off or
cut off in great depth before collection. In Squander implementation appears
those peaks, when solving CNF and cleaning out clauses. Mainly is from graphs
in selected tests obvious, that whereas imperative implementation uses around
10 Mb of memory (highest peak is 40 Mb), Squander allocates around 50 Mb of memory with highest
peak 115 Mb.

Regarding graphs of CPU usage, Squander and also imperative implementation uses
around 50 \% of CPU except graph instance of 40 nodes, maximal node grade 5
when was used only 25 \% of CPU computation performance in imperative
implementation.




By using command line arguments \verb|-verbose:gc -XX:+PrintGCTimeStamps| I got
the information about time when was the garbage collector performed, how much of
the memory was reclaimed including total available memory space and how long
does it take (performing garbage collector is highlighted in graphs via green
point). We can see that in Squander implementation is garbage collector
performed every time, when cleaning clauses in CNF, which is quite often
contrary to imperative implementation. In Table \ref{tab:hpGcActivity} are
presented quotients of garbage collector activity to total execution time of
both implementation. This table shows, that whereas in imperative implementation
is garbage collector time one hundredth percent, in Squander implementation
reaches sometimes one percent or more of execution time. 


\begin{table}[ht]


\begin{center}
\begin{tabular}{l|r|r|r|} \cline{2-4}

\multirow{4}{*}{} & 
\multicolumn{3}{>{\cellcolor[gray]{.8}}c|}{Number of nodes
in the graph} \\ \cline{2-4} 

&  40 & 50 &
 80\\ \cline{2-4}
 & \multicolumn{1}{>{\cellcolor[gray]{.8}}c|}{max grade} &
\multicolumn{1}{>{\cellcolor[gray]{.8}}c|}{max grade} &
\multicolumn{1}{>{\cellcolor[gray]{.8}}c|}{max grade}\\ \cline{2-4}
&  4 & 5 & 3 \\ \hline
\multicolumn{1}{|>{\cellcolor[gray]{.8}}l|}{Imperatively}  & 0.01\%
(0.005126 secs) & 0.01\%
(0.006266 secs) & 0.008\% (0.00125 secs)\\ \hline 
\multicolumn{1}{|>{\cellcolor[gray]{.8}}l|}{Squander} & 0.8\% (1.054949 secs) &
0.3\% (1.908237 secs) & 1.2\% (0.851782 secs)\\ \hline
\end{tabular}
\end{center}
\caption{Quotient of garbage collector activity to total execution time
of Hamiltonian Path algorithm implementation}
\label{tab:hpGcActivity}
\end{table}

\newpage


\begin{figure}
\begin{center}
\input{figures/graphs/hp/imp/40-5/heap.tex}
\caption{Heap memory usage in time - Hamiltonian Path imperative implementation for
graph of 40 nodes, maximal node grade 5 with info (green points),
when was GC performed}
\label{fig:hpIMem405}
\end{center}
\end{figure}





\begin{figure}
\begin{center}
\input{figures/graphs/hp/squander/40-5/heap.tex}
\caption{Heap memory usage in time - Hamiltonian Path Squander implementation for
graph of 40 nodes, maximal node grade 5 with info (green points),
when was GC performed}
\label{fig:hpSMem405}
\end{center}
\end{figure}


\begin{figure}
\begin{center}
\input{figures/graphs/hp/imp/40-5/cpu.tex}
\caption{CPU usage in time - Hamiltonian Path imperative implementation for graph
of 40 nodes and maximal node grade 5}
\label{fig:hpICpu405}
\end{center}
\end{figure}


\begin{figure}[ht]
\begin{center}
\input{figures/graphs/hp/squander/40-5/cpu.tex}
\caption{CPU usage in time - Hamiltonian Path Squander implementation for graph
of 40 nodes and maximal node grade 5}
\label{fig:hpSCpu405}
\end{center}
\end{figure}



\begin{figure}[ht]
\begin{center}
\input{figures/graphs/hp/imp/50-4/heap.tex}
\caption{Heap memory usage in time - Hamiltonian Path imperative implementation for
graph of 50 nodes, maximal node grade 4 with info (green points),
when was GC performed}
\label{fig:hpIMem504}
\end{center}
\end{figure}




\begin{figure}[ht]
\begin{center}
\input{figures/graphs/hp/squander/50-4/heap.tex}
\caption{Heap memory usage in time - Hamiltonian Path Sqaunder implementation for
graph of 50 nodes, maximal node grade 4 with info (green points),
when was GC performed}
\label{fig:hpSMem504}
\end{center}
\end{figure}

\begin{figure}[ht]
\begin{center}
\input{figures/graphs/hp/imp/50-4/cpu.tex}
\caption{CPU usage in time - Hamiltonian Path imperative implementation for graph
of 50 nodes and maximal node grade 4}
\label{fig:hpICpu504}
\end{center}
\end{figure}


\begin{figure}[ht]
\begin{center}
\input{figures/graphs/hp/squander/50-4/cpu.tex}
\caption{CPU usage in time - Hamiltonian Path Squander implementation for graph
of 50 nodes and maximal node grade 4}
\label{fig:hpSCpu504}
\end{center}
\end{figure}


\begin{figure}[ht]
\begin{center}
\input{figures/graphs/hp/imp/80-3/heap.tex}
\caption{Heap memory usage in time - Hamiltonian Path imperative implementation for
graph of 80 nodes, maximal node grade 3 with info (green points),
when was GC performed}
\label{fig:hpIMem803}
\end{center}
\end{figure}




\begin{figure}[ht]
\begin{center}
\input{figures/graphs/hp/squander/80-3/heap.tex}
\caption{Heap memory usage in time - Hamiltonian Path Sqaunder implementation for
graph of 80 nodes, maximal node grade 3 with info (green points),
when was GC performed}
\label{fig:hpSMem803}
\end{center}
\end{figure}


\begin{figure}[ht]
\begin{center}
\input{figures/graphs/hp/imp/80-3/cpu.tex}
\caption{CPU usage in time - Hamiltonian Path imperative implementation for graph
of 80 nodes and maximal node grade 3}
\label{fig:hpICpu803}
\end{center}
\end{figure}

\begin{figure}[ht]
\begin{center}
\input{figures/graphs/hp/squander/80-3/cpu.tex}
\caption{CPU usage in time - Hamiltonian Path Squander implementation for graph
of 80 nodes and maximal node grade 3}
\label{fig:hpSCpu803}
\end{center}
\end{figure}
\clearpage 

Now let us try to compute dependency between execution time and particular
graph's parameters for Squander implementation. For this purpose we use
statistic term called \textit{correlation} introduced in Chapter
\ref{ch:statistics}. Let us define following random variables:

\begin{enumerate}
  \item $X$ as execution time of concrete graph instance
  \item $Y$ as number of nodes in concrete graph instance
  \item $Z$ as maximal node grade in concrete graph instance
\end{enumerate}


For that purpose were used graph instances with 40, 50, 60, 70, 80, 90, 100
nodes and max. node grade 2, 3, 4. When exec. time reaches timeout (45
min), exec. time is 1 hour.
%median of random variable $X$, $Y$ and $Z$ will be computed as:
%$$EX = \frac{3 200 + 33 510 + 130 800 + 3 270 + 704 230 + 3 540}{13} +$$
%$$\frac{6 380 + 3 940 + 5 100 + 4 060 + 70 860 + 5 080 + 4 700}{13}=75282.31$$

%$$EY = \frac{3}{13}\cdot 40 + \frac{2}{13}\cdot 50 + \frac{2}{13}\cdot 60 +
%\frac{2}{13}\cdot 70 + \frac{2}{13}\cdot 80 + \frac{1}{13}\cdot 90 +
%\frac{1}{13}\cdot 100=63.85$$


%$$EZ = \frac{5}{13}\cdot 2 + \frac{5}{13}\cdot 3 + \frac{2}{13}\cdot 4 +
%\frac{1}{13}\cdot 5=2.92$$

%now we compute median $EXY$ and $EXZ$:

%$$EXY=40\cdot 3 200 \cdot \frac{1}{13}+ 40 \cdot 33 510 \cdot\frac{1}{13}+ 40
%\cdot  130 800 \cdot\frac{1}{13}+ 50 \cdot   3 270 \cdot\frac{1}{13}+50 \cdot  
%704 230\cdot\frac{1}{13}+$$ 
%$$60 \cdot   3 540 \cdot\frac{1}{13}+60\cdot   6 380 \cdot\frac{1}{13}+70\cdot 
%3 940 \cdot\frac{1}{13}+70\cdot  5 100 \cdot\frac{1}{13}+80\cdot  4 060
%\cdot\frac{1}{13}+$$ $$80\cdot 70 860\cdot\frac{1}{13}+90\cdot  5
%080 \cdot\frac{1}{13}+100\cdot  4 700 \cdot\frac{1}{13}=386 3400$$

%$$cov\left(X,Y\right)=EXY-\left(EX\right)\cdot \left(EY\right)=386
%3400-75282.31\cdot 63.85= -943375.49$$


%$$cov\left(X,Y\right)=E[\left(3200-75282.31\right)\left(40-63.85\right)+
%\left(33510-75282.31\right)\left(63.85-40\right)+$$
%$$\left(130800-75282.31\right)\left(40-63.85\right)+\left(3270-75282.31\right)\left(50-63.85\right)+\left(704230-75282.31\right)\left(50-63.85\right)+$$
%$$\left(3540-75282.31\right)\left(63.85-60\right)+\left(6380-75282.31\right)\left(63.85-60\right)
%+\left(3940-75282.31\right)\left(70-63.85\right)+$$$$\left(5100-75282.31\right)\left(70-63.85\right)+
%\left(4060-75282.31\right)\left(80-63.85\right)+\left(70860-75282.31\right)\left(80-63.85\right)+$$
%$$\left(5080-75282.31\right)\left(90-63.85\right)+\left(4700-75282.31\right)\left(100-63.85\right)]=
%-1179662.93$$


%new computation
%median and variance of random variable $X$, $Y$ and $Z$ will be computed as:
%$$EX = \frac{1}{14}\cdot(2 880 + 3 200 + 3 260 + 3 270 + 704 230 + 3 540+6 380
%+ 3 940 + $$
%$$5 100 + 4 060 + 70 860 + 5 080 + 3600 000+ 4
%700 + 3600 000)=572 892.86$$

%$$varX=E(X-EX)^2=\frac{1}{14}\cdot[\left(2 880-572
%892.86\right)^2+\left(3200-572892.86\right)^2+\left(3260-572892.86\right)^2+$$
%$$\left(3270-572892.86\right)^2+\left(704230-572892.86\right)^2+\left(3540-572892.86\right)^2+\left(6380-572892.86\right)^2+$$
%$$\left(3940-572892.86\right)^2+\left(5100-572892.86\right)^2+\left(4060-572892.86\right)^2+\left(70860-572892.86\right)^2+$$
%$$\left(5080-572892.86\right)^2+\left(3600000-572892.86\right)^2+\left(4700-572892.86\right)^2+\left(3600000-572892.86\right)^2]$$
%$$=1582462793237.48$$

%$$EY = \frac{1}{7}\cdot \left(40 +  50 +  60 +
% 70 +  80 +  90 +
%100\right)=70$$

%$$varY=E(Y-EY)^2=\frac{1}{14}\cdot[\left(40 -70\right)^2+\left(50
%-70\right)^2+\left(60 -70\right)^2+\left(70 -70\right)^2+$$
%$$\left(80 -70\right)^2+\left(90 -70\right)^2+\left(100 -70\right)^2]=200$$

%$$EZ = \frac{1}{2}\cdot \left(2 +  3\right)=2.5$$
%$$varZ=E(Z-EZ)^2=\frac{1}{2}\cdot [\left(2 -  2.5\right)^2+\left(3 - 
%2.5\right)^2]=0.25$$ 
%now we compute median $EXY$ and $EXZ$:

%$$EXY= \frac{1}{14}\cdot(40\cdot 2 880 + 40\cdot 3 200 +
%50 \cdot  3 260+ 50 \cdot   3 270 +60 \cdot   3 540 +60\cdot   6 380 +$$ 
%$$70\cdot 
%3 940 +70\cdot  5 100 +80\cdot  4 060
%+80\cdot 70 860+90\cdot  5
%080 +90\cdot  3 600 000 +$$ $$100\cdot  4 700
%+100\cdot  3 600 000)=49 479 892.86$$

%$$cov\left(X,Y\right)=EXY-\left(EX\right)\cdot \left(EY\right)=49 479 892.86
%-572892.86\cdot 70= 9377392.66$$

%$$cor(X,Y)=\frac{cov(X,Y)}{\sqrt{varX}\sqrt{varY}}=\frac{9377392.66}{\sqrt{1582462793237.48}\sqrt{200}}=0.53$$
%\newpage

%$$EXZ=2\cdot\frac{1}{14}\cdot\left(2880 + 3260 + 3 540 + 3 940 + 4 060 + 5 080 
%+ 4 700\right)$$
%$$3\cdot\frac{1}{14}\cdot\left(3 200  + 3 270  + 6 380  + 5 100 + 70 860  + 3
%600 000 + 3 600 000\right) = 1565810.71$$

%$$cov\left(X,Z\right)=EXZ-\left(EX\right)\cdot \left(EZ\right)=1565810.71
%-572892.86\cdot 2.5=133578.56$$

%$$cor(X,Z)=\frac{cov(X,Z)}{\sqrt{varX}\sqrt{varZ}}=\frac{133578.56}{\sqrt{1582462793237.48}\sqrt{0.25}}=0.11$$

%never computation
median and variance of random variable $X$, $Y$ and $Z$ will be computed as:
$$EX = \frac{1}{21}\cdot(2 880 + 3 200 +33 510  + 3 260 + 3 270 
 + 704 230 + 3
540+6 380 +3600000 + 3 940 +$$
$$ 5 100+3600000 + 4 060 + 70 860+3600000 + 5 080 + 3600 000+3600000+ 4
700 +$$
$$ 3600 000+3600000)=1240667.14$$

$$varX=E(X-EX)^2=\frac{1}{21}\cdot[\left(2 880-1240667.14
\right)^2+\left(3200-1240667.14\right)^2+\left(33510 -1240667.14\right)^2+$$
$$\left(3260-1240667.14\right)^2+\left(3270-1240667.14\right)^2+\left(704230-1240667.14\right)^2+\left(3540-1240667.14\right)^2+$$
$$\left(6380-1240667.14\right)^2+\left(3600000-1240667.14\right)^2+\left(3940-1240667.14\right)^2+\left(5100-1240667.14\right)^2+$$
$$\left( 3600000
-1240667.14\right)^2+\left(4060-1240667.14\right)^2+\left(70860-1240667.14\right)^2+\left(3600000-1240667.14\right)^2+$$
$$\left(5080-1240667.14\right)^2+\left(3600000-1240667.14\right)^2+\left(3600000-1240667.14\right)^2+\left(4700-572892.86\right)^2+$$
$$\left(3600000-1240667.14\right)^2+\left(3600000-1240667.14\right)^2]=2918575393247$$

$$EY = \frac{1}{7}\cdot \left(40 +  50 +  60 +
 70 +  80 +  90 +
100\right)=70$$

$$varY=E(Y-EY)^2=\frac{1}{7}\cdot[\left(40 -70\right)^2+\left(50
-70\right)^2+\left(60 -70\right)^2+\left(70 -70\right)^2+$$
$$\left(80 -70\right)^2+\left(90 -70\right)^2+\left(100 -70\right)^2]=400$$

$$EZ = \frac{1}{3}\cdot \left(2 +  3 + 4\right)=3$$
$$varZ=E(Z-EZ)^2=\frac{1}{3}\cdot [\left(2 -  3\right)^2+\left(3 - 
3\right)^2+\left(4 -  3\right)^2]=0.33$$ 
now we compute median $EXY$ and $EXZ$, $cov(X,Y)$ and $cov(X,Z)$, $cor(X,Y)$
and $cor(X,Z)$:

$$EXY= \frac{1}{21}\cdot(40\cdot 2 880 + 40\cdot 3 200  + 40\cdot 33510 +
50 \cdot  3 260+ 50 \cdot   3 270+ 50 \cdot   704230 +60 \cdot   3 540 +60\cdot  
6 380+$$ $$60 \cdot   3600000  +70\cdot 
3 940 +70\cdot  5 100 +70\cdot  3600000 +80\cdot  4 060
+80\cdot 70 860 +80\cdot  3600000+90\cdot  5
080 +90\cdot  3 600 000 +$$ $$90\cdot  3600000 +100\cdot  4 700
+100\cdot  3 600 000 +100\cdot  3600000)=103298590.5$$

$$cov\left(X,Y\right)=EXY-\left(EX\right)\cdot \left(EY\right)=119791888.1
-1240667.14\cdot 70= 16451890.7$$

$$cor(X,Y)=\frac{cov(X,Y)}{\sqrt{varX}\sqrt{varY}}=\frac{16451890.7}{\sqrt{2918575393247}\sqrt{400}}=0.48$$
%\newpage

$$EXZ=2\cdot\frac{1}{21}\cdot\left(2880 + 3260 + 3 540 + 3 940 + 4 060 + 5 080 
+ 4 700\right)+$$
$$3\cdot\frac{1}{21}\cdot\left(3 200  + 3 270  + 6 380  + 5 100 + 70 860  + 3
600 000 + 3 600 000\right)+$$
$$4\cdot\frac{1}{21}\cdot\left(33 510   + 704 230   + 3600000  + 3600000 + 3600000 
+ 3 600 000 + 3 600 000\right) = 4612967.14$$

$$cov\left(X,Z\right)=EXZ-\left(EX\right)\cdot \left(EZ\right)=4612967.14
-1240667.14\cdot 3=890965.72$$

$$cor(X,Z)=\frac{cov(X,Z)}{\sqrt{varX}\sqrt{varZ}}=\frac{890965.72}{\sqrt{2918575393247}\sqrt{0.33}}=0.91$$

According to computed correlation execution time directly depends more on node
grade, where is correlation with execution time 0.91, than node number of nodes, where
is correlation 0.48. When compute these correlations similarly for imperative
implementation, we can see that execution time depends directly little bit more
on number of nodes (correlation 0.48) than on maximal node grade in the graph
(correlation 0.44).
\newpage
\section{Knapsack Problem}

Imperative implementation of Knapsack algorithm can be done in many ways like
brute force with or without branch \& bounds criterium, dynamic programming or
by some heuristic (e.g. quotient price to weight of actual thing), which could
be sometimes inaccurate. I have choosed for those tests probably most common way
of implementation by brute force branch \& bounds depth first search (BB-DFS) -
see Listings \ref{ksImp}. Object \verb|pw| is instance of
class \verb|PriceWeight| and holds actual weight and price for the
configuration.

\lstinputlisting[label=ksImp,caption=Imperative
implementation of Knapsack Problem
algorithm]{src/knapsack/imp/Knapsack.java}

When measuring Knapsack implementation, it is important to emphasize, that
execution time depends on resulted configuration of things in knapsack. What
does it exactly means? E.g. when computing configuration fulfilling treshold
condition on set of things, from which is in the resulted configuration only
last thing, imperative algorithm implemented by branch and
bounds-brute force has to search almost whole state space (except for branches,
that are cut off) whereas Squander implementation started with empty
configuration of things and test this configuration adding one thing after
another when he finishes with all possibilities of actual number of things. Let
us look at execution times in Table \ref{tab:ksTimes}.

\begin{table}
\caption{Execution times of Knapsack algorithm implementation in ms for
instances with \uv{one last thing in solution}}
\label{tab:ksTimes}
\begin{center}
\begin{tabular}{l|r|r|r|r|r|r|r|} \cline{2-8}

\multirow{2}{*}{} & 
\multicolumn{7}{>{\cellcolor[gray]{.8}}c|}{Number of things
to choose from} \\ \cline{2-8} 
 &  25 & 27 & 30 & 32 & 35 & 37 & 40 \\ \hline
\multicolumn{1}{|>{\cellcolor[gray]{.8}}l|}{Imperatively} & 8 220 &
35 130 & 300 910 & 1 314 750 & 10 952 150 & \textbf{t/o}& \textbf{t/o} \\
\hline \multicolumn{1}{|>{\cellcolor[gray]{.8}}l|}{Squander} & 1 440 & 1
440 & 1 460 & 1 640 & 1 530 & 3 010 & 3 130 \\
\hline
\end{tabular}
%\label{fig:hpIMem405}
\end{center}
\end{table}

That was extreme example of execution instance with \uv{one last thing in
solution}, but let us compare average time of execution on 50 instances - see
Table \ref{tab:ksAvgTimes}. For imperative implementation is average
execution time growing according to size of problem instance but this is not
true for Squander.


\begin{table}[h]
\caption{Average execution times of Knapsack algorithm implementation in ms}
\label{tab:ksAvgTimes}
\begin{center}
\begin{tabular}{l|r|r|r|r|r|r|r|} \cline{2-8}

\multirow{2}{*}{} & 
\multicolumn{7}{>{\cellcolor[gray]{.8}}c|}{Number of things
to choose from} \\ \cline{2-8} 
 &  20 & 22 & 25 & 27 & 30 & 32 & 35 \\ \hline
\multicolumn{1}{|>{\cellcolor[gray]{.8}}l|}{Imperatively} & 1.8 &
3.2 & 167.2 & 700.4 & 5 989.2 & 25 586.6 & 219 212.2\\
\hline \multicolumn{1}{|>{\cellcolor[gray]{.8}}l|}{Squander} & 25 408.8 &
28 298.6 & 26 361.8 & 28 922.4 & 26 626.0 & 26 907.7 & 30 680.0 \\
\hline
\end{tabular}
%\label{fig:hpIMem405}
\end{center}
\end{table}

It appears that in Squander implementation does not depend on size of the
instance so much. Let us look at following Table \ref{tab:ksDependency}. From
that table is obvious, that in Squander implementation depends
execution time on number of choosed things in final solution more than on number of things to
choose from. Table \ref{tab:ksTimes} gives us also information, that execution
time of Squander implementation for instances with \uv{one last thing in
solution} is little bit \uv{suspiciously} short.

\begin{table}[ht]
\caption{Dependency of execution times to number of things in final solution in
Knapsack algorithm Squander implementation}
\label{tab:ksDependency}
\begin{center}
\begin{tabular}{l|r|r|r|r|r|r|r|r|r|r|} \cline{2-11}

\multirow{4}{*}{} & 
\multicolumn{10}{>{\cellcolor[gray]{.8}}c|}{Number of things to choose from} \\
\cline{2-11} &  \multicolumn{4}{c|}{20} &
\multicolumn{3}{c|}{27} &
\multicolumn{3}{c|}{32}\\ \cline{2-11}
 & \multicolumn{4}{>{\cellcolor[gray]{.8}}c|}{number of ch. things} &
 \multicolumn{3}{>{\cellcolor[gray]{.8}}c|}{number of ch. things} & \multicolumn{3}{>{\cellcolor[gray]{.8}}c|}{number of ch. things}\\
\cline{2-11} &  1 & 14 & 16 & 17 & 1 & 20 & 23 & 1 & 24 & 25  \\ \hline
\multicolumn{1}{|>{\cellcolor[gray]{.8}}l|}{Time(ms)} & 1 060 & 7 970 &
27 520 & 29 130 & 1 550 & 28 700 & 30 110 & 1 460 & 27 600 & 29 940
\\
\hline
\end{tabular}
%\label{fig:hpIMem405}
\end{center}
\end{table}


\begin{figure}
\begin{center}
\input{figures/graphs/ks/imp/40/heap.tex}
\caption{Heap memory usage in time - Hamiltonian Path imperative implementation
for instance with 40 things and info (green points), when was GC performed}
\label{fig:ksIMem40}
\end{center}
\end{figure}





\begin{figure}
\begin{center}
\input{figures/graphs/ks/squander/40/heap.tex}
\caption{Heap memory usage in time - Knapsack Problem Squander implementation
for instance with 40 things and info (green points),
when was GC performed}
\label{fig:ksSMem40}
\end{center}
\end{figure}


\begin{figure}
\begin{center}
\input{figures/graphs/ks/imp/40/cpu.tex}
\caption{CPU usage in time - Knapsack Problem imperative implementation for instance with 40 things}
\label{fig:ksICpu40}
\end{center}
\end{figure}


\begin{figure}[ht]
\begin{center}
\input{figures/graphs/ks/squander/40/cpu.tex}
\caption{CPU usage in time - Hamiltonian Path Squander implementation for instance with 40 things}
\label{fig:ksSCpu40}
\end{center}
\end{figure}
\clearpage 

Now look at statistics about memory heap usage and CPU usage of both
implementations of Knapsack Problem. CPU usage is for imperative implementation
and Squander implementation little bit under level of 50 \% almost all the time
of execution, whereas heap memory uses Squander implementation much more than imperative
implementation. In Squander implementation used memory reaches before the end of
execution 520 Mb in contrast with imperative implementation, where is used 75
Mb of memory for heap at most. Garbage collector in Squander is also used many
times - 2.6 \% of execution time, whereas in imperative implementation it is
0.9 \% in average! On the other hand Squander implementation holds maximum of
the execution time for all instances around 30 seconds, but for some instances throws
\verb|outOfMemory Exception|, which is quite unpleasant.



For the computation of dependency between execution time and particular
were choosed following random variables:

\begin{enumerate}
  \item $X$ as execution time of concrete graph instance
  \item $Y$ as number of things to choose from
  \item $Z$ as number of selected things in knapsack in best solution for
  concrete instance
\end{enumerate}


For that purpose were used knapsack instances with 20, 22, 25, 27, 30, 32, 35,
37, 40 things. When exec. time reaches timeout (45
min), exec. time is 1 hour.

median and variance of random variable $X$, $Y$ and $Z$ will be computed as:
$$EX = \frac{49}{466}\cdot 442 + \frac{49}{466}\cdot 5076 + \frac{50}{466}\cdot
9828 + \frac{50}{466}\cdot 23238 +  \frac{50}{466}\cdot 28122 + \frac{50}{466}\cdot
28643 + \frac{50}{466}\cdot 28123 +$$
$$ \frac{48}{466}\cdot 30327 +\frac{23}{466}\cdot 27899 + \frac{27}{466}\cdot
28171 +\frac{14}{466}\cdot 27380 +\frac{6}{466}\cdot 24840 =20511.66$$


$$varX=E(X-EX)^2=\frac{49}{466}\cdot\left(442-20511.66
\right)^2+\frac{49}{466}\cdot\left(5076-20511.66\right)^2+$$
$$\frac{50}{466}\cdot\left(9828
-20511.66\right)^2+\frac{50}{466}\cdot\left(23238-20511.66\right)^2+\frac{50}{466}\cdot\left(28122-20511.66\right)^2+$$
$$\frac{50}{466}\cdot\left(28643-20511.66\right)^2+\frac{50}{466}\cdot\left(28123-20511.66\right)^2+\frac{48}{466}\cdot\left(30327-20511.66\right)^2+$$
$$\frac{23}{466}\cdot\left(27899-20511.66\right)^2+\frac{27}{466}\cdot\left(28171-20511.66\right)^2+\frac{14}{466}\cdot\left(27380-20511.66\right)^2+$$
$$\frac{6}{466}\cdot\left(24840-20511.66\right)^2=202361073.47$$

$$EY =  \frac{49}{466}\cdot 4 + \frac{49}{466}\cdot 10 + \frac{50}{466}\cdot
15 + \frac{50}{466}\cdot 20 +  \frac{50}{466}\cdot 22 +
\frac{50}{466}\cdot 25 + \frac{50}{466}\cdot 27 +$$
$$ \frac{48}{466}\cdot 30 +\frac{23}{466}\cdot 32 + \frac{27}{466}\cdot
35 +\frac{14}{466}\cdot 37 +\frac{6}{466}\cdot 40 =21.49$$

$$varY=E(Y-EY)^2=\frac{49}{466}\cdot\left(4-21.49
\right)^2+\frac{49}{466}\cdot\left(10-21.49\right)^2+\frac{50}{466}\cdot\left(22-21.49\right)^2+$$
$$\frac{50}{466}\cdot\left(15
-21.49\right)^2+\frac{50}{466}\cdot\left(20-21.49\right)^2+\frac{50}{466}\cdot\left(25-21.49\right)^2+\frac{50}{466}\cdot\left(27-21.49\right)^2+$$
$$\frac{48}{466}\cdot\left(30-21.49\right)^2+\frac{23}{466}\cdot\left(32-21.49\right)^2+\frac{27}{466}\cdot\left(35-21.49\right)^2+\frac{14}{466}\cdot\left(37-21.49\right)^2+$$
$$\frac{6}{466}\cdot\left(40-21.49\right)^2=90.53$$
$$$$

$$EZ = \frac{18}{466}\cdot 1 + \frac{16}{466}\cdot 2 + \frac{22}{466}\cdot 3+
\frac{4}{466}\cdot4 + \frac{2}{466}\cdot5 + \frac{8}{466}\cdot6 +
\frac{17}{466}\cdot7+\frac{11}{466}\cdot8+\frac{9}{466}\cdot9+\frac{1}{466}\cdot10+$$
$$\frac{2}{466}\cdot11+\frac{7}{466}\cdot12+\frac{17}{466}\cdot13+\frac{20}{466}\cdot14+\frac{25}{466}\cdot15+\frac{32}{466}\cdot16+\frac{31}{466}\cdot17+\frac{29}{466}\cdot18+\frac{17}{466}\cdot19+\frac{23}{466}\cdot20+\frac{28}{466}\cdot21+$$
$$\frac{23}{466}\cdot22+\frac{27}{466}\cdot23+\frac{19}{466}\cdot24+\frac{16}{466}\cdot25+\frac{9}{466}\cdot26+\frac{7}{466}\cdot27+\frac{12}{466}\cdot28+\frac{7}{466}\cdot29+\frac{7}{466}\cdot30$$
$$=16.22$$






$$varZ=E(Z-EZ)^2=\frac{18}{466}\cdot \left(1 - 16.22\right)^2 +
\frac{16}{466}\cdot \left(2-16.22\right)^2 + \frac{22}{466}\cdot
\left(3-16.22\right)^2+ \frac{4}{466}\cdot\left(4-16.22\right)^2 +$$
$$\frac{2}{466}\cdot\left(5-16.22\right)^2 +\frac{8}{466}\cdot\left(6-16.22\right)^2 +
\frac{17}{466}\cdot\left(7-16.22\right)^2+\frac{11}{466}\cdot\left(8-16.22\right)^2+\frac{9}{466}\cdot\left(9-16.22\right)^2+$$
$$\frac{1}{466}\cdot\left(10-16.22\right)^2+\frac{2}{466}\cdot\left(11-16.22\right)^2+\frac{7}{466}\cdot\left(12-16.22\right)^2+\frac{17}{466}\cdot\left(13-16.22\right)^2+\frac{20}{466}\cdot\left(14-16.22\right)^2+$$
$$\frac{25}{466}\cdot\left(15-16.22\right)^2+\frac{32}{466}\cdot\left(16-16.22\right)^2+\frac{31}{466}\cdot\left(17-16.22\right)^2+\frac{29}{466}\cdot\left(18-16.22\right)^2+\frac{17}{466}\cdot\left(19-16.22\right)^2+$$
$$\frac{23}{466}\cdot\left(20-16.22\right)^2+\frac{28}{466}\cdot\left(21-16.22\right)^2+\frac{23}{466}\cdot\left(22-16.22\right)^2+\frac{27}{466}\cdot\left(23-16.22\right)^2+\frac{19}{466}\cdot\left(24-16.22\right)^2+$$
$$\frac{16}{466}\cdot\left(25-16.22\right)^2+\frac{9}{466}\cdot\left(26-16.22\right)^2+\frac{7}{466}\cdot\left(27-16.22\right)^2+\frac{12}{466}\cdot\left(28-16.22\right)^2+\frac{7}{466}\cdot\left(29-16.22\right)^2+$$
$$\frac{7}{466}\cdot\left(30-16.22\right)^2=62.87$$

 
now we compute median $EXY$ and $EXZ$, $cov(X,Y)$ and $cov(X,Z)$, $cor(X,Y)$
and $cor(X,Z)$:

$$EXY=\frac{49}{466}\cdot442\cdot 4
+\frac{49}{466}\cdot5076\cdot10+\frac{50}{466}\cdot9828
\cdot15+\frac{50}{466}\cdot23238\cdot20+\frac{50}{466}\cdot28122\cdot22+$$
$$\frac{50}{466}\cdot28643\cdot25+\frac{50}{466}\cdot28123\cdot27+\frac{48}{466}\cdot30327\cdot30+\frac{23}{466}\cdot27899\cdot32+\frac{27}{466}\cdot28171\cdot35+$$
$$\frac{14}{466}\cdot27380\cdot37+\frac{6}{466}\cdot24840\cdot40=534028.86$$

$$cov\left(X,Y\right)=EXY-\left(EX\right)\cdot \left(EY\right)=534028.86
-20511.66\cdot 21.49= 93233.29$$

$$cor(X,Y)=\frac{cov(X,Y)}{\sqrt{varX}\sqrt{varY}}=\frac{93233.29}{\sqrt{202361073.47}\sqrt{90.53}}=0.69$$
%\newpage

$$EXZ=\frac{18}{466}\cdot 1\cdot450.56 + \frac{16}{466}\cdot 2\cdot346.25 +
\frac{22}{466}\cdot 3\cdot542.273+ \frac{4}{466}\cdot4\cdot922.5 +
\frac{2}{466}\cdot5\cdot4370 + \frac{8}{466}\cdot6\cdot3186.25 +
$$
$$\frac{17}{466}\cdot7\cdot4839.412+\frac{11}{466}\cdot8\cdot6092.727+\frac{9}{466}\cdot9\cdot7028.889+\frac{1}{466}\cdot10\cdot6960+\frac{2}{466}\cdot11\cdot17810+\frac{7}{466}\cdot12\cdot6985.714+$$
$$\frac{17}{466}\cdot13\cdot14619.412+\frac{20}{466}\cdot14\cdot7947.5+\frac{25}{466}\cdot15\cdot19156.4+\frac{32}{466}\cdot16\cdot27553.44+\frac{31}{466}\cdot17\cdot26966.22+$$
$$\frac{29}{466}\cdot18\cdot28493.79+\frac{17}{466}\cdot19\cdot29205.88+\frac{23}{466}\cdot20\cdot28886.52+\frac{28}{466}\cdot21\cdot28967.86+\frac{23}{466}\cdot22\cdot29971.3+$$
$$\frac{27}{466}\cdot23\cdot29967.78+\frac{19}{466}\cdot24\cdot30345.26+\frac{16}{466}\cdot25\cdot29588.13+\frac{9}{466}\cdot26\cdot29301.11+\frac{7}{466}\cdot27\cdot29518.57+$$
$$\frac{12}{466}\cdot28\cdot29079.17+\frac{7}{466}\cdot29\cdot29228.57+\frac{7}{466}\cdot30\cdot29368.57=412741.63$$

$$cov\left(X,Z\right)=EXZ-\left(EX\right)\cdot \left(EZ\right)=412741.63
-20511.66\cdot 16.22=80042.51$$

$$cor(X,Z)=\frac{cov(X,Z)}{\sqrt{varX}\sqrt{varZ}}=\frac{80042.51}{\sqrt{202361073.47}\sqrt{62.87}}=0.71$$

According to computed correlation execution time directly depends little bit
more on number of selected things, where is correlation with execution time
0.71, than on number of things to choose from, where is correlation 0.69. For
imperative implementation were correlations computed similarly and there is
situation completely different, execution time directly depends more on number
of things to choose from (correlation 0.622) than on number of selected things
(correlation 0.014).
%\newpage
\section{L-dominant set of graph}
\label{sec:ldsgComp}
For comparison was implemented imperative version of L-dominant set of graph
algorithm of type branch \& bounds depth first search with depth restricted to
number of edges. In this implementation is main data structure stack, which is
initialized by empty set of nodes and actual best configuration of nodes
covering with its l-neighborhood whole graph is set to all nodes in the graph.
When is some state from stack popped, followers of that state are created (if
exist) and it is checked, whether have sense to push actual generated state to
stack, when actual state is not covering all nodes in the graph and this state
contains more selected nodes than state with best configuration. It means that
this branch is cut off.


Generating of new states itself is done, such that into configuration of set of
nodes for new state is put first node which is not covered by set of nodes in
configuration of actual state. Then is computed coverage of this new set of
nodes via matrix of adjacency. Coverage is computed by ORing of configuration of
set of nodes in actual state with all rows in matrix of adjacency which are
assigned in that configuration. ORing is done as many times as great is the
number l symbolizing length of neighborhood. Implementation is presented in
Listing \ref{lDomSetImp}.
\newpage
\lstinputlisting[label=lDomSetImp,caption=Imperative
implementation of L-dominant set of graph
algorithm]{src/lDominantSet/imp/LDomSet.java}
\newpage
When measuring execution times for set of graph configuration, we change
l-neighborhood value as a parameter. It is almost obvious, that for imperative
implementation when increasing number of l-neighborhood, execution time is
decreasing. This is obvious from Tables \ref{tab:ldsgTimes2},
\ref{tab:ldsgTimes3} and \ref{tab:ldsgTimes4}. Let us compare execution
times e.g. for instances of 40 nodes a maximal node grade 2 - for l=2 is
execution time 17 020 ms, l=3 is 1 670 ms and for l=4 is 520 ms. More significant
difference is for instance with 70 nodes and maximal node grade 3, where for
l=2 is execution time 74 840 ms, for l=3 is 6 530 ms and for l=4 is 190 ms.
Also when maximal grade of node is increased, execution time is decreasing,
because when increasing maximal node grade same neighborhood l contains more
nodes so search space of imperative algorithm is reduced and not very surprising
discovery that for graphs with more nodes is execution time bigger than for
graphs with less nodes.

Now let us look at execution times for Squander implementation. Here is
dependency on size of l-neighborhood slightly different, because algorithm is
implemented in a way, that every node is holding its neighborhood and Squander
is only comparing if some set of nodes with its neighborhood is covering whole
graph and whether is fulfilled treshold condition. When comparing execution
times e.g. for instance with 40 nodes, maximal node grade 2 we can see that for
l=2 is execution time 5 050 ms, for l=3 is 6 670 ms and for l=4 is 3 990 ms.
Moreover e.g. for instance with 60 nodes, maximal node grade 4 is execution
time increasing with size of l-neighborhood. From measurement is also obvious
that there is not so strong constraint between execution times of two instances
with same number of nodes and different maximal grade as was in imperative
implementation.



\begin{table}[ht]
\caption{Execution times of L-dominant set of graph algorithm implementation in ms for
l-neighborhood = 2}
\label{tab:ldsgTimes2}
%\begin{center}
\begin{tabular}{l|r|r|r|r|r|r|r|r|r|r|} \cline{2-11}

\multirow{4}{*}{} & 
\multicolumn{10}{>{\cellcolor[gray]{.8}}c|}{Number of nodes
in the graph} \\ \cline{2-11} 

&  \multicolumn{2}{c|}{10} & \multicolumn{2}{c|}{20} &
 \multicolumn{3}{c|}{30} & \multicolumn{3}{c|}{40}\\ \cline{2-11}
 & \multicolumn{2}{>{\cellcolor[gray]{.8}}c|}{max grade} &
\multicolumn{2}{>{\cellcolor[gray]{.8}}c|}{max grade} &
\multicolumn{3}{>{\cellcolor[gray]{.8}}c|}{max grade} &
\multicolumn{3}{>{\cellcolor[gray]{.8}}c|}{max grade}\\ \cline{2-11}
&  2 & 3 & 2 & 3 & 2 & 3 & 4 & 2 & 3 & 4  \\ \hline
\multicolumn{1}{|>{\cellcolor[gray]{.8}}l|}{Imperatively}  & 10 & 1
& 30 & 20 & 260 & 40 & 30 & 17 020 &
 260 & 60\\ \hline 
\multicolumn{1}{|>{\cellcolor[gray]{.8}}l|}{Squander} & 960 & 900 &
2 520 & 2 230 & 3 820 & 3 520 & 3 520 & 5 050 &
4 590 & 4 130\\ \hline
\end{tabular}

%\end{center}
\end{table}


\begin{table}
%\label{tab:hpTimes}
\begin{center}
\begin{tabular}{l|r|r|r|r|r|r|r|r|} \cline{2-9}

\multirow{4}{*}{} & 
\multicolumn{8}{>{\cellcolor[gray]{.8}}c|}{Number of nodes
in the graph} \\ \cline{2-9} 
&  \multicolumn{4}{c|}{50} &
\multicolumn{2}{c|}{60} &
\multicolumn{2}{c|}{70}\\ \cline{2-9}
 & \multicolumn{4}{>{\cellcolor[gray]{.8}}c|}{max grade} &
\multicolumn{2}{>{\cellcolor[gray]{.8}}c|}{max grade} &
\multicolumn{2}{>{\cellcolor[gray]{.8}}c|}{max grade}\\ \cline{2-9}
  & 2 & 3 & 4 & 5 & 3 & 4 & 3 & 4  \\ \hline
\multicolumn{1}{|>{\cellcolor[gray]{.8}}l|}{Imperatively} &
89 450 & 12 510 & 530 & 140 & 65 230
& 2 360 & 74 840 & 26 980 \\ \hline
\multicolumn{1}{|>{\cellcolor[gray]{.8}}l|}{Squander} & 4 780 &
6 510 & 5 310 & 4 880 & 29 780 & 5 680 & 176 360  &
32 380
\\
\hline
\end{tabular}
%\label{fig:hpIMem405}
\end{center}
\end{table}

\newpage
\begin{table}[p!]
\caption{Execution times of L-dominant set of graph algorithm implementation in ms for
l-neighborhood = 3}
\label{tab:ldsgTimes3}
%\begin{center}
\begin{tabular}{l|r|r|r|r|r|r|r|r|r|r|} \cline{2-11}

\multirow{4}{*}{} & 
\multicolumn{10}{>{\cellcolor[gray]{.8}}c|}{Number of nodes
in the graph} \\ \cline{2-11} 

&  \multicolumn{2}{c|}{10} & \multicolumn{2}{c|}{20} &
 \multicolumn{3}{c|}{30} & \multicolumn{3}{c|}{40}\\ \cline{2-11}
 & \multicolumn{2}{>{\cellcolor[gray]{.8}}c|}{max grade} &
\multicolumn{2}{>{\cellcolor[gray]{.8}}c|}{max grade} &
\multicolumn{3}{>{\cellcolor[gray]{.8}}c|}{max grade} &
\multicolumn{3}{>{\cellcolor[gray]{.8}}c|}{max grade}\\ \cline{2-11}
&  2 & 3 & 2 & 3 & 2 & 3 & 4 & 2 & 3 & 4  \\ \hline
\multicolumn{1}{|>{\cellcolor[gray]{.8}}l|}{Imperatively}  & 1 & 1 & 20 & 1 &
100 & 10 & 10 & 1 670 & 60 & 20\\ \hline 
\multicolumn{1}{|>{\cellcolor[gray]{.8}}l|}{Squander} & 900 & 960 &
2 280 & 2 360 & 2 690 & 3 130 & 3 060 & 6 670 &
4 280 & 5 280\\ \hline
\end{tabular}

%\end{center}
\end{table}


\begin{table}[p!]
%\label{tab:hpTimes}
\begin{center}
\begin{tabular}{l|r|r|r|r|r|r|r|r|} \cline{2-9}

\multirow{4}{*}{} & 
\multicolumn{8}{>{\cellcolor[gray]{.8}}c|}{Number of nodes
in the graph} \\ \cline{2-9} 
&  \multicolumn{4}{c|}{50} &
\multicolumn{2}{c|}{60} &
\multicolumn{2}{c|}{70}\\ \cline{2-9}
 & \multicolumn{4}{>{\cellcolor[gray]{.8}}c|}{max grade} &
\multicolumn{2}{>{\cellcolor[gray]{.8}}c|}{max grade} &
\multicolumn{2}{>{\cellcolor[gray]{.8}}c|}{max grade}\\ \cline{2-9}
  & 2 & 3 & 4 & 5 & 3 & 4 & 3 & 4  \\ \hline
\multicolumn{1}{|>{\cellcolor[gray]{.8}}l|}{Imperatively} &
72 360 & 260 & 60 & 40 & 570
& 60 & 6 530 & 130 \\ \hline
\multicolumn{1}{|>{\cellcolor[gray]{.8}}l|}{Squander} & 4 910 & 4 920 & 6 460 &
8 760 & 13 970 & 9 820 & 10 820 & 12 150
\\
\hline
\end{tabular}
%\label{fig:hpIMem405}
\end{center}
\end{table}



%\newpage
\begin{table}[p!]
\caption{Execution times of L-dominant set of graph algorithm implementation in ms for
l-neighborhood = 4}
\label{tab:ldsgTimes4}
%\begin{center}
\begin{tabular}{l|r|r|r|r|r|r|r|r|r|r|} \cline{2-11}

\multirow{4}{*}{} & 
\multicolumn{10}{>{\cellcolor[gray]{.8}}c|}{Number of nodes
in the graph} \\ \cline{2-11} 

&  \multicolumn{2}{c|}{10} & \multicolumn{2}{c|}{20} &
 \multicolumn{3}{c|}{30} & \multicolumn{3}{c|}{40}\\ \cline{2-11}
 & \multicolumn{2}{>{\cellcolor[gray]{.8}}c|}{max grade} &
\multicolumn{2}{>{\cellcolor[gray]{.8}}c|}{max grade} &
\multicolumn{3}{>{\cellcolor[gray]{.8}}c|}{max grade} &
\multicolumn{3}{>{\cellcolor[gray]{.8}}c|}{max grade}\\ \cline{2-11}
&  2 & 3 & 2 & 3 & 2 & 3 & 4 & 2 & 3 & 4  \\ \hline
\multicolumn{1}{|>{\cellcolor[gray]{.8}}l|}{Imperatively}  & 1 & 1 & 10 & 1 &
80 & 10 & 10 & 520 & 20 & 50\\ \hline 
\multicolumn{1}{|>{\cellcolor[gray]{.8}}l|}{Squander} & 1 110 & 1 040 &
1 800 & 2 230 & 2 540 & 3 020 & 3 010 & 3 990 &
5 120 & 5 250\\ \hline
\end{tabular}

%\end{center}
\end{table}


\begin{table}[p!]
%\label{tab:hpTimes}
\begin{center}
\begin{tabular}{l|r|r|r|r|r|r|r|r|} \cline{2-9}

\multirow{4}{*}{} & 
\multicolumn{8}{>{\cellcolor[gray]{.8}}c|}{Number of nodes
in the graph} \\ \cline{2-9} 
&  \multicolumn{4}{c|}{50} &
\multicolumn{2}{c|}{60} &
\multicolumn{2}{c|}{70}\\ \cline{2-9}
 & \multicolumn{4}{>{\cellcolor[gray]{.8}}c|}{max grade} &
\multicolumn{2}{>{\cellcolor[gray]{.8}}c|}{max grade} &
\multicolumn{2}{>{\cellcolor[gray]{.8}}c|}{max grade}\\ \cline{2-9}
  & 2 & 3 & 4 & 5 & 3 & 4 & 3 & 4  \\ \hline
\multicolumn{1}{|>{\cellcolor[gray]{.8}}l|}{Imperatively} &
9 930 & 90 & 1 & 20 & 50
& 20 & 190 & 130 \\ \hline
\multicolumn{1}{|>{\cellcolor[gray]{.8}}l|}{Squander} & 4 170 & 5 840 & 10 090 &
12 630 & 9 260 & 14 650 & 11 400 & 24 190
\\
\hline
\end{tabular}
%\label{fig:hpIMem405}
\end{center}
\end{table}
\clearpage
Execution times of Squander implementation are usually better for instances with
more nodes, lower maximal grade of nodes and lower size of l-neighborhood. For
smaller instances is Squander slower than imperative implementation, because
imperative implementation is finished before Squander creates the universe,
establishes bounds and starts Kodkod engine.


Regarding loading through computation system, graphs shows, that for imperative
implementation was heap memory usage around 25 Mb peak value whereas for
Squander implementation was from 12 Mb to 80 Mb. More significant difference was
measured for CPU usage, when imperative implementation took about 50 \% of its
performance, whereas Squander implementation tooks around 80 \%.


Garbage collector in Squander is not used as many times as in previous
comparisons - only 0.03 \% of execution time and in imperative
implementation it is 0.015 \% in average, which is better result than in
Squander implementation but not very significantly.

\clearpage


\begin{figure}
\begin{center}
\input{figures/graphs/ldsg/imp/50-2/2/heap.tex}
\caption{Heap memory usage in time - L-dominant set of graph imperative
implementation, l=2 for graph with 50 nodes, max. grade 2 and info, when was GC performed}
\label{fig:ldsgIMem5022}
\end{center}
\end{figure}





\begin{figure}
\begin{center}
\input{figures/graphs/ldsg/squander/50-2/2/heap.tex}
\caption{Heap memory usage in time - L-dominant set of graph Squander
implementation, l=2 for graph with 50 nodes, max. grade 2 and info, when was GC performed}
\label{fig:ldsgSMem5022}
\end{center}
\end{figure}


\begin{figure}
\begin{center}
\input{figures/graphs/ldsg/imp/50-2/2/cpu.tex}
\caption{CPU usage in time - L-dominant set of graph imperative
implementation, l=2 for graph with 50 nodes, max. grade 2}
\label{fig:ldsgICpu5022}
\end{center}
\end{figure}


\begin{figure}[ht]
\begin{center}
\input{figures/graphs/ldsg/squander/50-2/2/cpu.tex}
\caption{CPU usage in time - L-dominant set of graph Squander
implementation, l=2 for graph with 50 nodes, max. grade 2}
\label{fig:ldsgSCpu5022}
\end{center}
\end{figure}



\begin{figure}
\begin{center}
\input{figures/graphs/ldsg/imp/50-2/3/heap.tex}
\caption{Heap memory usage in time - L-dominant set of graph imperative
implementation, l=3 for graph with 50 nodes, max. grade 2 and info, when was GC
performed}
\label{fig:ldsgIMem5023}
\end{center}
\end{figure}





\begin{figure}
\begin{center}
\input{figures/graphs/ldsg/squander/50-2/3/heap.tex}
\caption{Heap memory usage in time - L-dominant set of graph Squander
implementation, l=3 for graph with 50 nodes, max. grade 2 and info, when was GC
performed}
\label{fig:ldsgSMem5023}
\end{center}
\end{figure}


\begin{figure}
\begin{center}
\input{figures/graphs/ldsg/imp/50-2/3/cpu.tex}
\caption{CPU usage in time - L-dominant set of graph imperative
implementation, l=3 for graph with 50 nodes, max. grade 2}
\label{fig:ldsgICpu5023}
\end{center}
\end{figure}


\begin{figure}[ht]
\begin{center}
\input{figures/graphs/ldsg/squander/50-2/3/cpu.tex}
\caption{CPU usage in time - L-dominant set of graph Squander
implementation, l=3 for graph with 50 nodes, max. grade 2}
\label{fig:ldsgSCpu5023}
\end{center}
\end{figure}




\begin{figure}
\begin{center}
\input{figures/graphs/ldsg/imp/50-2/4/heap.tex}
\caption{Heap memory usage in time - L-dominant set of graph imperative
implementation, l=4 for graph with 50 nodes, max. grade 2 and info, when was GC
performed}
\label{fig:ldsgIMem5024}
\end{center}
\end{figure}





\begin{figure}
\begin{center}
\input{figures/graphs/ldsg/squander/50-2/4/heap.tex}
\caption{Heap memory usage in time - L-dominant set of graph Squander
implementation, l=4 for graph with 50 nodes, max. grade 2 and info, when was GC
performed}
\label{fig:ldsgSMem5024}
\end{center}
\end{figure}


\begin{figure}
\begin{center}
\input{figures/graphs/ldsg/imp/50-2/4/cpu.tex}
\caption{CPU usage in time - L-dominant set of graph imperative
implementation, l=4 for graph with 50 nodes, max. grade 2}
\label{fig:ldsgICpu5024}
\end{center}
\end{figure}


\begin{figure}[ht]
\begin{center}
\input{figures/graphs/ldsg/squander/50-2/4/cpu.tex}
\caption{CPU usage in time - L-dominant set of graph Squander
implementation, l=4 for graph with 50 nodes, max. grade 2}
\label{fig:ldsgSCpu5024}
\end{center}
\end{figure}

\clearpage 
We can now compute how strong are dependencies between input data and execution
time for Squander implementation. Let us define for that purpose
following random variables:
\begin{enumerate}
  \item $X$ as execution time of concrete graph instance
  \item $Y$ as number of nodes in concrete graph instance
  \item $Z$ as maximal node grade in concrete graph instance
  \item $W$ as size of l-neighborhood for concrete computation
\end{enumerate}
For the computation were used graph instances with 10, 20, 30, 40, 50, 60, 70
nodes, max. node grade 2, 3, 4 and l-neighborhood  2, 3, 4. When exec. time
reaches timeout (45 min), exec. time is 1 hour.

$$EX = \frac{1}{63}\cdot(960  + 900  +1 070  + 2 520  + 2 230  
 + 2 740 + 3 820+ 3 520 + 3 520 + 5 050 + 4 590 + 4 130
+$$
$$4 780 + 6 510 +5 310+62 354+29 780+ 5 680 + 250 180+176 360 +32 380+ 900 +$$
 $$960 + 1 070 + 2 280 +2 360 + 1 930 +2 690 +3 130 +3 060 +6 670 +4 280+ 5
 280 +4 910 +$$
 $$4 920 +6 460+22 341 +13 970 +9 820+14 378 +10 820 + 12 150 +1 110+ 1 040+ 1
 150+$$ $$ 1 800 +2 230 + 2 050 +2 540 +3 020 +3 010 +3 990 +5 120+
 5 250+4 170 +5 840 +10 090+$$ 
 $$13 580+9 260+ 14 650+27 290 +11 400 +24 190) =14214.97$$

%here I am


$$varX=E(X-EX)^2=\frac{1}{63}\cdot[\left(960-14214.97
\right)^2+\left(900-14214.97\right)^2+\left(1070 -14214.97\right)^2+$$
$$\left(2520-14214.97\right)^2+\left(2230-14214.97\right)^2+\left(2740-14214.97\right)^2+\left(3820-14214.97\right)^2+$$
$$\left(3520-14214.97\right)^2+\left(3520-14214.97\right)^2+\left(5050-14214.97\right)^2+\left(4590-14214.97\right)^2+$$
$$\left( 4130
-14214.97\right)^2+\left(4780-14214.97\right)^2+\left(6510-14214.97\right)^2+\left(5310-14214.97\right)^2+$$
$$\left(62354-14214.97\right)^2+\left(29780-14214.97\right)^2+\left(5680-14214.97\right)^2+\left(25180-14214.97\right)^2+$$
$$\left(176360-14214.97\right)^2+\left(32380-14214.97\right)^2+\left(900-14214.97
\right)^2+\left(960-14214.97\right)^2+$$
%TADY
$$\left(1070
-14214.97\right)^2+\left(2280-14214.97\right)^2+\left(2360-14214.97\right)^2+\left(1930-14214.97\right)^2+$$ $$\left(2690-14214.97\right)^2+\left(3130-14214.97\right)^2+\left(3060-14214.97\right)^2+\left(6670-14214.97\right)^2+$$
$$\left(4280-14214.97\right)^2+\left( 5280
-14214.97\right)^2+\left(4910-14214.97\right)^2+\left(4920-14214.97\right)^2+$$
$$\left(6460-14214.97\right)^2+\left(22341-14214.97\right)^2+\left(13970-14214.97\right)^2+\left(9820-14214.97\right)^2+$$
$$\left(14378-14214.97\right)^2+\left(10820-14214.97\right)^2+\left(12150-14214.97\right)^2+\left(1110-14214.97
\right)^2+$$
$$\left(1040-14214.97\right)^2+\left(1150
-14214.97\right)^2+\left(1800-14214.97\right)^2+\left(2230-14214.97\right)^2+$$
%TADY
$$\left(2050-14214.97\right)^2+\left(2540-14214.97\right)^2+\left(3020-14214.97\right)^2+\left(3010-14214.97\right)^2+$$
$$\left(3990-14214.97\right)^2+\left(5120-14214.97\right)^2+\left( 5250
-14214.97\right)^2+\left(4170-14214.97\right)^2+$$
$$\left(5840-14214.97\right)^2+\left(10090-14214.97\right)^2+\left(13580-14214.97\right)^2+\left(9260-14214.97\right)^2+$$
$$\left(14650-14214.97\right)^2+\left(27290-14214.97\right)^2+\left(11400-14214.97\right)^2+\left(24190-14214.97\right)^2]$$
$$=565226301.39$$


$$EY = \frac{1}{7}\cdot \left(10 + 20+ 30 + 40 +  50 +  60 +
 70\right)=40$$

$$varY=E(Y-EY)^2=\frac{1}{7}\cdot[\left(10 -40\right)^2+\left(20
-40\right)^2+\left(30 -40\right)^2+\left(40 -40\right)^2+$$
$$\left(50 -40\right)^2+\left(60 -40\right)^2+\left(70 -40\right)^2]=400$$

$$EZ = \frac{1}{3}\cdot \left(2 +  3 + 4\right)=3$$
$$varZ=E(Z-EZ)^2=\frac{1}{3}\cdot [\left(2 -  3\right)^2+\left(3 - 
3\right)^2+\left(4 -  3\right)^2]=0.33$$

$$EW = \frac{1}{3}\cdot \left(2 +  3 + 4\right)=3$$
$$varW=E(W-EW)^2=\frac{1}{3}\cdot [\left(2 -  3\right)^2+\left(3 - 
3\right)^2+\left(4 -  3\right)^2]=0.33$$  
now we compute median $EXY$ and $EXZ$, $cov(X,Y)$ and $cov(X,Z)$, $cor(X,Y)$
and $cor(X,Z)$:

$$EXY= \frac{1}{63}\cdot(10\cdot 960  + 10\cdot  900  + 10\cdot  1070 +
20 \cdot  2520+ 20 \cdot   2230+ 20 \cdot  2740  +30 \cdot   3820 +30\cdot  
 3520+$$ $$30 \cdot  3520 +40\cdot 
5050 +40\cdot  4590 +40\cdot 4130 +50\cdot  4780
+50\cdot   6510 +50\cdot 5310+60\cdot  62354
 +60\cdot  29780 +$$ $$60\cdot   5680  +70\cdot  250180
+70\cdot   176360 +70\cdot 32380 +10\cdot 900
 +10\cdot 960 +10\cdot  1070 + 20 \cdot 2280+$$
 $$20\cdot   2360  +20\cdot  1930
+30\cdot   2690 +30\cdot  3130 +30\cdot 3060
 +40\cdot 6670 +40\cdot  4280 + 40 \cdot  5280+$$
 $$50\cdot  4910  +50\cdot 4920
+50\cdot 6460 +60\cdot  22341 +60\cdot 13970
 +60\cdot  9820 +70\cdot  14378 + 70 \cdot  10820+$$
 $$70\cdot  12150  +10\cdot 1110
+10\cdot  1040 +10\cdot  1150 +20\cdot 1800
 +20\cdot 2230 +20\cdot   2050 + 30 \cdot  2540+$$
 $$30\cdot   3020  +30\cdot  3010
+40\cdot  3990 +40\cdot   5120 +40\cdot  5250
 +50\cdot 4170 +50\cdot   5840 + 50 \cdot  10090+$$
$$60\cdot  13580  +60\cdot  9260
+60\cdot 14650  +70\cdot 27290 +70\cdot  11400
 +70\cdot   24190)=885620$$

$$cov\left(X,Y\right)=EXY-\left(EX\right)\cdot \left(EY\right)=885620
-14214.97\cdot 40= 317021.2$$

$$cor(X,Y)=\frac{cov(X,Y)}{\sqrt{varX}\sqrt{varY}}=\frac{317021.2}{\sqrt{565226301.39}\sqrt{400}}=0.67$$
%\newpage

$$EXZ= \frac{1}{63}\cdot(2\cdot 960  + 3\cdot  900  + 4\cdot  1070 +
2 \cdot  2520+ 3 \cdot   2230+ 4 \cdot  2740  +2 \cdot   3820 +3\cdot  
 3520+$$ $$4 \cdot  3520 +2\cdot 
5050 +3\cdot  4590 +4\cdot 4130 +2\cdot  4780
+3\cdot   6510 +4\cdot 5310+2\cdot  62354
 +3\cdot  29780 +$$ $$4\cdot   5680  +2\cdot  250180
+3\cdot   176360 +4\cdot 32380 +2\cdot 900
 +3\cdot 960 +4\cdot  1070 + 2 \cdot 2280+$$
 $$3\cdot   2360  +4\cdot  1930
+2\cdot   2690 +3\cdot  3130 +4\cdot 3060
 +2\cdot 6670 +3\cdot  4280 + 4 \cdot  5280+$$
 $$2\cdot  4910  +3\cdot 4920
+4\cdot 6460 +2\cdot  22341 +3\cdot 13970
 +4\cdot  9820 +2\cdot  14378 + 3 \cdot  10820+$$
 $$4\cdot  12150  +2\cdot 1110
+3\cdot  1040 +4\cdot  1150 +2\cdot 1800
 +3\cdot 2230 +4\cdot   2050 + 2 \cdot  2540+$$
 $$3\cdot   3020  +4\cdot  3010
+2\cdot  3990 +3\cdot   5120 +4\cdot  5250
 +2\cdot 4170 +3\cdot   5840 + 4 \cdot  10090+$$
$$2\cdot  13580  +3\cdot  9260
+4\cdot 14650  +2\cdot 27290 +3\cdot  11400
 +4\cdot   24190)=38147.71$$

$$cov\left(X,Z\right)=EXZ-\left(EX\right)\cdot \left(EZ\right)=38147.71
-14214.97\cdot 3=-4497.2$$

$$cor(X,Z)=\frac{cov(X,Z)}{\sqrt{varX}\sqrt{varZ}}=\frac{-4497.2}{\sqrt{565226301.39}\sqrt{0.33}}=-0.33$$

%\newpage

$$EXW= \frac{1}{63}\cdot(2\cdot 960  + 2\cdot  900  + 2\cdot  1070 +
2 \cdot  2520+ 2 \cdot   2230+ 2 \cdot  2740  +2 \cdot   3820 +2\cdot  
 3520+$$ $$2 \cdot  3520 +2\cdot 
5050 +2\cdot  4590 +2\cdot 4130 +2\cdot  4780
+2\cdot   6510 +2\cdot 5310+2\cdot  62354
 +2\cdot  29780 +$$ $$2\cdot   5680  +2\cdot  250180
+2\cdot   176360 +2\cdot 32380 +3\cdot 900
 +3\cdot 960 +3\cdot  1070 + 3 \cdot 2280+$$
 $$3\cdot   2360  +3\cdot  1930
+3\cdot   2690 +3\cdot  3130 +3\cdot 3060
 +3\cdot 6670 +3\cdot  4280 + 3 \cdot  5280+$$
 $$3\cdot  4910  +3\cdot 4920
+3\cdot 6460 +3\cdot  22341 +3\cdot 13970
 +3\cdot  9820 +3\cdot  14378 + 3 \cdot  10820+$$
 $$3\cdot  12150  +4\cdot 1110
+4\cdot  1040 +4\cdot  1150 +4\cdot 1800
 +4\cdot 2230 +4\cdot   2050 + 4 \cdot  2540+$$
 $$4\cdot   3020  +4\cdot  3010
+4\cdot  3990 +4\cdot   5120 +4\cdot  5250
 +4\cdot 4170 +4\cdot   5840 + 4 \cdot  10090+$$
$$4\cdot  13580  +4\cdot  9260
+4\cdot 14650  +4\cdot 27290 +4\cdot  11400
 +4\cdot   24190)=35413.1$$

$$cov\left(X,W\right)=EXW-\left(EX\right)\cdot \left(EW\right)=35413.1
-14214.97\cdot 3=-7231.81$$

$$cor(X,W)=\frac{cov(X,W)}{\sqrt{varX}\sqrt{varW}}=\frac{-7231.81}{\sqrt{565226301.39}\sqrt{0.33}}=-0.53$$

From computed correlations is obvious, that execution time depends most on
number of nodes in the graph, where is correlation with execution time 0.67, in
such sense, that with more nodes in the graph is execution time increasing.
Correlations of other two parameters tells us, that with higher node grade
(size of l-neighborhood) is execution time shortening. More with size of
l-neighborhood, where is correlation -0.53, than with maximal node grade, where
is correlation -0.33. Correlations for imperative implementation told us, that
execution time directly depends on all parameters, most on number of nodes
(correlation 0.34), then on maximal node grade (correlation 0.2) and least
depends on size of l-neighborhood (correlation 0.18).


\newpage
\section{General bisection breadth}

Imperative version of General bisection breadth algorithm was implemented in
similar way like imperative version of L-dominant set of graph algorithm in
Listing \ref{lDomSetImp}. State space is searched using Depth first search
algorithm extended by branch \& bounds criterium. At first state with empty configuration
and maximal price (number of bounds connecting two sets in th graph, which is
necessary to minimize) is pushed onto stack. For every state popped from stack
are generated its followers and if configuration of actual follower does not
contain demanded number of nodes it is pushed onto stack. Otherwise is generated
follower tested if its configuration is better (contains less edges connecting
two groups of nodes) than actual best state and if yes, it is marked as actual
best state. Branch \& bounds criterium is implemented such, that when actual
state has more or equal edges connecting nodes in its configuration than
actual best state's configuration, its branch is cut off, because there is no
way to find configuration in its branch containing less connecting edges than
actual best state's configuration.

\lstinputlisting[label=GbbImp,caption=Imperative
implementation of General bisection breadth
algorithm]{src/generalBisectionBreadth/imp/Gbb.java}
\newpage
For measuring characteristics of imperative and Squander implementation was used
similar set of graphs as in previous algorithm measurement in
Section \ref{sec:ldsgComp}. Instead of changing parameter of size
of neighborhood is changed number of nodes in set A. From that measurement is
obvious information that when increasing maximal node grade in the graph
instance, execution time for imperative implementation is longer. This is also
almost always true for Squander implementation, except for some instances where
is execution time with maximal node grade decreasing - instance with 70 nodes
and 14 nodes in set A - or instances where it looks like, that not depends on
maximal node grade so much - graph with 40 nodes and 8 nodes in set A. We can
see from execution times also, that longest execution times have
such configuration of nodes, where in set A has to be exactly half of total
number of nodes.


When comparing both implementation it is obvious, that execution of Squander's
implementation of algorithm takes more time than execution using DFS algorithm
with branch and bounds criterium, probably thanks to constraint checking number
of edges connecting both sets of nodes in Squander implementation.

\begin{table}[ht]
\caption{Execution times of General bisection breadth algorithm implementation
in ms for $\frac{1}{5}$ nodes in one node set}
\label{tab:gbbTimes15}
%\begin{center}
\begin{tabular}{l|r|r|r|r|r|r|r|r|r|r|} \cline{2-11}

\multirow{4}{*}{} & 
\multicolumn{10}{>{\cellcolor[gray]{.8}}c|}{Number of nodes
in the graph} \\ \cline{2-11} 

&  \multicolumn{2}{c|}{10} & \multicolumn{2}{c|}{20} &
 \multicolumn{3}{c|}{30} & \multicolumn{3}{c|}{40}\\ \cline{2-11}
 & \multicolumn{2}{>{\cellcolor[gray]{.8}}c|}{set A} &
\multicolumn{2}{>{\cellcolor[gray]{.8}}c|}{set A} &
\multicolumn{3}{>{\cellcolor[gray]{.8}}c|}{set A} &
\multicolumn{3}{>{\cellcolor[gray]{.8}}c|}{set A}\\ \cline{2-11}
&  \multicolumn{2}{c|}{2} & \multicolumn{2}{c|}{4} & \multicolumn{3}{c|}{6} &
\multicolumn{3}{c|}{8}  \\ \cline{2-11}
 & \multicolumn{2}{>{\cellcolor[gray]{.8}}c|}{max grade} &
\multicolumn{2}{>{\cellcolor[gray]{.8}}c|}{max grade} &
\multicolumn{3}{>{\cellcolor[gray]{.8}}c|}{max grade} &
\multicolumn{3}{>{\cellcolor[gray]{.8}}c|}{max grade}\\ \cline{2-11} 
&  2 & 3 & 2 & 3 & 2 & 3 & 4 & 2 & 3 & 4  \\ \hline
\multicolumn{1}{|>{\cellcolor[gray]{.8}}l|}{Imperatively}  & 1 & 1
& 1 & 10 & 20 & 30 & 40 & 10 &
 170 & 700\\ \hline 
\multicolumn{1}{|>{\cellcolor[gray]{.8}}l|}{Squander} & 900 & 770 &
1 090 & 1 060 & 1 810 & 3 080 & 2 970 & 2 980 &
15 010 & 7 880\\ \hline
\end{tabular}

%\end{center}
\end{table}


\begin{table}
%\label{tab:hpTimes}
\begin{center}
\begin{tabular}{l|r|r|r|r|r|r|r|r|} \cline{2-9}

\multirow{4}{*}{} & 
\multicolumn{8}{>{\cellcolor[gray]{.8}}c|}{Number of nodes
in the graph} \\ \cline{2-9} 
&  \multicolumn{4}{c|}{50} &
\multicolumn{2}{c|}{60} &
\multicolumn{2}{c|}{70}\\ \cline{2-9}
   & \multicolumn{4}{>{\cellcolor[gray]{.8}}c|}{set A} &
\multicolumn{2}{>{\cellcolor[gray]{.8}}c|}{set A} &
\multicolumn{2}{>{\cellcolor[gray]{.8}}c|}{set A}\\ \cline{2-9}
&  \multicolumn{4}{c|}{10} & \multicolumn{2}{c|}{12} & \multicolumn{2}{c|}{14}
\\ \cline{2-9}
 & \multicolumn{4}{>{\cellcolor[gray]{.8}}c|}{max grade} &
\multicolumn{2}{>{\cellcolor[gray]{.8}}c|}{max grade} &
\multicolumn{2}{>{\cellcolor[gray]{.8}}c|}{max grade}\\ \cline{2-9}
  & 2 & 3 & 4 & 5 & 2 & 3 & 2 & 3  \\\hline 

 \multicolumn{1}{|>{\cellcolor[gray]{.8}}l|}{Imperatively} &
20 & 240 & 830 & 110 & 20
& 20 & 2 010 & 1 260 \\ \hline
\multicolumn{1}{|>{\cellcolor[gray]{.8}}l|}{Squander} & 3 500 &
81 410 & \textbf{t/o} & \textbf{t/o} & 12 880 & 254 570 & 8 510  &
311 930
\\
\hline
\end{tabular}
%\label{fig:hpIMem405}
\end{center}
\end{table}

\newpage
\begin{table}[p!]
\caption{Execution times of General bisection breadth algorithm implementation
in ms for $\frac{1}{3}$ nodes in one node set}
\label{tab:gbbTimes13}
%\begin{center}
\begin{tabular}{l|r|r|r|r|r|r|r|r|r|r|} \cline{2-11}

\multirow{4}{*}{} & 
\multicolumn{10}{>{\cellcolor[gray]{.8}}c|}{Number of nodes
in the graph} \\ \cline{2-11} 

&  \multicolumn{2}{c|}{10} & \multicolumn{2}{c|}{20} &
 \multicolumn{3}{c|}{30} & \multicolumn{3}{c|}{40}\\ \cline{2-11}
 & \multicolumn{2}{>{\cellcolor[gray]{.8}}c|}{set A} &
\multicolumn{2}{>{\cellcolor[gray]{.8}}c|}{set A} &
\multicolumn{3}{>{\cellcolor[gray]{.8}}c|}{set A} &
\multicolumn{3}{>{\cellcolor[gray]{.8}}c|}{set A}\\ \cline{2-11}
&  \multicolumn{2}{c|}{3} & \multicolumn{2}{c|}{7} & \multicolumn{3}{c|}{10} &
\multicolumn{3}{c|}{13}  \\ \cline{2-11}
 & \multicolumn{2}{>{\cellcolor[gray]{.8}}c|}{max grade} &
\multicolumn{2}{>{\cellcolor[gray]{.8}}c|}{max grade} &
\multicolumn{3}{>{\cellcolor[gray]{.8}}c|}{max grade} &
\multicolumn{3}{>{\cellcolor[gray]{.8}}c|}{max grade}\\ \cline{2-11}
&  2 & 3 & 2 & 3 & 2 & 3 & 4 & 2 & 3 & 4  \\ \hline

\multicolumn{1}{|>{\cellcolor[gray]{.8}}l|}{Imperatively}  & 1 & 1 & 10 & 10 &
30 & 120 & 170 & 80 & 900 & 3 530\\ \hline 
\multicolumn{1}{|>{\cellcolor[gray]{.8}}l|}{Squander} & 720 & 780 &
1 010 & 1 330 & 1 780 & 7 840 & 59 080 & 2 970 &
111 040 & \textbf{t/o}\\ \hline
\end{tabular}

%\end{center}
\end{table}


\begin{table}[p!]
%\label{tab:hpTimes}
\begin{center}
\begin{tabular}{l|r|r|r|r|r|r|r|r|} \cline{2-9}

\multirow{4}{*}{} & 
\multicolumn{8}{>{\cellcolor[gray]{.8}}c|}{Number of nodes
in the graph} \\ \cline{2-9} 
&  \multicolumn{4}{c|}{50} &
\multicolumn{2}{c|}{60} &
\multicolumn{2}{c|}{70}\\ \cline{2-9}
   & \multicolumn{4}{>{\cellcolor[gray]{.8}}c|}{set A} &
\multicolumn{2}{>{\cellcolor[gray]{.8}}c|}{set A} &
\multicolumn{2}{>{\cellcolor[gray]{.8}}c|}{set A}\\ \cline{2-9}
&  \multicolumn{4}{c|}{17} & \multicolumn{2}{c|}{20} & \multicolumn{2}{c|}{23}
\\ \cline{2-9}
 & \multicolumn{4}{>{\cellcolor[gray]{.8}}c|}{max grade} &
\multicolumn{2}{>{\cellcolor[gray]{.8}}c|}{max grade} &
\multicolumn{2}{>{\cellcolor[gray]{.8}}c|}{max grade}\\ \cline{2-9}
  & 2 & 3 & 4 & 5 & 2 & 3 & 2 & 3  \\ \hline
\multicolumn{1}{|>{\cellcolor[gray]{.8}}l|}{Imperatively} &
330 & 1 590 & 29 400 & \textbf{t/o} & 350
& \textbf{t/o} & 25 160 & \textbf{t/o} \\ \hline
\multicolumn{1}{|>{\cellcolor[gray]{.8}}l|}{Squander} & 13 350 & \textbf{t/o} & \textbf{t/o} &
\textbf{t/o} & 82 140 & \textbf{t/o} & 172 220 & \textbf{t/o}
\\
\hline
\end{tabular}
%\label{fig:hpIMem405}
\end{center}
\end{table}



%\newpage
\begin{table}[p!]
\caption{Execution times of General bisection breadth algorithm implementation
in ms for $\frac{1}{2}$ nodes in one node set}
\label{tab:gbbTimes12}
%\begin{center}
\begin{tabular}{l|r|r|r|r|r|r|r|r|r|r|} \cline{2-11}

\multirow{4}{*}{} & 
\multicolumn{10}{>{\cellcolor[gray]{.8}}c|}{Number of nodes
in the graph} \\ \cline{2-11} 

&  \multicolumn{2}{c|}{10} & \multicolumn{2}{c|}{20} &
 \multicolumn{3}{c|}{30} & \multicolumn{3}{c|}{40}\\ \cline{2-11}
 & \multicolumn{2}{>{\cellcolor[gray]{.8}}c|}{set A} &
\multicolumn{2}{>{\cellcolor[gray]{.8}}c|}{set A} &
\multicolumn{3}{>{\cellcolor[gray]{.8}}c|}{set A} &
\multicolumn{3}{>{\cellcolor[gray]{.8}}c|}{set A}\\ \cline{2-11}
&  \multicolumn{2}{c|}{5} & \multicolumn{2}{c|}{10} & \multicolumn{3}{c|}{15} &
\multicolumn{3}{c|}{20}  \\ \cline{2-11}
 & \multicolumn{2}{>{\cellcolor[gray]{.8}}c|}{max grade} &
\multicolumn{2}{>{\cellcolor[gray]{.8}}c|}{max grade} &
\multicolumn{3}{>{\cellcolor[gray]{.8}}c|}{max grade} &
\multicolumn{3}{>{\cellcolor[gray]{.8}}c|}{max grade}\\ \cline{2-11}
&  2 & 3 & 2 & 3 & 2 & 3 & 4 & 2 & 3 & 4  \\ \hline

\multicolumn{1}{|>{\cellcolor[gray]{.8}}l|}{Imperatively}  & 1 & 10 & 20 & 20 &
110 & 310 & 510 & 2 140 & 8 120 & 22 500\\ \hline 
\multicolumn{1}{|>{\cellcolor[gray]{.8}}l|}{Squander} & 750 & 750 &
1 210 & 1 400 & 2 010 & 38 610 & 40 870 & 9 850 &
\textbf{t/o} & \textbf{t/o}\\ \hline
\end{tabular}

%\end{center}
\end{table}


\begin{table}[p!]
%\label{tab:hpTimes}
\begin{center}
\begin{tabular}{l|r|r|r|r|r|r|r|r|} \cline{2-9}

\multirow{4}{*}{} & 
\multicolumn{8}{>{\cellcolor[gray]{.8}}c|}{Number of nodes
in the graph} \\ \cline{2-9} 
&  \multicolumn{4}{c|}{50} &
\multicolumn{2}{c|}{60} &
\multicolumn{2}{c|}{70}\\ \cline{2-9}
   & \multicolumn{4}{>{\cellcolor[gray]{.8}}c|}{set A} &
\multicolumn{2}{>{\cellcolor[gray]{.8}}c|}{set A} &
\multicolumn{2}{>{\cellcolor[gray]{.8}}c|}{set A}\\ \cline{2-9}
&  \multicolumn{4}{c|}{25} & \multicolumn{2}{c|}{30} & \multicolumn{2}{c|}{35}
\\ \cline{2-9}
 & \multicolumn{4}{>{\cellcolor[gray]{.8}}c|}{max grade} &
\multicolumn{2}{>{\cellcolor[gray]{.8}}c|}{max grade} &
\multicolumn{2}{>{\cellcolor[gray]{.8}}c|}{max grade}\\ \cline{2-9}
  & 2 & 3 & 4 & 5 & 2 & 3 & 2 & 3  \\ \hline
\multicolumn{1}{|>{\cellcolor[gray]{.8}}l|}{Imperatively} &
86 090 & 160 250 & 350 300 & \textbf{t/o} & \textbf{t/o}
& \textbf{t/o} & \textbf{t/o} & \textbf{t/o} \\ \hline
\multicolumn{1}{|>{\cellcolor[gray]{.8}}l|}{Squander} & 40 980 & \textbf{t/o} &
\textbf{t/o} & \textbf{t/o} & \textbf{t/o} & \textbf{t/o} & \textbf{t/o} & \textbf{t/o}
\\
\hline
\end{tabular}
%\label{fig:hpIMem405}
\end{center}
\end{table}
\clearpage
When comparing heap memory usage in following graphs we can see that opposite to
previous implementations of algorithms Squander's implementation has lower load
on heap memory. Usually it is up to 15 Mb except for peak at the beginning when
starts Kodkod engine and universe is created, but also here heap memory does not
occupied more than 25 Mb. Imperative implementation has also big peak at the
beginning of computation but then stabilizes memory usage under 10 Mb.

CPU usage is as usual for both implementations around 50 \% except for Squander
when starting Kodkod engine.

Garbage collector was used quite often in both version of implementation, in
imperative 0.5 \% in average and in Squander 2.44 \% of execution time, which
gives again better result for imperative implementation.
\clearpage


\begin{figure}
\begin{center}
\input{figures/graphs/gbb/imp/70-2-1-3/heap.tex}
\caption{Heap memory usage in time - General bisection breadth imperative
implementation, set A=$\frac{1}{3}$ for graph with 70 nodes, max. grade 2 and
info, when was GC performed}
\label{fig:gbbIHeap90213}
\end{center}
\end{figure}


\begin{figure}
\begin{center}
\input{figures/graphs/gbb/squander/70-2-1-3/heap.tex}
\caption{Heap memory usage in time - General bisection breadth Squander
implementation, set A=$\frac{1}{3}$ for graph with 70 nodes, max. grade 2 and
info, when was GC performed}
\label{fig:gbbSHeap90213}
\end{center}
\end{figure}



\begin{figure}
\begin{center}
\input{figures/graphs/gbb/imp/70-2-1-3/cpu.tex}
\caption{CPU usage in time - General bisection breadth imperative
implementation, set A=$\frac{1}{3}$ for graph with 70 nodes, max. grade 2}
\label{fig:gbbICpu70213}
\end{center}
\end{figure}




\begin{figure}
\begin{center}
\input{figures/graphs/gbb/squander/70-2-1-3/cpu.tex}
\caption{CPU usage in time - General bisection breadth Squander
implementation, set A=$\frac{1}{3}$ for graph with 70 nodes, max. grade 2}
\label{fig:gbbSCpu70213}
\end{center}
\end{figure}


\begin{figure}
\begin{center}
\input{figures/graphs/gbb/imp/50-2-1-2/heap.tex}
\caption{Heap memory usage in time - General bisection breadth imperative
implementation, set A=$\frac{1}{2}$ for graph with 50 nodes, max. grade 2 and
info, when was GC performed}
\label{fig:gbbIHeap50212}
\end{center}
\end{figure}

\begin{figure}
\begin{center}
\input{figures/graphs/gbb/squander/50-2-1-2/heap.tex}
\caption{Heap memory usage in time - General bisection breadth Squander
implementation, set A=$\frac{1}{2}$ for graph with 50 nodes, max. grade 2 and
info, when was GC performed}
\label{fig:gbbSHeap50212}
\end{center}
\end{figure}



\begin{figure}
\begin{center}
\input{figures/graphs/gbb/imp/50-2-1-2/cpu.tex}
\caption{CPU usage in time - General bisection breadth imperative
implementation, set A=$\frac{1}{2}$ for graph with 50 nodes, max. grade 2}
\label{fig:gbbICpu50212}
\end{center}
\end{figure}

\begin{figure}
\begin{center}
\input{figures/graphs/gbb/squander/50-2-1-2/cpu.tex}
\caption{CPU usage in time - General bisection breadth Squander
implementation, set A=$\frac{1}{2}$ for graph with 50 nodes, max. grade 2}
\label{fig:gbbSCpu50212}
\end{center}
\end{figure}
\clearpage
%We can now compute how strong are dependencies between input data and execution
%time for Squander implementation. We define for that purpose random following
%variables:
For computation of dependencies between input, output data and execution
time for Squander implementation we define following
random variables:
\begin{enumerate}
  \item $X$ as execution time of concrete graph instance
  \item $Y$ as number of nodes in concrete graph instance
  \item $Z$ as maximal node grade in concrete graph instance
  \item $W$ as ratio of the number of nodes of set A to the total number of
  nodes of the graph for concrete computation
\end{enumerate}
For the computation were used graph instances with 10, 20, 30, 40, 50, 60, 70
nodes, max. node grade 2, 3, 4 and ratio of the number of nodes of set A to the total number of
  nodes of the graph  $\frac{1}{5}$, $\frac{1}{3}$, $\frac{1}{2}$. When exec.
  time reaches timeout (45 min), exec. time is 1 hour.

$$EX = \frac{1}{63}\cdot(900  + 770  +830  + 1090  + 1060  
 + 2 120 + 1 810+ 3 060 + 2970 + 2 980 + 15 010 + 7 880
+$$
$$3500 + 81 410 +3600000+12 880+254 570+ 3600000 + 8510+311 930 +3600000+ 720
+$$ $$780 + 860 + 1010 +1330 + 2110 +1780 +7840 +59 080 +2 970 +111 040+
3600 000 +13 350 +$$ $$3600 000 +3600 000+82 140 +3600 000 +3600000+172 220 +3600
000 + 3600000 +750+ 750+ 900+$$ $$ 1 210 +1400 + 2 240 +2 010 +38 610 +40
870 +9850 +3600000+ 3600000+40 980 +3600000 +3600000+$$ $$3600000+3600000+
3600000+3600000 +3600000 +3600000) =1163652.1$$

%here I am


$$varX=E(X-EX)^2=\frac{1}{63}\cdot[\left(900-1163652.1
\right)^2+\left(770-1163652.1\right)^2+\left(830 -1163652.1\right)^2+$$
$$\left(1090-1163652.1\right)^2+\left(1060-1163652.1\right)^2+\left(2120-1163652.1\right)^2+\left(1810-1163652.1\right)^2+$$
$$\left(3060-1163652.1\right)^2+\left(2970-1163652.1\right)^2+\left(2980-1163652.1\right)^2+\left(15010-1163652.1\right)^2+$$
$$\left( 7880
-1163652.1\right)^2+\left(3500-1163652.1\right)^2+\left(81410-1163652.1\right)^2+\left(3600000-1163652.1\right)^2+$$
$$\left(12880-1163652.1\right)^2+\left(254570-1163652.1\right)^2+\left(3600000-1163652.1\right)^2+\left(8510-1163652.1\right)^2+$$
$$\left(311930-1163652.1\right)^2+\left(3600000-1163652.1\right)^2+\left(720-1163652.1
\right)^2+\left(780-1163652.1\right)^2+$$
%TADY
$$\left(860
-1163652.1\right)^2+\left(1010-1163652.1\right)^2+\left(1330-1163652.1\right)^2+\left(2110-1163652.1\right)^2+$$
$$\left(1780-1163652.1\right)^2+\left(7840-1163652.1\right)^2+\left(59080-1163652.1\right)^2+\left(2970-1163652.1\right)^2+$$
$$\left(111040-1163652.1\right)^2+\left( 3600000
-1163652.1\right)^2+\left(13350-1163652.1\right)^2+\left(3600000-1163652.1\right)^2+$$
$$\left(3600000-1163652.1\right)^2+\left(82140-1163652.1\right)^2+\left(3600000-1163652.1\right)^2+\left(3600000-1163652.1\right)^2+$$
$$\left(172220-1163652.1\right)^2+\left(3600000-1163652.1\right)^2+\left(3600000-1163652.1\right)^2+\left(750-1163652.1
\right)^2+$$ $$\left(750-1163652.1\right)^2+\left(900
-1163652.1\right)^2+\left(1210-1163652.1\right)^2+\left(1400-1163652.1\right)^2+$$
%TADY
$$\left(2240-1163652.1\right)^2+\left(2010-1163652.1\right)^2+\left(38610-1163652.1\right)^2+\left(40870-1163652.1\right)^2+$$
$$\left(9850-1163652.1\right)^2+\left(3600000-1163652.1\right)^2+\left( 3600000
-1163652.1\right)^2+\left(40980-1163652.1\right)^2+$$
$$\left(3600000-1163652.1\right)^2+\left(3600000-1163652.1\right)^2+\left(3600000-1163652.1\right)^2+\left(3600000-1163652.1\right)^2+$$
$$\left(3600000-1163652.1\right)^2+\left(3600000-1163652.1\right)^2+\left(3600000-1163652.1\right)^2+\left(3600000-1163652.1\right)^2]$$
$$=2763798806962.41$$


$$EY = \frac{1}{7}\cdot \left(10 + 20+ 30 + 40 +  50 +  60 +
 70\right)=40$$

$$varY=E(Y-EY)^2=\frac{1}{7}\cdot[\left(10 -40\right)^2+\left(20
-40\right)^2+\left(30 -40\right)^2+\left(40 -40\right)^2+$$
$$\left(50 -40\right)^2+\left(60 -40\right)^2+\left(70 -40\right)^2]=400$$

$$EZ = \frac{1}{3}\cdot \left(2 +  3 + 4\right)=3$$
$$varZ=E(Z-EZ)^2=\frac{1}{3}\cdot [\left(2 -  3\right)^2+\left(3 - 
3\right)^2+\left(4 -  3\right)^2]=0.33$$

$$EW = \frac{1}{3}\cdot \left(\frac{1}{5} +  \frac{1}{3} +
\frac{1}{2}\right)=0.34$$ 
$$varW=E(W-EW)^2=\frac{1}{3}\cdot [\left(\frac{1}{5} - 
0.34\right)^2+\left(\frac{1}{3} - 0.34\right)^2+\left(\frac{1}{2} - 
0.34\right)^2]=0.0151$$ 
now we compute median $EXY$ and $EXZ$, $cov(X,Y)$ and $cov(X,Z)$, $cor(X,Y)$
and $cor(X,Z)$:

$$EXY= \frac{1}{63}\cdot(10\cdot 900  + 10\cdot  770  + 10\cdot  830 +
20 \cdot  1090+ 20 \cdot   1060+ 20 \cdot  2120  +30 \cdot   1810 +30\cdot  
 3060+$$ $$30 \cdot  2970 +40\cdot 
2980 +40\cdot  15010 +40\cdot 7880 +50\cdot  3500
+50\cdot   81410 +50\cdot 3600000+60\cdot  12880
 +60\cdot  254570 +$$ $$60\cdot   3600000  +70\cdot  8510
+70\cdot   311930 +70\cdot 3600000 +10\cdot 720
 +10\cdot 780 +10\cdot  860 + 20 \cdot 1010+$$
 $$20\cdot   1330  +20\cdot  2110
+30\cdot   1780 +30\cdot  7840 +30\cdot 59080
 +40\cdot 2970 +40\cdot  111040 + 40 \cdot  3600000+$$
 $$50\cdot  13350  +50\cdot 3600000
+50\cdot 3600000 +60\cdot  82140 +60\cdot 3600000
 +60\cdot  3600000 +70\cdot  172220 + 70 \cdot  3600000+$$
 $$70\cdot  3600000  +10\cdot 750
+10\cdot  750 +10\cdot  900 +20\cdot 1210
 +20\cdot 1400 +20\cdot   2240 + 30 \cdot  2010+$$
 $$30\cdot   38610  +30\cdot  40870
+40\cdot  9850 +40\cdot   3600000 +40\cdot  3600000
 +50\cdot 40980 +50\cdot   3600000 + 50 \cdot  3600000+$$
$$60\cdot  3600000  +60\cdot  3600000
+60\cdot 3600000  +70\cdot 3600000 +70\cdot  3600000
 +70\cdot   3600000)=66880915.87$$

$$cov\left(X,Y\right)=EXY-\left(EX\right)\cdot \left(EY\right)=66880915.87
-1163652.1\cdot 40= 20334831.87$$

$$cor(X,Y)=\frac{cov(X,Y)}{\sqrt{varX}\sqrt{varY}}=\frac{20334831.87}{\sqrt{2763798806962.41}\sqrt{400}}=0.612$$
%\newpage

$$EXZ= \frac{1}{63}\cdot(2\cdot 900  + 3\cdot  770  + 4\cdot  830 +
2 \cdot  1090+ 3 \cdot   1060+ 4 \cdot  2120  +2 \cdot   1810 +3\cdot  
 3060+$$ $$4 \cdot  2970 +2\cdot 
2980 +3\cdot  15010 +4\cdot 7880 +2\cdot  3500
+3\cdot   81410 +4\cdot 3600000+2\cdot  12880
 +3\cdot  254570 +$$ $$4\cdot   3600000  +2\cdot  8510
+3\cdot   311930 +4\cdot 3600000 +2\cdot 720
 +3\cdot 780 +4\cdot  860 + 2 \cdot 1010+$$
 $$3\cdot   1330  +4\cdot  2110
+2\cdot   1780 +3\cdot  7840 +4\cdot 59080
 +2\cdot 2970 +3\cdot  111040 + 4 \cdot  3600000+$$
 $$2\cdot  13350  +3\cdot 3600000
+4\cdot 3600000 +2\cdot  82140 +3\cdot 3600000
 +4\cdot  3600000 +2\cdot  172220 + 3 \cdot  3600000+$$
 $$4\cdot  3600000  +2\cdot 750
+3\cdot  750 +4\cdot  900 +2\cdot 1210
 +3\cdot 1400 +4\cdot   2240 + 2 \cdot  2010+$$
 $$3\cdot   38610  +4\cdot  40870
+2\cdot  9850 +3\cdot   3600000 +4\cdot  3600000
 +2\cdot 40980 +3\cdot   3600000 + 4 \cdot  3600000+$$
$$2\cdot  3600000  +3\cdot  3600000
+4\cdot 3600000  +2\cdot 3600000 +3\cdot  3600000
 +4\cdot   3600000)=4001419.68$$

$$cov\left(X,Z\right)=EXZ-\left(EX\right)\cdot \left(EZ\right)=4001419.68
-1163652.1\cdot 3=510463.38$$

$$cor(X,Z)=\frac{cov(X,Z)}{\sqrt{varX}\sqrt{varZ}}=\frac{510463.38}{\sqrt{2763798806962.41}\sqrt{0.33}}=0.53$$

%\newpage

$$EXW= \frac{1}{63}\cdot(\frac{1}{5}\cdot 900  + \frac{1}{3}\cdot  770  +
\frac{1}{2}\cdot 830 + \frac{1}{5} \cdot  1090+ \frac{1}{3} \cdot   1060+
\frac{1}{2} \cdot  2120  +\frac{1}{5} \cdot   1810 +\frac{1}{3}\cdot 3060+$$
$$\frac{1}{2} \cdot  2970 +\frac{1}{5}\cdot 2980 +\frac{1}{3}\cdot  15010
+\frac{1}{2}\cdot 7880 +\frac{1}{5}\cdot  3500 +\frac{1}{3}\cdot   81410
+\frac{1}{2}\cdot 3600000+\frac{1}{5}\cdot 12880 +\frac{1}{3}\cdot  254570 +$$
$$\frac{1}{2}\cdot   3600000  +\frac{1}{5}\cdot  8510 +\frac{1}{3}\cdot   311930
+\frac{1}{2}\cdot 3600000 +\frac{1}{5}\cdot 720 +\frac{1}{3}\cdot 780
+\frac{1}{2}\cdot 860 + \frac{1}{5} \cdot 1010+$$ $$\frac{1}{3}\cdot   1330 
+\frac{1}{2}\cdot  2110 +\frac{1}{5}\cdot   1780 +\frac{1}{3}\cdot  7840
+\frac{1}{2}\cdot 59080 +\frac{1}{5}\cdot 2970 +\frac{1}{3}\cdot  111040
+\frac{1}{2} \cdot  3600000+$$ $$\frac{1}{5}\cdot  13350  +\frac{1}{3}\cdot
3600000 +\frac{1}{2}\cdot 3600000 +\frac{1}{5}\cdot  82140 +\frac{1}{3}\cdot
3600000 +\frac{1}{2}\cdot  3600000 +\frac{1}{5}\cdot  172220 + \frac{1}{3} \cdot
3600000+$$ $$\frac{1}{2}\cdot  3600000  +\frac{1}{5}\cdot 750
+\frac{1}{3}\cdot  750 +\frac{1}{2}\cdot  900 +\frac{1}{5}\cdot 1210
 +\frac{1}{3}\cdot 1400 +\frac{1}{2}\cdot   2240 + \frac{1}{5} \cdot  2010+$$
 $$\frac{1}{3}\cdot   38610  +\frac{1}{2}\cdot  40870
+\frac{1}{5}\cdot  9850 +\frac{1}{3}\cdot   3600000 +\frac{1}{2}\cdot  3600000
 +\frac{1}{5}\cdot 40980 +\frac{1}{3}\cdot   3600000 + \frac{1}{2} \cdot 
 3600000+$$ $$\frac{1}{5}\cdot  3600000  +\frac{1}{3}\cdot  3600000
+\frac{1}{2}\cdot 3600000  +\frac{1}{5}\cdot 3600000 +\frac{1}{3}\cdot  3600000
 +\frac{1}{2}\cdot   3600000)=476961.62$$
 
$$cov\left(X,W\right)=EXW-\left(EX\right)\cdot \left(EW\right)=476961.62
-1163652.1\cdot 0.34=81319.91$$

$$cor(X,W)=\frac{cov(X,W)}{\sqrt{varX}\sqrt{varW}}=\frac{81319.91}{\sqrt{2763798806962.41}\sqrt{0.0151}}=0.4$$

Computed correlations shows, that execution time directly depends most on
number of nodes in the graph, where is correlation with execution time 0.612,
but not very significantly in contrast with maximal node grade (correlation
0.53) and ratio of the number of nodes of set A to the total number of nodes of
the graph (correlation 0.4). From correlations computed for imperative
implementation is obvious, that also here is execution time the most directly
dependent on number of nodes in the graph (correlation 0.39). That is the
same situation like in Squander implementation, but in imperative implementation
is execution time more dependent on ratio of the number of nodes in set A to the
total number of nodes in the graph (correlation 0.38 - almost the same number
like for number of nodes in the graph) than on maximal node grade (correlation
0.33).


%\newpage

%*****************************************************************************
\chapter{Conclusion}

Framework Squander is really interesting tool that brings into classical Java
new way for solving problems containing lot of constraints. Main
advantage of that framework is, that programmer can smoothly switch between
declarative logic and imperative programming. That all was written in
theoretical part and what are the experiences? Of course when using this framework,
programme allocates more memory, sometimes throws out of memory exception,
computes bad result and so on. On the other hand, Squander is still in
development and there were also appearing some changes during the time I used
this framework.
%But how elegant was declaring algorithm instead
%of writing lot of code telling system how to compute something. 
In my opinion Squander provides high-quality API for declaration of algorithms
with wide range of operators and expressions provided by JSFL language. Sometimes is
quite hard to declare problem easily, because some operators and expressions are missing
(e.g. summation without possibility of declaring condition) but these problems
can be solved by using another operators or expressions (e.g. Java ternary
operators). When implementing algorithms, programmer has to be careful in
declaring objects, which will use framework, because of size of final universe.
It is useful to declare various types of variables and avoid using arrays, lists
and maps so much (they are creating ternary relations) in order to create as
lowest number of atoms as possible and to decrease size of universe. Another
necessary thing to mention is about bitwidth used in framework for integers. In
case, when programmer declares some minimizing treshold variable and set it to
value $2$ powered by $n\in\mathbb{N}$ subtracted by $1$, framework figures out that
scope of all signed integer variables will be at least up to size of that
variable (e.g. when using treshold of size 511, Squander uses bitwidth 10 and
scope from -512 to 511). That means, when desirable result
has to be greater than that treshold, then it is out of that scope and framework
throws no result exception. Supporting only first order logic can also caused some problems when
implementing optimizing algorithms. This problem can be solved by using some
treshold value for solution, which is \uv{good enough} for the programmer, or by
implementing some heuristic, which will change treshold dynamically according to
some dependency between input and output parameters - it could be good task
for future work. Someone could suggest implementation of higher order logic into
framework, but it would be very difficult to implement a fully automatic solver
for it. Even if everything is bounded, quantifying over all functions would be
extremely inefficient, so the whole tool would not be very practical.

Every programmer should ask a question why do not people (or programmers)
use logic programming instead of imperative programming. And I have to answer
myself \uv{I don't really know}. Of course there are according to Essam
\cite{essam:cla} some weaknesses of Prolog like cut (does not backtrack on
choices it has made), problem that Prolog does not always knows \uv{whole world}
and not correct implementation of negation (negation means that variable cannot
be proven true). On the other hand there are such advantages like easy
maintenance, no memory leaks or dangling pointers, good code optimization
(approach performance of C) and it is naturally parallel paradigm. All in all Squander is
evaluated in another way than Prolog, but I think there are no serious problems
why do not use declarative programming.
%According to Alireza Azem's PhD. thesis from
%Universität Paderborn

%Why people do not use logic programming.

%Some problems
%caused by bugs in framework could easily repaired, because
%framework is still in development.
%*****************************************************************************
% Seznam literatury je v samostatnem souboru reference.bib. Ten
% upravte dle vlastnich potreb, potom zpracujte (a do textu
% zapracujte) pomoci prikazu bibtex a nasledne pdflatex (nebo
% latex). Druhy z nich alespon 2x, aby se poresily odkazy.

\begin{thebibliography}{1}

\bibitem{milicevic:executableSpecificationsForJavaPrograms}
Aleksandar Milicevic; MASSACHUSETTS INSTITUTE OF TECHNOLOGY, Department of
Electrical Engineering and Computer Science; \textit{Executable Specifications
for Java Programs}, September 2010.

\bibitem{torlak:constraintSolver}
Emina Torlak; MASSACHUSETTS INSTITUTE OF TECHNOLOGY, Department of
Electrical Engineering and Computer Science; \textit{A Constraint Solver for
Software Engineering: Finding Models and Cores of Large Relational
Specifications - PhD. thesis}, February 2009.


\bibitem{web:squander}Squander
official website;\\\verb|http://people.csail.mit.edu/aleks/squander/|


\bibitem{horstmannCornell:coreJava}
Cay Horstmann and Gary Cornell; \textit{Core Java}, 7th edition.

\bibitem{jirku:progProlog}
Petr Jirků a kol.; \textit{Programování v jazyku Prolog}, 1991.

\bibitem{kolar:jui}
doc. RNDr. Josef Kolář, CSc.; Czech Technical University, Faculty of Electrical
Engineering; \textit{Jazyky pro umělou inteligenci}, 1994.


\bibitem{navara:mvt}
prof. Ing. Mirko Navara, DrSc.; Czech Technical University, Faculty of Electrical
Engineering; \textit{Pravděpodobnost a matematická
statistika}, 2007.


\bibitem{schmidt:paa}
Ing. Jan Schmidt, PhD.; Czech Technical University, Faculty of Electrical
Engineering; \textit{Problems and algorithms - lectures}, 2011.


\bibitem{tvrdik:par}
prof. Ing. Pavel Tvrdík, CSc.; Czech Technical University, Faculty of Electrical
Engineering; \textit{Parallel algorithms and computing - semestral works}, 2011.

\bibitem{kulich:stat}
doc. Mgr. Milan Kulich, PhD.; MFF
Univerzity Karlovy; \textit{Matematická statistika - lectures}, summer 2011.


\bibitem{nino:pls}
Dr. Jaime Niño, Associate Professor of Computer Science; University of New
Orleans; \textit{Programming language structure - lectures}, 2011.

\bibitem{essam:cla}Dr. Daryl Essam, University of New South Wales
Sydney;\textit{Computer Languages and Algorithms - lectures}, 2011.\\
\verb|http://seit.unsw.adfa.edu.au/coursework/ZEIT3113/lectures/05/PL5/PL5.htm|
%\bibitem{azem:thesis}Dr.-Ing. Alireza Azem; Universität Pradeborn;
%\textit{Software Reliability Determination for Conventional and Logic
%Programming (PRORel)}\\
%\verb|http://adt.uni-paderborn.de/forschung/completed-doctoral-theses-phd-theses.html#Reliability|


\bibitem{java:annotations}Annotations;\\
\verb|http://download.oracle.com/javase/1,5.0/docs/guide/language/annotations.html|

\bibitem{web:mathIsFun}Math
is fun
web;\\\verb|http://www.mathsisfun.com/games/triangle-peg-solitaire/index.html#|

\bibitem{oracle:javadoc}Oracle Java documentation - \verb|ThreadMXBean|;\\
\verb|http://download.oracle.com/javase/1,5,0/docs/api/|

\bibitem{oracle:javadocSet}Oracle Java documentation - \verb|java.util.Set|;\\
\verb|http://download.oracle.com/javase/6/docs/api/java/util/Set.html|

\end{thebibliography}

% originally following specification for bibliography formating was used
%\bibliographystyle{abbrv}

% Here is an improvment by Petr Dlouhy (April 2010).
% It is mainly for supervisors who expect Czech fomrating rules for references
% Additional feature is live url addresses to sources from your pdf file
% It requires the file csplainnat.bst (included in this sample zipfile).

\bibliographystyle{csplainnat}

%bibliographystyle{plain}
%\bibliographystyle{psc}
{
%JZ: 11.12.2008 Kdo chce mit v techto ukazkovych odkazech take odkaz na CSTeX:
\def\CS{$\cal C\kern-0.1667em\lower.5ex\hbox{$\cal S$}\kern-0.075em $}
\bibliography{reference}
}


% M. Dušek radi:
%\bibliographystyle{alpha}
% kdy citace ma tvar [AutorRok] (napriklad [Cook97]). Sice to asi neni  podle ceske normy (BTW BibTeX stejne neodpovida ceske norme), ale je to nejprehlednejsi.
% 3.5.2009 JZ polemizuje: BibTeX neobvinujte, napiste a poskytnete nam styl (.bst) splnujici citacni normu CSN/ISO.

%*****************************************************************************
%*****************************************************************************
\appendix


%*****************************************************************************

%*****************************************************************************
\chapter{List of used shortcuts}

\begin{description}
\item[SAT] Boolean satisfiability problem
\item[EJB] Enterprise Java Beans
\item[NP] Nondeterministic polynomial time
\item[NPO] Nondeterministic polynomial time for optimized problems
\item[JFSL] JForge Specification Language
\item[BST] Binary Search Tree
\item[JVM] Java Virtual Machine
\item[TPTP] Test \& Performance Tools Platform
\item[RAM] Random Access Memory
\item[CNF] Conjunctive Normal Form
\item[GC] Garbage Collector
\item[BB-DFS] Branch \& Bounds Depth First Search
\item[BFS] Breadth First Search
\item[CPU] Central Processor Unit
\item[API] Application Programming Interface
\end{description}


%*****************************************************************************
\chapter{Few terms from statistics}
\label{ch:statistics}

\section{Basic terms}
Due to computation of dependencies between input or output data and execution
time in Chapter \ref{ch:comparison} Comparison will be presented in this smaller
chapter some statistic terms. At first we have to define term \textit{random
variable}. As is defined in \cite{navara:mvt}, let $\mathcal{S}$ is a
phenomenal field, $\Omega\in\mathcal{S}$ is a certain phenomenon, and
$P$ probability of the phenomenal field $\mathcal{S}$. The real
function: 
\begin{center}
$X:\Omega \rightarrow \mathbb{R}$,
\end{center}

for which the set

$$\{E; E \subset \Omega, X\left(E\right) \leq x\} \in
\mathcal{S}$$

is for each value $x \in \mathbb{R}$ called a random variable. E.g. when we
have an experiment with throwing a die. We can assign every side of die number
from 1 to 6 according to number of points on that side but also we can assign
those sides with 0 and 1 according to even or odd number of points on that side.

Another necessary terms to define are \textit{median} and \textit{variance}.
According to Navara \cite{navara:mvt}, when random variable $X$ has discrete distribution, then
number:
$$EX=\sum_i x_i\cdot P\left[X=x_i\right]=\sum_i x_i p_i$$

Variance of random variable $X$ is number $var X = E(X-EX)^2$. Number $\sigma =
\sqrt{var X}$ is called \textit{standard deviation}.

\section{Covariance}
Finally we can define terms which we will use for computing dependency between
two random variables. It is so called \textit{covariance}, which is defined for two
random variables as \cite{navara:mvt}:

$$cov(Y,Z)=E\left[\left(Y-EY\right)\left(Z-EZ\right)\right]$$
Clauses about covariance \cite{kulich:stat}:

\begin{center}
$cov(X,X)=var X$\\
$cov(X,Y)=cov(Y,X)$\\
$cov(X,Y)^2\leq var X \cdot var Y$\\
$cov(X,Y) = EXY - EX\cdot EY$\\
If $X$ and $Y$ are independent, then
$cov\left(X,Y\right)=0 \rightarrow EXY=EX\cdot EY$\\
\end{center}
\begin{itemize}
  \item If is covariance positive, it means, that random variables $X$ and
$Y$ are dependent and that grater values of one variable are connected with
greater values of the second variable (and lower values of one variable connected with
lower values of the second variable). E.g.: human height and weight.
  \item If is covariance negative, it means, that random variables $X$ and
$Y$ are dependent and that greater values of one variable are connected with
lower values of the second variable. E.g.: pattern depth
of tyre and braking distance.
\end{itemize}
\section{Correlation}

Values of covariance have bad interpretation. We know from given value
$cov(X,Y)\neq0$ in which direction are $X$ and $Y$ dependent, but we do not know
how strong dependence is. We define for that reason \textit{correlation}
\cite{kulich:stat}:

$$cor(X,Y)=\frac{cov(X,Y)}{\sqrt{var X}\sqrt{var Y}}$$ 

Clauses about correlation \cite{kulich:stat}:

\begin{center}
Correlation $cor(X,Y)$ is always between -1 and 1. Correlation is zero just when
$cov(X,Y)=0$\\
If $X$ and $Y$ are independent, then $cor(X,Y)=0$\\
$cor(X,Y)=1$ just when $Y=a+bX$; $a\in\mathbb{R}$ and $b>0$\\
$cor(X,Y)=-1$ just when $Y=a+bX$; $a\in\mathbb{R}$ and $b<0$\\
\end{center}

Independent variables have always zero correlation. But when is correlation
zero, it does not mean, that random variables $X$ and $Y$ are independent
necessarily.
%*****************************************************************************
%\chapter{Instalační a uživatelská příručka}
%\textbf{\large Tato příloha velmi žádoucí zejména u softwarových
%implementačních prací.}

%*****************************************************************************
\chapter{Contents of the attached CD}
%\textbf{\large Tato příloha je povinná pro každou práci. Každá práce musí totiž
%obsahovat přiložené CD. Viz dále.}

%Může vypadat například takto. Váš seznam samozřejmě bude odpovídat typu vaší
%práce. (viz \cite{infodp}):

%\begin{figure}[h]
%\begin{center}
%\includegraphics[width=14cm]{figures/seznamcd}
%\caption{Seznam přiloženého CD --- příklad}
%\label{fig:seznamcd}
%\end{center}
%\end{figure}

%Na GNU/Linuxu si strukturu přiloženého CD můžete snadno vyrobit příkazem:\\ 
%\verb|$ tree . >tree.txt|\\
%Ve vzniklém souboru pak stačí pouze doplnit komentáře.

%Z \textbf{README.TXT} (případne index.html apod.)  musí být rovněž zřejmé, jak
%programy instalovat, spouštět a jaké požadavky mají tyto programy na hardware.

%Adresář \textbf{text}  musí obsahovat soubor s vlastním textem práce v PDF nebo
%PS formátu, který bude později použit pro prezentaci diplomové práce na WWW.
\include{cd/tree}
\end{document}
